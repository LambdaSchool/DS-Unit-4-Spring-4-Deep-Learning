diff --git a/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb b/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb
index e9e8759..e73a529 100644
--- a/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb
+++ b/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb
@@ -27,7 +27,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 1,
    "metadata": {
     "ExecuteTime": {
      "end_time": "2019-10-15T01:09:43.747351Z",
@@ -80,7 +80,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 2,
    "metadata": {
     "ExecuteTime": {
      "end_time": "2019-10-15T01:09:21.086085Z",
@@ -93,10 +93,10 @@
      "output_type": "stream",
      "text": [
       "﻿\n",
-      "project gutenberg’s the complete works of william shakespeare, by william\n",
-      "shakespeare\n",
+      "Project Gutenberg’s The Complete Works of William Shakespeare, by William\n",
+      "Shakespeare\n",
       "\n",
-      "this ebook \n"
+      "This eBook \n"
      ]
     }
    ],
@@ -109,7 +109,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 32,
+   "execution_count": 3,
    "metadata": {
     "ExecuteTime": {
      "end_time": "2019-10-15T01:48:58.337808Z",
@@ -128,10 +128,10 @@
     {
      "data": {
       "text/plain": [
-       "'contents the sonnets all’s well that ends well the tragedy of antony and cleopatra as you like it th'"
+       "'Contents THE SONNETS ALL’S WELL THAT ENDS WELL THE TRAGEDY OF ANTONY AND CLEOPATRA AS YOU LIKE IT TH'"
       ]
      },
-     "execution_count": 32,
+     "execution_count": 3,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -149,7 +149,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 37,
+   "execution_count": 4,
    "metadata": {
     "ExecuteTime": {
      "end_time": "2019-10-15T02:13:14.245573Z",
@@ -162,7 +162,7 @@
      "output_type": "stream",
      "text": [
       "Total Characters:  5256461\n",
-      "Total Characters:  71\n"
+      "Total Unique Characters:  99\n"
      ]
     }
    ],
@@ -175,9 +175,175 @@
     "n_chars = len(text)\n",
     "n_vocab = len(chars)\n",
     "print (\"Total Characters: \", n_chars)\n",
-    "print (\"Total Characters: \", n_vocab)"
+    "print (\"Total Unique Characters: \", n_vocab)"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "We can see that the text blob have 500K characters, and that each converted to lowercase with no `\\r` gave us 99 unique characters. "
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 5,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Total Patterns:  5256361\n"
+     ]
+    }
+   ],
+   "source": [
+    "seq_length = 100\n",
+    "\n",
+    "X_data= []\n",
+    "y_data = []\n",
+    "\n",
+    "for i in range(0, n_chars - seq_length, 1):\n",
+    "    seq_in = text[i:i + seq_length]\n",
+    "    seq_out = text[i + seq_length]\n",
+    "    X_data.append([char2idx[char] for char in seq_in])\n",
+    "    y_data.append(char2idx[seq_out])\n",
+    "\n",
+    "n_patterns = len(X_data)\n",
+    "print(\"Total Patterns: \", n_patterns)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "scrolled": true
+   },
+   "outputs": [],
+   "source": [
+    "# Reshape X to be [samples, time steps, features]\n",
+    "X = np.reshape(X_data, (n_patterns, seq_length, 1))\n",
+    "\n",
+    "# Normalize\n",
+    "X = X / float(n_vocab)\n",
+    "\n",
+    "# One hot encode the output variable\n",
+    "y = to_categorical(y_data)\n",
+    "\n",
+    "print(f'Shape of X: {X.shape}')\n",
+    "print(f'Shape of y: {y.shape}')"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Create Model"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def create_model1(X, y):\n",
+    "    # Define the LSTM model\n",
+    "    model = Sequential()\n",
+    "    model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
+    "    model.add(Dropout(0.2))\n",
+    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
+    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
+    "    return model\n",
+    "\n",
+    "\n",
+    "model1 = create_model1(X, y)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Add callbacks"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import wandb\n",
+    "from wandb.keras import WandbCallback\n",
+    "\n",
+    "wandb.init(project=\"angus\")\n",
+    "\n",
+    "# define the checkpoint\n",
+    "# Directory where the checkpoints will be saved\n",
+    "checkpoint_directory = './training_checkpoints'\n",
+    "\n",
+    "if not os.path.exists(checkpoint_directory ):\n",
+    "    os.makedirs(checkpoint_directory)\n",
+    "    print(f'New directory created at $:->{checkpoint_directory}')\n",
+    "file_name =\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
+    "checkpoint_filename = os.path.join(checkpoint_directory, file_name)\n",
+    "checkpoint_callback = ModelCheckpoint(checkpoint_filename, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
+    "\n",
+    "callbacks_list = [checkpoint_callback, WandbCallback()]"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Train/Fit Model"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "wandb.config.epochs = 100\n",
+    "wandb.config.batch_size = 128\n",
+    "history = model1.fit(X, y, \n",
+    "                     validation_split=0.33, \n",
+    "                     batch_size=wandb.config.batch_size, \n",
+    "                     epochs=wandb.config.epochs, \n",
+    "                     callbacks=callbacks_list\n",
+    "                    )"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Plot Loss"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "plt.plot(history.history['loss'])\n",
+    "plt.title('Model loss')\n",
+    "plt.ylabel('Loss')\n",
+    "plt.xlabel('Epoch')\n",
+    "plt.legend(['Train'], loc='upper left')\n",
+    "plt.show()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
   {
    "cell_type": "code",
    "execution_count": null,
@@ -220,9 +386,9 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "U4-S3-DNN (Python 3.7)",
+   "display_name": "U4-S1-NLP (Python3)",
    "language": "python",
-   "name": "u4-s3-dnn"
+   "name": "u4-s1-nlp"
   },
   "language_info": {
    "codemirror_mode": {
diff --git a/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb b/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb
index ebd0297..8b31f1b 100644
--- a/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb
+++ b/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb
@@ -765,9 +765,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "U4-S3-DNN (Python 3.7)",
+   "display_name": "U4-S1-NLP (Python3)",
    "language": "python",
-   "name": "u4-s3-dnn"
+   "name": "u4-s1-nlp"
   },
   "language_info": {
    "codemirror_mode": {
