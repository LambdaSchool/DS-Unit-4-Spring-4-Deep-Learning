{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcs-lambda/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1LyK8v-z7CH",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a1a1a347-07ad-4604-ed4a-7b1db5cc4b3a"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZAUMQzM1J1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "b301923d-5427-48dc-d964-ae35695ff848"
      },
      "source": [
        "!wget https://www.gutenberg.org/files/100/100-0.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-23 20:23:24--  https://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5777367 (5.5M) [text/plain]\n",
            "Saving to: ‘100-0.txt’\n",
            "\n",
            "100-0.txt           100%[===================>]   5.51M   944KB/s    in 9.5s    \n",
            "\n",
            "2020-03-23 20:23:35 (591 KB/s) - ‘100-0.txt’ saved [5777367/5777367]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfSBJviu1YDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "fa25ac45-2365-46b9-90f1-0d230bd38ca7"
      },
      "source": [
        "!sed -nre '/^THE SONNETS/,/^THE END/p' 100-0.txt > sonnets_all.txt\n",
        "!sed -ire '1d;$d;' sonnets_all.txt\n",
        "!sed -nre '/^ALL’S WELL THAT ENDS WELL/,/^  FINIS/p' 100-0.txt > not_sonnets.txt\n",
        "!sed -ire '$d;' not_sonnets.txt\n",
        "!rm *.txtre\n",
        "!ls -la"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 11284\n",
            "drwxr-xr-x 1 root root    4096 Mar 23 20:35 .\n",
            "drwxr-xr-x 1 root root    4096 Mar 23 20:22 ..\n",
            "-rw-r--r-- 1 root root 5777367 Nov  7 13:05 100-0.txt\n",
            "drwxr-xr-x 1 root root    4096 Mar 20 16:17 .config\n",
            "drwxr-xr-x 2 root root    4096 Mar 23 20:32 .ipynb_checkpoints\n",
            "-rw-r--r-- 1 root root 5651002 Mar 23 20:35 not_sonnets.txt\n",
            "drwxr-xr-x 1 root root    4096 Mar 18 16:23 sample_data\n",
            "-rw-r--r-- 1 root root  101858 Mar 23 20:34 sonnets_all.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGADCqWbEZnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "9f9deb32-6fba-46a4-f62c-3f6269d4f6c3"
      },
      "source": [
        "!head sonnets_all.txt"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "                    1\r\n",
            "\r\n",
            "From fairest creatures we desire increase,\r\n",
            "That thereby beauty’s rose might never die,\r\n",
            "But as the riper should by time decease,\r\n",
            "His tender heir might bear his memory:\r\n",
            "But thou contracted to thine own bright eyes,\r\n",
            "Feed’st thy light’s flame with self-substantial fuel,\r\n",
            "Making a famine where abundance lies,\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODDg0bBAEZme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "988b7675-6948-41cf-8a0c-98e6a34a9030"
      },
      "source": [
        "!tail sonnets_all.txt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And so the general of hot desire,\r\n",
            "Was sleeping by a virgin hand disarmed.\r\n",
            "This brand she quenched in a cool well by,\r\n",
            "Which from Love’s fire took heat perpetual,\r\n",
            "Growing a bath and healthful remedy,\r\n",
            "For men discased, but I my mistress’ thrall,\r\n",
            "  Came there for cure and this by that I prove,\r\n",
            "  Love’s fire heats water, water cools not love.\r\n",
            "\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA_YnIoMEZjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "d8386d28-2575-4091-b6d3-1af4065d1a8c"
      },
      "source": [
        "!head not_sonnets.txt"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ALL’S WELL THAT ENDS WELL\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Contents\r\n",
            "\r\n",
            "ACT I\r\n",
            "Scene I. Rossillon. A room in the Countess’s palace.\r\n",
            "Scene II. Paris. A room in the King’s palace.\r\n",
            "Scene III. Rossillon. A Room in the Palace.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlpUpWfrEZK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "4c7a44ca-7c76-4a9c-facb-ad26a4b96a18"
      },
      "source": [
        "!tail not_sonnets.txt"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thus weary of the world, away she hies,             1189\r\n",
            "And yokes her silver doves; by whose swift aid\r\n",
            "Their mistress mounted through the empty skies,\r\n",
            "In her light chariot quickly is convey’d;           1192\r\n",
            "  Holding their course to Paphos, where their queen\r\n",
            "  Means to immure herself and not be seen.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NSMPykwEZGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR3d6KOPEZDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = ['sonnets_all.txt', 'not_sonnets.txt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avY5rMXiEY_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "67379f1d-2839-4e14-d517-c7c7cc5e4916"
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        print(file)\n",
        "        with open(f'./{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sonnets_all.txt\n",
            "not_sonnets.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oIk9gVTHFPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "31c84edf-b5c8-44f4-b6c9-3b79a5e29f4b"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JL9DodJHHFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySzN6ae2HHu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "2d28ab78-56d8-4f9d-b561-5b4b5703b248"
      },
      "source": [
        "print(len(chars), len(char_int), len(int_char))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 101 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vieGX1rHHo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "555bab15-d558-4cfb-ff58-6bf50ab915ba"
      },
      "source": [
        "print(chars)\n",
        "print(char_int)\n",
        "print(int_char)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['p', ':', 'z', '8', '*', '(', 'e', 'h', 'æ', 'D', '7', '1', '’', 'w', '”', 'y', ',', '`', 'n', '!', 'f', 'O', 'i', 'g', 'K', ')', 'W', 'â', 'S', 'r', 'A', 's', '-', 'è', 'q', 'œ', 'é', ';', 't', 'I', 'Æ', '\\t', '4', '?', 'ç', 'F', 'N', 'Q', 'R', '9', 'J', 'É', 'Y', '}', 'E', 'm', ' ', 'l', 'c', 'k', 'à', '‘', '2', '\\\\', \"'\", 'V', '.', 'u', 'H', 'G', 'P', '5', '&', 'X', 'C', 'x', 'U', '|', '6', 'Z', 'L', '\"', ']', 'B', '\\n', 'ê', '0', 'M', 'v', 'b', 'j', '—', 'T', 'd', 'î', 'o', '“', '[', 'a', '_', '3']\n",
            "{'p': 0, ':': 1, 'z': 2, '8': 3, '*': 4, '(': 5, 'e': 6, 'h': 7, 'æ': 8, 'D': 9, '7': 10, '1': 11, '’': 12, 'w': 13, '”': 14, 'y': 15, ',': 16, '`': 17, 'n': 18, '!': 19, 'f': 20, 'O': 21, 'i': 22, 'g': 23, 'K': 24, ')': 25, 'W': 26, 'â': 27, 'S': 28, 'r': 29, 'A': 30, 's': 31, '-': 32, 'è': 33, 'q': 34, 'œ': 35, 'é': 36, ';': 37, 't': 38, 'I': 39, 'Æ': 40, '\\t': 41, '4': 42, '?': 43, 'ç': 44, 'F': 45, 'N': 46, 'Q': 47, 'R': 48, '9': 49, 'J': 50, 'É': 51, 'Y': 52, '}': 53, 'E': 54, 'm': 55, ' ': 56, 'l': 57, 'c': 58, 'k': 59, 'à': 60, '‘': 61, '2': 62, '\\\\': 63, \"'\": 64, 'V': 65, '.': 66, 'u': 67, 'H': 68, 'G': 69, 'P': 70, '5': 71, '&': 72, 'X': 73, 'C': 74, 'x': 75, 'U': 76, '|': 77, '6': 78, 'Z': 79, 'L': 80, '\"': 81, ']': 82, 'B': 83, '\\n': 84, 'ê': 85, '0': 86, 'M': 87, 'v': 88, 'b': 89, 'j': 90, '—': 91, 'T': 92, 'd': 93, 'î': 94, 'o': 95, '“': 96, '[': 97, 'a': 98, '_': 99, '3': 100}\n",
            "{0: 'p', 1: ':', 2: 'z', 3: '8', 4: '*', 5: '(', 6: 'e', 7: 'h', 8: 'æ', 9: 'D', 10: '7', 11: '1', 12: '’', 13: 'w', 14: '”', 15: 'y', 16: ',', 17: '`', 18: 'n', 19: '!', 20: 'f', 21: 'O', 22: 'i', 23: 'g', 24: 'K', 25: ')', 26: 'W', 27: 'â', 28: 'S', 29: 'r', 30: 'A', 31: 's', 32: '-', 33: 'è', 34: 'q', 35: 'œ', 36: 'é', 37: ';', 38: 't', 39: 'I', 40: 'Æ', 41: '\\t', 42: '4', 43: '?', 44: 'ç', 45: 'F', 46: 'N', 47: 'Q', 48: 'R', 49: '9', 50: 'J', 51: 'É', 52: 'Y', 53: '}', 54: 'E', 55: 'm', 56: ' ', 57: 'l', 58: 'c', 59: 'k', 60: 'à', 61: '‘', 62: '2', 63: '\\\\', 64: \"'\", 65: 'V', 66: '.', 67: 'u', 68: 'H', 69: 'G', 70: 'P', 71: '5', 72: '&', 73: 'X', 74: 'C', 75: 'x', 76: 'U', 77: '|', 78: '6', 79: 'Z', 80: 'L', 81: '\"', 82: ']', 83: 'B', 84: '\\n', 85: 'ê', 86: '0', 87: 'M', 88: 'v', 89: 'b', 90: 'j', 91: '—', 92: 'T', 93: 'd', 94: 'î', 95: 'o', 96: '“', 97: '[', 98: 'a', 99: '_', 100: '3'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IzwmBMpHHmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "11ee66c3-f552-44cf-849b-db762c2a4958"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1109842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuZ2B-lOHJTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "22a3cf1d-c2f5-48eb-f1a2-6f2088e8e65f"
      },
      "source": [
        "print(sequences[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[84, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 11, 84, 84, 45, 29, 95, 55, 56, 20, 98, 22, 29, 6, 31, 38, 56, 58, 29, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_3gqEGaHJRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "91f3d6fc-5f45-4fcc-b30e-7b695804dad2"
      },
      "source": [
        "print([int_char[i] for i in sequences[0]])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '1', '\\n', '\\n', 'F', 'r', 'o', 'm', ' ', 'f', 'a', 'i', 'r', 'e', 's', 't', ' ', 'c', 'r', 'e']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5axInqmMHJKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRlvNpUUHJIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "2239bb8b-3caa-4c52-a961-495eb3f93687"
      },
      "source": [
        "print(x.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1109842, 40, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BozOazbxJfJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "a3695185-a376-476e-8d65-869146b44d0d"
      },
      "source": [
        "print(x[0].shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mT9SIoDHJGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "51eba00b-0868-453d-aaba-0593db125ccd"
      },
      "source": [
        "print(y.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1109842, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teFx4O5SHI8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=x[0].shape, dropout=.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djkniVJDHI69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# translate a prediction into a character (index of a character)\n",
        "\n",
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF9t9NXOHI5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw5c2lQQHIwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d0a8a0e-92f6-405c-d7a3-838c5242af39"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1109842 samples\n",
            "Epoch 1/10\n",
            "1109600/1109842 [============================>.] - ETA: 0s - loss: 2.2522 - accuracy: 0.3633\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"sh'd.\n",
            "  ANTONY. Make me not offended\n",
            "   \"\n",
            "sh'd.\n",
            "  ANTONY. Make me not offended\n",
            "    Think go never- adquestedyse neven Rock.     Preate oow ma holds hone\n",
            "And gentill his colline peobyting morey\n",
            "Te’ll nethen any you sleak I ant callecolas  wath dre surss.\n",
            "  KANG LBFFRESTERL. And to hele ereade bid not is a make erol:\n",
            "He as agionswac! weed be, was have Geady,\n",
            "To of twe karsuess sow path she wite to thou ste\n",
            "                         Entes eeele in loveee\n",
            "W\n",
            "    CIRITAUE. I how abwes\n",
            "1109842/1109842 [==============================] - 191s 172us/sample - loss: 2.2521 - accuracy: 0.3633\n",
            "Epoch 2/10\n",
            "1109824/1109842 [============================>.] - ETA: 0s - loss: 2.0137 - accuracy: 0.4180\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"s, and there have sat\n",
            "The livelong day w\"\n",
            "s, and there have sat\n",
            "The livelong day witr hemver-d dissiet the sectler! Woul wifl to wot friends for this go-glutot.\n",
            "O finnagh eye oo goint him I have mil?\n",
            "    Are ronque tow poor a lain, you say won,\n",
            "To the core a mar, come it dows, one your under soud spour sny,\n",
            "O fullo a peapes's befirth.\n",
            "\n",
            "BRACUSE.\n",
            "The heaven un anl of ly by thr pent de,\n",
            "What will scames, our caot a daling that God his mas untlay Jose,\n",
            "Highie hall.\n",
            "\n",
            "PYRE.\n",
            "Anser dol\n",
            "1109842/1109842 [==============================] - 183s 165us/sample - loss: 2.0137 - accuracy: 0.4179\n",
            "Epoch 3/10\n",
            "1109664/1109842 [============================>.] - ETA: 0s - loss: 1.9406 - accuracy: 0.4360\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \" foe;\n",
            "  While Collatine and his consorte\"\n",
            " foe;\n",
            "  While Collatine and his consorted seeps?\n",
            "\n",
            "SEROND\n",
            "SIS OLLEW.\n",
            "That a vanily\n",
            "and the whol on you, And Silbtinier Tosicran kes Frems\n",
            "And Gives as offidece bookehehant—r\n",
            "no- mishan,\n",
            "Agrowady and her fare unoir nather,\n",
            "Had toumathross bean you higged thinh a mal stalf\n",
            "To all there andif falls to and I mask, I ims,\n",
            "    And, fallo sluch in ore lia dack and your ling\n",
            "    Was fair hows orte, and tome mast'd do you\n",
            "de will an mines thou in\n",
            "1109842/1109842 [==============================] - 185s 167us/sample - loss: 1.9406 - accuracy: 0.4360\n",
            "Epoch 4/10\n",
            "1109568/1109842 [============================>.] - ETA: 0s - loss: 1.8994 - accuracy: 0.4472\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"t see\n",
            "Dick Surgeon, sot?\n",
            "\n",
            "CLOWN.\n",
            "O, he’s\"\n",
            "t see\n",
            "Dick Surgeon, sot?\n",
            "\n",
            "CLOWN.\n",
            "O, he’s be wall,\n",
            "Farly that his other, leny\n",
            "Am; ory merisenoner, Anton, by soming, and descratce\n",
            "Ot manneasaw housen mooks boar.\n",
            "\n",
            "VIRET.\n",
            "Descate me time he his acceided favion:    What him lords, might with men ruth of effry,\n",
            "    And father down.\n",
            "  ALY. I dr as theme heartwer on, hers on silgers; whein dear bew besians,\n",
            "    Brousing ruarms to ranure in a Forn!\n",
            "  PLINCE.\n",
            "I would you, not and dymerfor.\n",
            "THE\n",
            "1109842/1109842 [==============================] - 187s 169us/sample - loss: 1.8993 - accuracy: 0.4472\n",
            "Epoch 5/10\n",
            "1109824/1109842 [============================>.] - ETA: 0s - loss: 1.8723 - accuracy: 0.4539\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"ter.\n",
            "  PISTOL. I know you, Mistress Doro\"\n",
            "ter.\n",
            "  PISTOL. I know you, Mistress Dorous viliaine! Where Tosis, you.\n",
            "  WaRz'r powersh on it anr farene to know of ntse,\n",
            "    And friends to dren we wase weuld rine were whild;\n",
            "My lord buse he world to erfolm his that with othirt.\n",
            "\n",
            "LIAGOR\n",
            "Sa, it we will so brot, lord? Upon your paine and\n",
            "Stane of thus or that his basche, all bue in the, if the most goys,\n",
            "    Who, we give it yourng Aperces With a spounds,\n",
            "When like know my triaps his gra\n",
            "1109842/1109842 [==============================] - 187s 168us/sample - loss: 1.8723 - accuracy: 0.4539\n",
            "Epoch 6/10\n",
            "1109568/1109842 [============================>.] - ETA: 0s - loss: 1.8549 - accuracy: 0.4582\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"te, had stol’n of both,\n",
            "And to his robbe\"\n",
            "te, had stol’n of both,\n",
            "And to his robber! I see tested voirot\n",
            "Shall cam the day-hine the treasant Dusen, and tear, and here down to\n",
            "    Armesen for I wail of the sbrake dise,\n",
            "And lensexpacian again!\n",
            "\n",
            "KING. A lotes nor amowl, the ompine in mone; 'Tis welk for no give all;\n",
            "    That what blooder well a Exet shall see it.\n",
            "\n",
            "HELLE.\n",
            "I would dot my his sirf\n",
            "    When is my live feeld, incoarding from hand;\n",
            "In bur, fir if I heart ancontary ilur?\n",
            "1109842/1109842 [==============================] - 185s 167us/sample - loss: 1.8549 - accuracy: 0.4582\n",
            "Epoch 7/10\n",
            "1109824/1109842 [============================>.] - ETA: 0s - loss: 1.8398 - accuracy: 0.4626\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"li walls,\n",
            "    And made what work I pleas\"\n",
            "li walls,\n",
            "    And made what work I please him at in, in yourpell,\n",
            "And I am the fevers to not in he it deary.\n",
            "          Where bldes ser!\n",
            "\n",
            "\n",
            "      FORe'blow'd my chamm'd?\n",
            "       Enter CHANLER\n",
            "Nat cornant to the YONG  My sweet wast in findt;\n",
            "Unom be be place-did lives he take of the feht;\n",
            "My deeasynes of sheep Spparerat; aut you were stead;\n",
            "for closses her half if sight deach pold.\n",
            "To tendines, Plor and tho growid jesting wourd any,\n",
            "    Not\n",
            "1109842/1109842 [==============================] - 186s 167us/sample - loss: 1.8398 - accuracy: 0.4626\n",
            "Epoch 8/10\n",
            "1109824/1109842 [============================>.] - ETA: 0s - loss: 1.8299 - accuracy: 0.4657\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"his bad verses.\n",
            "\n",
            "CINNA.\n",
            "I am not Cinna t\"\n",
            "his bad verses.\n",
            "\n",
            "CINNA.\n",
            "I am not Cinna the Benoleny of Bebond\n",
            "The prassager, or Pooice\n",
            "    This fuitwey frow agine of she\n",
            "    And pabblerel keep three by devilly on\n",
            "    thbu had low.\n",
            "  KING RIDEELAR. These suchidgy be; call the first; and sertage,\n",
            "With no leasume,\n",
            "in devistulus applory at ond, neighows,\n",
            "     year to to mirs this dear prounty seedfus be in no moremalse theator;\n",
            "    To respid's true: hath no's seive ip, an\n",
            "    And find in\n",
            "1109842/1109842 [==============================] - 188s 170us/sample - loss: 1.8298 - accuracy: 0.4657\n",
            "Epoch 9/10\n",
            "1109504/1109842 [============================>.] - ETA: 0s - loss: 1.8195 - accuracy: 0.4682\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"at Greenwich,\n",
            "    After your Highness ha\"\n",
            "at Greenwich,\n",
            "    After your Highness harsor.\n",
            "  QUEEN MARGARET. [OARMAN. GArdo, in yours, brither she'll that brave,\n",
            "    A do the world lever shat'd in the hears\n",
            "'mme-efact.  [Rirenl.]\n",
            "  RUCHESPA.\n",
            "I will not by mon wo you the thoughts.\n",
            "    Now have heason presude?\n",
            "  ELENTER. Ay,\n",
            "d         Mons his fuild? Greating his life your godd,\n",
            "Ciliafer spurn of th’e foir ponsonio.\n",
            "I am death of hiddas; and for therefore\n",
            "    Take thou wilt nish? Po\n",
            "1109842/1109842 [==============================] - 193s 174us/sample - loss: 1.8194 - accuracy: 0.4682\n",
            "Epoch 10/10\n",
            "1109824/1109842 [============================>.] - ETA: 0s - loss: 1.8114 - accuracy: 0.4699\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"e of spirit in a waste of shame\n",
            "Is lust \"\n",
            "e of spirit in a waste of shame\n",
            "Is lust mend nor ese me bet ingune, marged\n",
            "    That first more to she pasfuld men in\n",
            "    than the misited from her whechol is prof,\n",
            "You that,—I will be neglince me me voie?\n",
            "\n",
            "FIRST CLIANTIT.\n",
            "My seithment, frueld, came her sheep.\n",
            "Om\n",
            "      His tinco my mal.\n",
            "           Exit\n",
            "  CUEIANO. For even as Boyct’s cours. Them, which is deldouth, Lo\n",
            "PRESTINGSAMATEN\n",
            "\n",
            "  The Bebidem and here what a cholans of no him.\n",
            "The w\n",
            "1109842/1109842 [==============================] - 192s 173us/sample - loss: 1.8114 - accuracy: 0.4699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2963f9160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weDtqjzOHIrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}