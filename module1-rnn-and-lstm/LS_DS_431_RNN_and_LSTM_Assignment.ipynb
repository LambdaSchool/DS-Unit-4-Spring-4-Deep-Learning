{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "maxlen = 80\n",
    "max_features = 20000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.gutenberg.org/files/100/100-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-17 01:28:11--  https://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5777367 (5.5M) [text/plain]\n",
      "Saving to: ‘100-0.txt’\n",
      "\n",
      "100-0.txt           100%[===================>]   5.51M  9.05MB/s    in 0.6s    \n",
      "\n",
      "2019-12-17 01:28:14 (9.05 MB/s) - ‘100-0.txt’ saved [5777367/5777367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.gutenberg.org/files/100/100-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get(url)\n",
    "data.encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode the data as characters\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 1148005\n"
     ]
    }
   ],
   "source": [
    "maxlen=32\n",
    "step=5\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Specify x & y\n",
    "\n",
    "#encoding the sequence data into numpy vectors\n",
    "\n",
    "#it is faster to update something than create it, so initializing with a 0's array set\n",
    "#creating 0 numpy arrays, len(sentances) length, and each array will have maxlen number of entries and the length of characters set.\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "\n",
    "#we are looping through all the sentance, preserving the id number i\n",
    "for i, sentence in enumerate(sentences):\n",
    "    #we are going to update each of those arrays, and preserve the location integerger of the character in that sequence t\n",
    "    for t, char in enumerate(sentence):\n",
    "        #we are appending the sentance id, the character location id and the actual character number and set that equal to 1\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        #taking the sentance id and passing the next character and setting it equal to 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1148005, 32, 108)\n",
      "(1148005, 108)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample function from lecture\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "1147904/1148005 [============================>.] - ETA: 0s - loss: 1.7293\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"elf;\n",
      "At whose conception, till \"\n",
      "elf;\n",
      "At whose conception, till the stand the sunce and this shall see thee and such the bear me the party the contention.\n",
      "                                                                                                                                                                                                                                                                                                                    \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"elf;\n",
      "At whose conception, till \"\n",
      "elf;\n",
      "At whose conception, till be made a bear of your drowers with with on her honour of your heart for thee.\n",
      "                                                                                      Exeunt Touss and Anotianio, which a parts.\n",
      "\n",
      "\n",
      "      Enter EDRANA. How down a monster thy batter shall contentle this sorrow had her father.\n",
      "                                                                                           \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"elf;\n",
      "At whose conception, till \"\n",
      "elf;\n",
      "At whose conception, till not legs texcem'd or sence,\n",
      "    Youth feares done of dy to fare ever\n",
      "Though thou rrwhick; but so donege.\n",
      "\n",
      "Where, any and sdocted, and did the poor greatthing none beseech\n",
      "\n",
      "  CARTARINE. I have unbed, The Nevening crook. That door that her remen! provey, may speaks, long may ton. Th' gover\n",
      "As who marring. Soo me Egyperts.\n",
      "Bind not arroast; so it pleasure.\n",
      "    O. Thou are faverest like recor\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"elf;\n",
      "At whose conception, till \"\n",
      "elf;\n",
      "At whose conception, till 'tar! 'Thory, comes: suce moath, I !\n",
      "    Be coon, but carts. From brao'st blact\n",
      "      Ever life. Atele thy ssorn it lils.\n",
      "  'With hower; Is their gliccan if wich seed;\n",
      "A rugely, all che. my shigh plessing day\n",
      "As it gold is unfer'd, wh you dreading.\n",
      "My very broking, done, instangeneb'd, and to they within Martiny.\n",
      "  ARgATH. Hound all brow, Attendent._]\n",
      "\n",
      "BAUEDER.\n",
      "But,\n",
      "    Nor up of dever.\n",
      "1148005/1148005 [==============================] - 661s 576us/sample - loss: 1.7293\n",
      "Epoch 2/5\n",
      "1147904/1148005 [============================>.] - ETA: 0s - loss: 1.5667\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ures\n",
      "Could not abide to be with\"\n",
      "ures\n",
      "Could not abide to be with the seas.\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ures\n",
      "Could not abide to be with\"\n",
      "ures\n",
      "Could not abide to be with her survice,\n",
      "So see the see will stay the bear,\n",
      "    Not the praction be man will strain me?\n",
      "\n",
      " Re-enter And Lord is of first of the worlder of a word will be my lord\n",
      "    And she come to your salt and take,\n",
      "    The love of person of contern of the\n",
      "                                                                                                                                                  \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ures\n",
      "Could not abide to be with\"\n",
      "ures\n",
      "Could not abide to be with perets.\n",
      "\n",
      "GENTLEMAN.\n",
      "Le! Nifther is I would, with that will play me.\n",
      "\n",
      "ANCEMON.\n",
      "Master is keep to me, then will in the feed, that yous guid:\n",
      "Tame 'tis cillent, where must stee the to the barded\n",
      "haws Whit, rate, I come and bid the trinder.\n",
      "She would repoop here.\n",
      "\n",
      "GENTLEMUES\n",
      "  LADY OF NUSTESS\n",
      "  KING MARGART. Ay, wherefore lant par the bidle. commantser, be serve totherer all a hapglasion\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ures\n",
      "Could not abide to be with\"\n",
      "ures\n",
      "Could not abide to be with Crintsdongnes Luclo.\n",
      "   I will? I\n",
      "But this partaant free Mort anclesond\n",
      "Herev'd in the Ficer Uhjeba, will not se\n",
      "Country have not gentleman poorue, not dangry.\n",
      "\n",
      "ORFANN.\n",
      "He were condonow and jotueture down with chart.\n",
      "\n",
      "LEONT.\n",
      "To\n",
      "    I’ll le were palsag’d the lift or that,\n",
      "In besearn it ono Clar'd-,\n",
      "Cike all tetcly Toldauron\n",
      "How fearlingly 't’s boe Reachol, music.\n",
      "\n",
      "ISAMUS.\n",
      "I an at \n",
      "1148005/1148005 [==============================] - 611s 532us/sample - loss: 1.5667\n",
      "Epoch 3/5\n",
      "1147904/1148005 [============================>.] - ETA: 0s - loss: 1.6158\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" speech, my lord,\n",
      "With almost a\"\n",
      " speech, my lord,\n",
      "With almost and the change the great than the stard,\n",
      "    That shall be thou stores and the world.\n",
      "    The will the store the grace and be that shall be so the straight to my stronged the great to the of the straight the great and that he was that he will not the good the strange that I see the father,\n",
      "    That is the street the strange of the counts and the straight to love the state the great and thou stra\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" speech, my lord,\n",
      "With almost a\"\n",
      " speech, my lord,\n",
      "With almost and peace and monster.\n",
      "                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" speech, my lord,\n",
      "With almost a\"\n",
      " speech, my lord,\n",
      "With almost againwut pair a Ipod's of host.\n",
      "\n",
      "RICNATANTOM.                                                                                                                             anot hire,   miscal should as by I, give my voach and traitor in no pprehens hither;\n",
      "Such aehctian and father, of outsed probmarion,\n",
      "But estory in me as seen our palence as is I persers.\n",
      "  KINGE. Gitter sped was supendoth it o\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" speech, my lord,\n",
      "With almost a\"\n",
      " speech, my lord,\n",
      "With almost amentde! [Aside fairing?\n",
      "\n",
      "Asturnedre?\n",
      "\n",
      "wirt id my opidedages, Steas, fall such needs and you shall doubt ay se. for health,\n",
      "Mour end, wors.\n",
      "\n",
      "  then,\n",
      "Lady! Sleep? I come, beside my Satbokco all fiend\n",
      "Wherice halu in s, Lorinnied’s unceansaby is garne and unbhe's celcos prameves in to fiendgall’d,\n",
      "    Bearles mowed; lold in you: loogledle, and train thundik  we true, from this purpety-celar\n",
      "1148005/1148005 [==============================] - 610s 531us/sample - loss: 1.6157\n",
      "Epoch 4/5\n",
      "1147904/1148005 [============================>.] - ETA: 0s - loss: 8.1827\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", you indicate that you have rea\"\n",
      "  you indicate that you have reanp,eert"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " o .w, hemne wKlhathlende e\n",
      "tol phathlor mooe ,nhl.\n",
      " ,fon.U k N  Aor\n",
      " , me pthemy molhpes, pr an   Sn,nOnen\n",
      "\n",
      "sarevt Ak myoulal.nce   PfAneE  A l ,el,’'le.s\n",
      " w.ol h' Aory DahedandereHe netIw mo mer Can\n",
      "l: delI,El.\n",
      "sav, IDds, wyNof otceId   an ’y?a N,noMlney  hel,k lhavte Uefn,Lee dH', Sondeereaeyor te  lyge ahewshere r l ntet  y toenhloulaet teerenrem D, hs m.on\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", you indicate that you have rea\"\n",
      ", you indicate that you have reange  y mharo,gande U th ynounonLdhuErende cevhuto asrtnhor  thlh  ffrelv crtt  ;ue\n",
      "hkeefeR,mhoemieknw,ay n re of f nwrIhly ,heli\n",
      "r\n",
      " w \n",
      "e tta\n",
      "lees,nenther no  gEAl g.thuth,thr  Ea dre nokyihersteree thleMuo dolleey tehndeeRethleye cathe enc werewEOngehba thr nhac wor oi Eoure ewthoeyoManhuy Moon,\n",
      "nrelder ngye Oatheree ho  moman Uv\n",
      "sw'y e  nhlheesEee n, thuden,LeRhe  ppr asnethhs\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", you indicate that you have rea\"\n",
      ", you indicate that you have reatpE oinatre.\n",
      "omea nonede r ree  thacoeran\n",
      "uonb\n",
      "SOv, hmey Awuem. tha tente\n",
      "n. uenind thoWEne\n",
      "SnUhnthuereue dve  ,\n",
      "enthlyete  d gHeryoo,n E bortkden,a\n",
      "arihy\n",
      "nyI s,nsl  t  uohake   s  hee O '  \n",
      "aer'k ,she domet Thy erIp llu hynk.nhyeiESaf iuf Eiluooct\n",
      "n;elly\n",
      "  meItnrkaon deotene niesi y thuyofrHurunheoti e. lhuIIe\n",
      "souy.Ms,we U Nwr,epre cnroha s N,l,foleme\n",
      ".ks;'kge yishapreayse arooce\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \", you indicate that you have rea\"\n",
      "r you indicate that you have rearf ar thlathnereou dersr\n",
      ",rlllerurgn mhatpanha  enI Shsden mthet) geiOyer eroTloatall henneaMoa gimeu P asthllohpe\n",
      "rmr ,aiers,oirihtenii Aothey feter.in wtmrgue m yosthedolenpr\n",
      " Frinhnsthorthyk, thian  w rno  odardeo\n",
      "EaYamaaAun deer a eas.,land.\n",
      "eidosns'e\n",
      "KComdethspyerh,  eldeI dphllahpor diAokkk g ccoteriure e sisphteyoe .M\n",
      "msandaweneonHh aS.AarP peyflhen yoa'hu\n",
      "msn ceIey EF I yy \n",
      "1148005/1148005 [==============================] - 614s 535us/sample - loss: 8.1830\n",
      "Epoch 5/5\n",
      "1147904/1148005 [============================>.] - ETA: 0s - loss: 7.8973\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rce\n",
      "show his head on the Rialto\"\n",
      "rce\n",
      "show his head on the Rialto\n",
      "         tee e q \n",
      "   b   WAvNQe    we            te Le   LA Wer\n",
      " pe t   fee we the e ee   t       oun    Op   pe eAee S    ; p t kwee  ee we t   o       Wqthele Ike\n",
      " peN  be pIL   bte\n",
      " pe e    t b he    we Ne  W   ber      b e      O  fe   u  be W Oespe tke   F Whe  Se   se p    b  \n",
      "  LAe p j  pe      WAve   s   IN b   heelen b   s  he  We  b  Ie we    IN  NTIe  We  Wne fe  We the   W    b \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rce\n",
      "show his head on the Rialto\"\n",
      "rce\n",
      "show his head on the Rialto\n",
      "Steet woen     t   W  t ou  pe per S  WAeApe wee i Cd t t thakpee  te  in I       t  wen  i\n",
      "  ne  LOA  e    tenE b      b       fReeN    b cht w he int  s    C WeRe pe    tnOher\n",
      " I  tse th]  ;  phU\n",
      " t te w \n",
      "    bene pe t pZp     fouIs;  henere  Q sER\n",
      "Cesot   e \n",
      " heeQ  in et  S we w t ksfSeeree Hee pe    t;  Woes   fe \n",
      "eAe  aNe th e  IN R  w tes e ke     Wepe“ in tne we peTr inSoee  tY\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rce\n",
      "show his head on the Rialto\"\n",
      "rce\n",
      "show his head on the Rialtowaeedlee o  pie t athCot h yeherlhe QgSiHd Ie\n",
      "eraen  s weshhones th \n",
      "tnh t'nt y ndlhessstye m   eo\n",
      " pe  i\n",
      "Dy  \n",
      "t oneite t eRhLoum.eotset poeena, d  tespr wer\n",
      "hpt v   wetir s   nt b B\n",
      "o\n",
      "s i\n",
      "et y s     e enm sn ert bey tothitth oaaetetse yer  s se f r \n",
      " hA Fo\n",
      " fen\n",
      "aN  aAda  ger ehle iAneleloth  whete titkeslk ttt    eN ,\n",
      "roN. euo ee hWdetbhcenae, no  Zar reeRs  ere r   s   bse    \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rce\n",
      "show his head on the Rialto\"\n",
      "rce\n",
      "nhow his head on the Rialtowit der oateosler nen ss pesse fw  o\n",
      "u ep h \n",
      "ee  Rree ahL  WosUuh ike.leeppIsely\n",
      " s ohynen;yoss  oe weamtler snr  aibe\n",
      "R \n",
      "eo\n",
      " erumesesm ee\n",
      "e s \n",
      "Are \n",
      "wGI w teha Ihnllee e   vivil pOss tIinYeeer whriwilesofeisn.thetDo \n",
      "feeelmse pulspy  sbor   cd.ee ,es edrern eigwot c hip ooh pyW ns O eees,t nerrtea seave   i\n",
      "tAvife e,seNste  a!e es Wierls  w.\n",
      "l, h cee\n",
      "hito’s  buar    yd an ehel\n",
      "1148005/1148005 [==============================] - 610s 532us/sample - loss: 7.8971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f941dafc5c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "         epochs=5,\n",
    "         callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
