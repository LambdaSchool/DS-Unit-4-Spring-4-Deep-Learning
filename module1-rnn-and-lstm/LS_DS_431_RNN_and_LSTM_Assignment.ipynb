{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "shakespeare_url = \"https://www.gutenberg.org/files/100/100-0.txt\" \n",
    "filepath = get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath, encoding=\"utf8\") as f:\n",
    "    shakespeare_text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True, lower=False)\n",
    "tokenizer.fit_on_texts([shakespeare_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "chars = list(set(tokenizer.word_index))\n",
    "\n",
    "char_indices = {c:i for i,c in enumerate(chars)}\n",
    "indices_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 1114611\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequence Data\n",
    "maxlen = 100\n",
    "step = 5\n",
    "\n",
    "sequences = [] # Each element is 40 characters long\n",
    "next_chars = [] # One element for each sequence\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "print('sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114611, 100, 107)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114611, 107)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build the model: a single LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(shakespeare_text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = shakespeare_text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0127 14:28:46.149579 20360 deprecation.py:323] From C:\\Users\\Elina\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "199936/200000 [============================>.] - ETA: 0s - loss: 2.7092\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ll do't.                                \"\n",
      "ll do't.                                5333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ll do't.                                \"\n",
      "ll do't.                                5333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ll do't.                                \"\n",
      "ll do't.                                3Q932BZ3e2*Z3 5D29Voè!P33,âB3T2è\"*,%Z—3ê\"2ê3B23!Pê*Kê32*èV 5i3n,BèPe*Z3nâê*3GP*39PeV6—3o*a*53333\"23ê\"P3,G,UQ3âP!%3KPU*3*â2B,Z3âv29—3Peo3!2U,B*ZA5533iM,BZ3Z372n,P*o32K*93!2*,oU* 5iB3\"2n3eU*B—553to3ê,Z39Peèè*T*—3Z*Kêa*—5æiB'\"*3oêPê*a*,Bè*3PPPo3Pâ*oê,Bê\"PBZ3ê,ç5'\"9*ê—3EK*3ZPn—3n3!*26Z,2oZD 55'Mt*;iu 5D,M3o39PK3n*ê2B3ê\"2ê2ê\"P!*32B*B6â 3&3BPK*K,6K 5iPe3ê\"322U*3Z*!*K—5iBZ32*K—3K\"*ê533&\"* 5â3,T,ê3!2o3Pe3\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ll do't.                                \"\n",
      "ll do't.                                5œt!,ê\"*O35333'\"*3QPKP!UP3&v2U*3nPê,Ueâç3ê\"*3G*â93F*n93ZK2BQ,âZ3393,9932Z 5iBQ,Z3!2To**o3\"* 533_\titæM'*3ioê\",ê%3UêPeo2ââT,êY*o—3n,!n32Bè3Pv,v,,2—3ê32K3ê\"eo3Z2n,ê3\"*2è;ê53'PK*èZ3év3U2ZP6B\n",
      "n,2â933*393?,œ3n2*êv3\n",
      "v3U9Pe—3É,UQ,U*32vZ3'\"2U9B*KGâBQ*3ê2ToeB\"*K33\",G*o—5iK93\"Gê**âââê\"2ê\"2Ke—523œ&Geoèâ,BO3êPTK32,!$3v23,72KQ932,ê3&\",â,o\"ê*3EP!ç5235\"O33\"*âPBê32eB\"2ââv*o%,B—ê\"2oZ31é*23!,âeZ—3n2B* 53,Qâ\n",
      "MT2ê\"3BP\n",
      "200000/200000 [==============================] - 172s 859us/sample - loss: 2.7091\n",
      "Epoch 2/5\n",
      "199936/200000 [============================>.] - ETA: 0s - loss: 2.1958\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are made\"\n",
      "e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are madeB3ê\"*3ê\"*3ê\"*3ê\"*3\"*K*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3!*K*B3ê\"*3\"2ê3ê\"*3o\"2BZ3ê\"*3ê\"*3ê\"*3ê\"*3!*oê3ê\"*3ê\"*3o2K*3!2Bê32BZ3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3n,ê\"3ê\"*3\"*3\"*K3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3oêPK3ê\"*3ê\"*3ê\"*3!*3ê\"*3ê\"*3ê\"*3o\"*K3ê\"*3ê\"*3o\"*K3ê\"*3ê\"*3ê\"*3ê\"*3oPK*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3UPBZ3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3ê\"*3o*K*o3ê\"*3o*K*o3ê\"*3ê\"*3ê\"*3oêPK*3ê\"*3UPBZ3ê\"*\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are made\"\n",
      "e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are madeK3oP3K,Bê 5531MXœÉÉ 3œ3ê\"*3\"*K*3oP!3ê\"2ê3ê\"*3U*K*K*o32BZ3Pv3ê\"*32BZ3Pv3G*2ê3UPBZoê3\",Bè32BZ3ê\"*3ê\"*K3,B3ê\"*3ê\"*3ê\"*3\"*3ê\"2ê3\"*3U\",o32ê3!2ê*BPeoo3Pv3!*3ê\",o3ê\"*3o*âPK*K3,B3ê\"*3Q*Kê3Pv32BZ32BZ3ê\"*3UPK*3\"*3ê\"*3ê\"*3BPeK32BZ3ê\"*3ê\"*3\"PK3ê\"*3n,ââ3oPn3!*o32BZ3n\"*o3ê\",!3UPBè*Bê3œ3o*KZ*oê3PB3ê\"*3n*K,Bè* 533EÉXiæ__1 3tP3\"Pe3\",B39Pe3G*Z3ê\"*3oeK*—3n,Q*3BP3GPBè*—3œ3BPeê3ê\"*3\"2ê3,B32B3ê\"*3ê\"*3!*K*o53333&\"Pe3\"2B\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are made\"\n",
      "e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are madeo3PBP3o,!,Bè6ê32Bè\"*Z3êe*3oPê3,ê\"*3n,ââ53333œBZ3oâ2BZoê3GKPa* 533\t_MuM;tM 3œê3Peâ3!2B2ZUBè,â9 3\tPn,ê\"93œ3\n",
      "v3K*â,è*3UPUâ6Z 533iB 3v2Bê—53333]Pe!3nPââ3\"2ê3\"*3K,èo*53333n*K*3!!2n3YPâG*ê3,Kê3ê\"Pt533'\"P3ê\"*K3,!3ovPeK5333BP!o32b*3èPbè2BZ6â56B3UPê\"\n",
      "3\"*3U,PBo3ê\",Z3?2_,B3\"*Beoê3Z*Kê\"*3!2a*A5iBZ\"*K,!3,â!5êP3UPBè*Bo32ê\"Pv3\"2eo32âê3Pv3v,2âZ3o*3ê\"932ê\"3ê*3UKPZoê6ê3*K*B*3ê\",!o—5'\"*n3\"939Pe3!Pa*3oê2KU*3êP3!,v*32\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are made\"\n",
      "e, sit on me.\n",
      "\n",
      "KATHERINA.\n",
      "Asses are madeBY,o,GZ3ÉK3v3ê2﻿—37,Za,Bê\n",
      "3oiââ,T\",è 33333\tê*,!3êâ2a*3%3,èQ,o3œo39PK*v 5*o3,B3\"P3v,!|P3ZP3o,àPêK3Z2aê*93\",aPê—3!2v22a*3Bê,Bè3PB!2BvK2Bç3DPeB—3\"93333333!,KZ,Bç5É\n",
      "Z3eBZ3T\",êv3\"*!*3\"*BBPGBQ9323G*BPeK3!2Bè*ç3'\"2Z3UPB 3iBê32BZ3GK2*!533æœ1è 5EeG*d|PeBè 3?i?9$533333333333333333333333']**3EM\t1MXÉJî3n93oâPâ*,v3n,,vO3âPc—39PeKo*3UP3UPeKè*Z3B60â2Ue 53333œ,U\"6B3âPê3,Bç3œBZ3PBZ3n,ê\"*âu3è;2Bn2â6o—3iBZ3o9,o*v*KO\n",
      "200000/200000 [==============================] - 181s 905us/sample - loss: 2.1957\n",
      "Epoch 3/5\n",
      "199936/200000 [============================>.] - ETA: 0s - loss: 1.9470\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"tinues; the Britons fly; Cymbeline is ta\"\n",
      "tinues; the Britons fly; Cymbeline is ta*K3ê\"*3TKP!*3ê\"*3U2Bê*K3o\"2ê3ê\"*3U2Bê*Ko3o\"2ê\"*K3vPK3\"*K*3o*K*3ê\"*3è2ê*o3Pv3ê\"*3TK2ê*K*o3oê*K3\"*K3ê\"*3èPê3ê\"*3UPeBZ—53333'\"*3ê\"2ê3ê\"*3èPê3ê\"*3TK2Bê*K32BZ3ê\"*3TK*2ê3ê\"*3n*K*3ê\"*3\"*K3ê\"*3G*2ââ*Z3ê\"*3TK*2ê*3ê\"*3o*K*o3ê\"*3\"2a*3ê\"*3TK2,B3ê\"*3\"2a*3ê\"*3U2BZ*K3oê2K*3ê\"*3è*2Bê*Ko32BZ3\",o3ê\"*3\"*K3ê\"*3n,ê\"3o\"2ê\"32BZ3ê\"*3èKPBè*o3\"*K3o\"2BZ3ê\"*3èKPBè*Z3Pv3ê\"*3èPê\"*K3PB3ê\"*3o*2Ko3ê\"*3o2K*3ê\"*3èKPBè*Z3ê\"*3èKPBê*K\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tinues; the Britons fly; Cymbeline is ta\"\n",
      "tinues; the Britons fly; Cymbeline is ta*K3\"*K3a,oê*K3oê**o3!*3vK**o3ê\"*3èKPBè*—53333Eeê3Pv3n\"*B3Z,o323vK**3ê\"*3TK,Bè3ê\"Pe3oPK*3ê\"*3vPK3,B3ê\"*3UP,Bè3,B3ê\"*3èK,Bè3êP3êP3ê\",o3!*oê53333'\"*3n*ââ3\"2oê*â3ê\"*33T*K,oo32BZ3êP3!*Bê*Ko—53333'\",B3o\"*K*3,B3ê\"*3nPKZ32BZ3\"*3!2B*3UPB*o—53333'\"*3T*ââ293o,Bè*K3,B3œ3Z,o32BZ3eBZ3TK*2Q32o3,BZ*K3\"*K3Pv32BZ3ê\"*3ê\"*3ê\"*3n2êâ*—53333iBZ3ê\",!3!2oê*K3ê\"Pe3G*2ê3o,B3ê\"93n,ââ3,B3ê\"2ê3\"*K3ê\"*3èPê3\"*K3TPK*32BZ3G*3UPB*o\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"tinues; the Britons fly; Cymbeline is ta\"\n",
      "tinues; the Britons fly; Cymbeline is ta,B3PP3!2â93U\"*B3PK3nPKêK*—3ê\"*%3n\"*6Z3œ3!2êê—5ÉK33nPnBB93\"2Q*3ê\"*n$3Pv3UPBèeêeK,Bè51\"2B3UP!3T2,Boê$3vK**oè2Ko*—3B,ê\"*ê,BèPvvoêo3ê\"*3è*K*o—32BZ3o*2oêBP2o3vPK5io*32BZ3\"93o2ê3o2â3n\"*K—39PeK3ê\"*3a*K93oeB3!2oêK,oPBPPâ 55\t?œœœ1 5'P—3?Po*K,Pn%3Z,!3oPBZ3\",ê—3*B 3œ3ZP3TeKêo3PeK3êP3ê2ê2Z3ê\",o3êP3o,ê 553\tæM1M—3iXæœ] 3]*ê3ê\"*3o\"**3G93n2ââ39Pe3êP3\"*3n\",BQ—53333œê3n,B—3,o3êP3ê\"*Bè6oê3GPv*3n\"93Keè*%533331*B*BB*Z\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"tinues; the Britons fly; Cymbeline is ta\"\n",
      "tinues; the Britons fly; Cymbeline is ta*K 37V''Mæ;M\t 3tP! 3èPê3â9ê93Pââ2Zoo3n,ê\"3U2ê\"Pç3vâ*93!2oo53333D2ê\"323QB2ê\"PeêZ 3iBè*Ko3ê\"2,è\"ê 3D*3K*è*KKèeBè5(K*Tâ,o3n*K3n\"P*âZ3GK*2Tê3êP3ê\"93Z2êèUeèO3YeT%53333)*T*BZBZoêK*\n",
      "oZ3,B3U*o3Z*2Z3n,ê\"*oçVA55œ_àMt'M 5ê\"3ê\"2o3è*2êOO55'œxMt 5&*3T 3EMn_MXt2ê$39Pe|Y*o3PT3\"*2âQ*Z—32B3293èP!Z3PB,Bè*oo3o2,âoo533MGQXit(É(œÉæœ_Mt5133OàœMb1—3G*œB3K*,T2Z,eè%3vâ*3*BU,Bv3T,B3êP3eKZ6oê39PeK*3eââ,Poo6Z5)*Boê,Pâ9—3ê\"*3Q\n",
      "200000/200000 [==============================] - 182s 908us/sample - loss: 1.9471\n",
      "Epoch 5/5\n",
      " 42752/200000 [=====>........................] - ETA: 2:27 - loss: 1.8937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P6\"ç55é31ÉàX1i'X' 5'\"6332K,PQ*â2B3!*3âPa*v3ê\"*32,v,â—3èPâZoê*Z32BZ%3G*Pooo3B2ê9—5&\"*K*o%3ê\",B*3ê\"*3!2ye*Z3o2a*3\"2ê33ê*â*3Bèoe—5iKPBeKB3n2ê\"3,o3o\"*n—53333iBZ3UKPeè 33333&,ê\"3eâ,è\"—3œ3v*2â$o3!*â*39K\n",
      "200000/200000 [==============================] - 186s 931us/sample - loss: 1.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2389542df88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x[:200000], y[:200000],\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
