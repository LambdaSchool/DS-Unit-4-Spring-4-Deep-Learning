{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Important Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating streamlined function for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = 'shakespeare_plays.txt'\n",
    "sonnets = 'shakespeare_sonnets.txt'\n",
    "full_text = 'shakespeare_full.txt'\n",
    "\n",
    "# Setting up function for streamlined processing\n",
    "def process_text(input_text):\n",
    "    \"\"\"Opens and processes text to be ready for model fitting\"\"\"\n",
    "\n",
    "    # Import and encoding\n",
    "    response = requests.get(input_text)\n",
    "    text = response.text\n",
    "    response.encoding = 'utf-8'\n",
    "    # len(text) # For debugging\n",
    "\n",
    "    # Encoding data as chars\n",
    "    chars = list(set(text))\n",
    "    char_int = {c:i for i, c in enumerate(chars)}\n",
    "    int_char = {i:c for i, c in enumerate(chars)}\n",
    "\n",
    "    # Create the Sequence Data\n",
    "    maxlen = 40\n",
    "    step = 5\n",
    "    encoded = [char_int[c] for c in text]\n",
    "    sequences = [] # Each element is 40 characters long\n",
    "    next_chars = [] # One element for each sequence\n",
    "    for i in range(0, len(encoded) - maxlen, step):\n",
    "        sequences.append(encoded[i : i + maxlen])\n",
    "        next_chars.append(encoded[i + maxlen])\n",
    "    # print('sequences:', len(sequences)) # For debugging\n",
    "\n",
    "    # Specify x & y\n",
    "    x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[i, t, char] = 1\n",
    "        y[i, next_chars[i]] = 1\n",
    "    # print(x.shape, y.shape) # For debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\" Prints generated text one char at a time for each epoch on trained data\"\"\"\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 0.7, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_int[char]] = 1\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = int_char[next_index]\n",
    "            # print(\"next_char: \" + next_char)\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "            # print(\"sentence[1:]: \" + sentence[1:])\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            # sys.stdout.flush() # This is bugging, not adding any spaces\n",
    "        print()\n",
    "\n",
    "def run_model():\n",
    "    # Instantiate and fit the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')  \n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    model.fit(x, y, batch_size=128, epochs=5, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating text from all works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 1155466 samples\nEpoch 1/5\n1155456/1155466 [============================>.] - ETA: 0s - loss: 2.1140\n----- Generating text after Epoch: 0\n----- diversity: 0.2\n----- Generating with seed: \" this fellow.âWhose graveâs this, si\"\n this fellow.âWhose graveâs this, sir mad the prove thefor the may the sing of the porter thebeare the will herthe will the porderand the prisele to the beart of the tothe for the for the may so mand\n    And the will the will the wordthe mant of the prownes\n  And theprood thecome the beat of a more the made the madse\n    And the bear the some the will his willthe beart and her the pray the some\n  The wher the sond t\n----- diversity: 0.5\n----- Generating with seed: \" this fellow.âWhose graveâs this, si\"\n this fellow.âWhose graveâs this, sit you have the will bit the prate.\n   He to me lood of the bothmy to king to his a paine\n  And the lord youa bast should of the in with of the rime.\n    The that in the and the are the will fard.\n    The sir it to athis fornot in pore the and the comed the word,\n    Andhe it is for collone the have the stare the mant\n    Andwith the good the wall chaster be bearter\n    The of this \n----- diversity: 1.0\n----- Generating with seed: \" this fellow.âWhose graveâs this, si\"\n this fellow.âWhose graveâs this, sim-sor.\n\n\n         [KEn he But MOUY] Pars, pilling you youhaed,\nInt do me love predordkend, andthee\nTe piteel Reme, your heakn so, wenten thy\nAth of issbip! Frenge ol And the earming!\nYom moveld hilh to with be land did and toor\n    Hond, inssionlove groith rucou;\nAnd to nat a packinow.\n    Hop prat lither bodind yoy sake.\nTo dideoul I saiss to dimenisedtiod,\n    Or that I d\n----- diversity: 1.2\n----- Generating with seed: \" this fellow.âWhose graveâs this, si\"\n this fellow.âWhose graveâs this, sip; and He, I hevilu\nSperge's dight-da doje, in thit hame ello.\n\nAMA.\nA timentarns ye cender,\nThis as ananLy,yor what hyow. it ever-Frymy:\nNove aclits blore it raintl ant be dey, Oy my pre;\nTheu hef thigwtld slows allupboth myporswiue,wain.\n\nCaEn tG, MI\n       7pealn knowd my nisue vilak, sur mim.\n\nQRENAN|ANSTROMOB\nEL ROPANZRDERSGES\nTEThU ForCoEndlat\n gook\nAed math stally mid\n1155466/1155466 [==============================] - 483s 418us/sample - loss: 2.1140\nEpoch 2/5\n1155456/1155466 [============================>.] - ETA: 0s - loss: 1.7828\n----- Generating text after Epoch: 1\n----- diversity: 0.2\n----- Generating with seed: \"ld can make me joy.\n    Life is as tedi\"\nld can make me joy.\n    Life is as tedingthe chainesthe starnthesing\nAndthebut theconfort inthe ravethe mands,\n    Andthe promethe will inthe the stand tome the seadthe grace the haveso dound\n   That when thewill thepray the goodthe stand\n    The stand the stain ofthe stand the stand\n    Andso more my lord withmy lordto my havethe content of themander here the tandof the will shallshall thegood the \n----- diversity: 0.5\n----- Generating with seed: \"ld can make me joy.\n    Life is as tedi\"\nld can make me joy.\n    Life is as tedichand mycounders,and is the steakingwith my lond me.\nAnd life the haveme the reast so but the forther.\n    Tome the right of theParguanthat wellpair of thee.\nWhich shall mecountersthe all inthethat,thepare so your saint of thestard.\n  Sochank andmayshow you the ferestthinge\n  And with a strough, thouhave mayconten and your searand willamoness,\n    Andmy \n----- diversity: 1.0\n----- Generating with seed: \"ld can make me joy.\n    Life is as tedi\"\nld can make me joy.\n    Life is as tediet onyours notmy hones lathal not; pray acsweft\n    Tomuttervolfers. That our plopeny.\n\nQUEDUS.\nSuce faried:truf fornce saviseto say.\n   That'dseaphish,and stawcher here tonite\nThat sib mysases of fear houk,with hoveand fathere ald no\n I abang distingofforturas you hingeds,\nOrchusmy sormandsMlatstike.\n\n[_Exeunted aLas, nither. Heard and, the Mpligs thee, fallust firtus\n----- diversity: 1.2\n----- Generating with seed: \"ld can make me joy.\n    Life is as tedi\"\nld can make me joy.\n    Life is as tedill:âung, insopt I will!\nYou, tIt thus, in;\nWhoid lief I vape us is reivge ot:\nWor-wirly of wenive brithe.\nTo hobles; struaute\n loor. SoS, wooedus peroth\nUpungly seppatited,,bilgveil Kingmed? âTis ofelenabt\nons candosoomtheybwast whitunces!,\n   To in you todgunt' I mustand itstert gobl.\n    Kenbugubatomencemplausextel, alls: d'drife:\nWhere with madingsold swalup! âtyin,\n\n1155466/1155466 [==============================] - 476s 412us/sample - loss: 1.7828\nEpoch 3/5\n1155456/1155466 [============================>.] - ETA: 0s - loss: 1.6725\n----- Generating text after Epoch: 2\n----- diversity: 0.2\n----- Generating with seed: \".\n\nMERCUTIO.\nThy wit is a very bitter\"\n.\n\nMERCUTIO.\nThy wit is a very bitter the man thecourted the sir,\n Andthetall the wark themanthe stadethe sirse the sir,\nAnd themore thepresent thestadethe sender\nThe man thething thesent the stracethe mander.\n\n [_Exit the Kingthe King his partion thestade\n  Thewill the seed the strancethe counterthe send\n  Andthe stadethe sentthe beartthe canser,\n  And theman the stake thestade thesi\n----- diversity: 0.5\n----- Generating with seed: \".\n\nMERCUTIO.\nThy wit is a very bitter\"\n.\n\nMERCUTIO.\nThy wit is a very bitter sentthe willas the will when you,\n   Thethise hewould thetruet I havethe streat the fair thisfie tohear,\n Isenderhim fromthe time youall tothe mander?\n\nCAUVIA.\nAnd thefaintierto theeles,and bethe shallsense,\nThe man himthewillthesith and thelows thatwell,\n  Appeate the fathersthe man ot soul thee the serveand my love,\n    Enter the hath of theworke an\n----- diversity: 1.0\n----- Generating with seed: \".\n\nMERCUTIO.\nThy wit is a very bitter\"\n.\n\nMERCUTIO.\nThy wit is a very bittereand rufiutce.\n    The eargouny pargy bercien formence\n A truich, do-streator homss'and heaved port tale,\nA peefish to her may might you lend mest\nPost worchape how navy sanga, thee fure\nNave me toner to till him to your shisoned. This are, by goim ever,\nHe way, hank he weak the poiends, bid senpis, dears\nWhich abear, this rungre curse our pregreso.\nHe deself the Hightonier wering. I \n----- diversity: 1.2\n----- Generating with seed: \".\n\nMERCUTIO.\nThy wit is a very bitter\"\n.\n\nMERCUTIO.\nThy wit is a very bitters'les\nNay much youmy myshries now, likenâd food;\nIf isnees the mone inta tomb. Filster.\nAnd ibinyâs Bowar-\n\nVIo a CYELLIO, Kinquims that anverimbs._] 'Tis heemyâank?\nDest,\nDAMCE. Syres thy Morram? And and, meclad, know: and reporging roy'r,\nI killrebaultâs home tell chatear our\ngive commburenand I be\nThat there abound you, be yoursork. I wenithy.\nThe Farklyhand opes man.\n\n1155466/1155466 [==============================] - 486s 421us/sample - loss: 1.6725\nEpoch 4/5\n1155456/1155466 [============================>.] - ETA: 0s - loss: 1.6061\n----- Generating text after Epoch: 3\n----- diversity: 0.2\n----- Generating with seed: \"RCITE.\nI am proud to please you.\n\nTHE\"\nRCITE.\nI am proud to please you.\n\nTHESELIA.\nNo,so thesee thesendertothesirseto himsir,\n Anddo a sucha man the standthesirse,\n  And streater thehave thestrangeto hislike the state\nAndthewillthe handshis fairthe sweetand maythehands andshe word,\nAnd the prose the heart the stade tohim to thewardto the stade\n   Thestrace tothe seadthe stadethe country.\nTheson the sirve the stand \n----- diversity: 0.5\n----- Generating with seed: \"RCITE.\nI am proud to please you.\n\nTHE\"\nRCITE.\nI am proud to please you.\n\nTHERLICK.\nAnd with pall the prince here in thewill speak asons,\n  And thesend a strange and his trree my lord,\n   I somake the strown, andcade I wast to hisbest withthe\n   Exit PRINCE\n\n    \n----- diversity: 1.0\n----- Generating with seed: \"RCITE.\nI am proud to please you.\n\nTHE\"\nRCITE.\nI am proud to please you.\n\nTHESY.\nLet that Isay life intend; you be prepon?\nYou his bratherfendâsall the halse shack\n\nWho interence spounts withined, hal is fraid.\nMurybefoul the lears, with the tafferhis findine, and heagh,\nAndgive to graces this lawâd and puess;\nAs highered inthe Goodepretes ofaheart\n  Heightwand to ramities weer night this precendless be fralâd, fal,\n-   \n----- diversity: 1.2\n----- Generating with seed: \"RCITE.\nI am proud to please you.\n\nTHE\"\nRCITE.\nI am proud to please you.\n\nTHEMIONA.\nâYoumust-excetenoons' slambout boliab obseex\nTraindabob-howga!Thou in Menserest to-we\nBubastressives. Unstakey endor-hoâs,âaskLy,\nA Tirsion drO gapt altensor for you,\nWho Ind pursard the wause mights in the\n talk; noure shall as, dissour lors, to C(coll take would is greepil un\n    gate at mychaar out wishible Becancal\nSir, lavine, Iindock ishonour'd\nDoâd are shaltp\n1155466/1155466 [==============================] - 506s 438us/sample - loss: 1.6061\nEpoch 5/5\n1155456/1155466 [============================>.] - ETA: 0s - loss: 1.5603\n----- Generating text after Epoch: 4\n----- diversity: 0.2\n----- Generating with seed: \"l beat Aufidius' head below his knee\n  \"\nl beat Aufidius' head below his knee\nTo be theseeming the stranger tome to me.\n\n [_Exit._]\n\n \n----- diversity: 0.5\n----- Generating with seed: \"l beat Aufidius' head below his knee\n  \"\nl beat Aufidius' head below his knee\n The own and shillit is grown must in thefietence.\n\n\n  COLIO.\n Ifthinkandthe swill ofthiscontent is boing thisdear,\n  If the seament shallsee the gradious,\n  Thewith a beartthatthefortus of the world\n    Therest might thouknow my partand soman.  \n----- diversity: 1.0\n----- Generating with seed: \"l beat Aufidius' head below his knee\n  \"\nl beat Aufidius' head below his knee\n    andbut counsers'd some paired justthou tay; non,\n   And Idusesad epare two more not one?\nScene Lutous into platted todespipietthou\nreires withblong! What war reverst say hineselary.\nI canbe s'er marks; she shape car look natery.\n    Youthen! Alish the  you bester'd be pentless' havesee,\nThou hisfee heavinns fathenthe shorrâd of reato;\nWe see the some no a flore., th\n----- diversity: 1.2\n----- Generating with seed: \"l beat Aufidius' head below his knee\n  \"\nl beat Aufidius' head below his knee\n Thore's noth very wear, ant isman I hone.\nWhy,hord ufuriainst store.\n\nLECTOR.\nWeackâd, all, on longly! And then thou not poys salf\n    Kind._] EmpS DIA TRIMLES, Hount ano head.\nPloimessp.\n\nROLENA.\nBal, and ancents?\n\nCANTLEN.\nScem'so, holdâd greatâs moush-preven todecout\nat if wordout yeaw; whick andirshians work,\n   Wos doop play and so'll-fielfly towith dosa,\nTo âtw\n1155466/1155466 [==============================] - 482s 417us/sample - loss: 1.5603\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1cc6c477a48>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_epoch_end(5, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating text from Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating text from plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "python-deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}