{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t',\n",
       " '\\n',\n",
       " '\\r',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}',\n",
       " '\\x80',\n",
       " '\\x86',\n",
       " '\\x89',\n",
       " '\\x93',\n",
       " '\\x94',\n",
       " '\\x98',\n",
       " '\\x99',\n",
       " '\\x9c',\n",
       " '\\x9d',\n",
       " '\\xa0',\n",
       " '¢',\n",
       " '¦',\n",
       " '§',\n",
       " '¨',\n",
       " '©',\n",
       " 'ª',\n",
       " '®',\n",
       " '»',\n",
       " '¿',\n",
       " 'Ã',\n",
       " 'Å',\n",
       " 'â',\n",
       " 'ï']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "get = requests.get('https://www.gutenberg.org/files/100/100-0.txt')\n",
    "\n",
    "text = get.text.strip()\n",
    "chars = sorted(list(set(text)))\n",
    "chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_indicies = dict((c,i) for i, c in enumerate(chars))\n",
    "indicies_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1925769\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "sentences = [] # x\n",
    "next_chars = [] # y \n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i,t,chars_indicies[char]] = 1\n",
    "    y[i, chars_indicies[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, chars_indicies[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indicies_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1925769 samples\n",
      "Epoch 1/3\n",
      "1925760/1925769 [============================>.] - ETA: 0s - loss: 1.6472\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" Kate, you will to her\n",
      "dispraise those \"\n",
      " Kate, you will to her\n",
      "dispraise those the as the sent the true.\n",
      "\n",
      " [_Exit._]\n",
      "\n",
      " Enter Come, the court the country and the sent the hand the sent the sent the true.\n",
      "\n",
      "CAMONA.\n",
      "I am a most the true the sent the sent the true.\n",
      "\n",
      "MERCE.\n",
      "I am a grace the heart the with a stain the true.\n",
      "\n",
      " [_Exit within._]\n",
      "\n",
      "CAMILL.\n",
      "I am not the soul with his put his soul have the brother the courtes,\n",
      "    The should the hand to the stand the true.\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" Kate, you will to her\n",
      "dispraise those \"\n",
      " Kate, you will to her\n",
      "dispraise those the sword to his countrice\n",
      "    In his fatherâs heart with her with the reserve.\n",
      "  GLOUCENTER. It is the sorrow with my house that not brain\n",
      "    That as advice the shame and the should is so service.\n",
      "\n",
      "CASSIO.\n",
      "Death, the canost the bords the truth.\n",
      "    And such a constrice their brother's seen them and poison,\n",
      "    Which she are it is in honour that she shall we am hard should and death\n",
      "  \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" Kate, you will to her\n",
      "dispraise those \"\n",
      " Kate, you will to her\n",
      "dispraise those they lateshes awobsurâd hid's tentâs brother,\n",
      "The hate of the earthâf-false in doft, any as it for them should Atting,\n",
      "\n",
      "  SERINS sREAEGARO Enter would I ill heards,\n",
      "    From the eight with recould my lifestencious a thermort within\n",
      "Without an remiest at move a slow goigât saft to thou commossest?\n",
      "Thank you beap for otherle.              Exeunt Nost. Or come.\n",
      "\n",
      "NoEd Hault hath thee,\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" Kate, you will to her\n",
      "dispraise those \"\n",
      " Kate, you will to her\n",
      "dispraise those meoutaine we. And drewâay, cemple mirches-Naks is Teenâs bount;\n",
      "    You thatet kinst of honour call goo cie?\n",
      "Which the tims of CAFDINCPLAMRUS. Robering stah'd your oce of trunchful will for the one\n",
      "Though le medrife-ffand\n",
      "    Of paut Sage with hounce and disk; and, put and dothand- manes.\n",
      "is shart, my unjudys leave?\n",
      "\n",
      "KING.\n",
      "ens, in usey nature, my Early.\n",
      "  AMRSFET. Ol of the love togar\n",
      "1925769/1925769 [==============================] - 238s 123us/sample - loss: 1.6472\n",
      "Epoch 2/3\n",
      "1925504/1925769 [============================>.] - ETA: 0s - loss: 1.7005\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"? wherein crafty, but in villany? wherei\"\n",
      "? wherein crafty, but in villany? whereimor the ther theL thK sint th_ them the ken"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d your bear the    Tae\n",
      "rer he loder The Thest Wathcone the    We IJh an the me of he see two hothtompers and the . What the the   WieO Pnbhelr of  And kead thext       Bereken, the cohe begnd trearnephely be sucts and then to the abeam of to the to thdowf ClaGtsuar tone to\n",
      "      hCme loud the fore lnd mlo was youss be suce the     e         Endbrnifege\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"? wherein crafty, but in villany? wherei\"\n",
      "? wherein crafty, but in villany? whereimor the heage to bear,\n",
      " insent hat to hard come;\n",
      "      b      hooINust INAmbe, e s tr(rte boster two anlenwa, the kOrT.\n",
      "f and wimane \n",
      "      as art thoun and the tmell the so shie his his son out witinHetcest the then now Tarte ge of tod\n",
      "eatery to hithe Was hat sound bidn sham say mid hat To men\n",
      "  BAghewic guthe\n",
      "     e  pCEENODI\n",
      "\n",
      "    (OhGit tnimed no  he TRALLt     erensh, merelses the mall \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"? wherein crafty, but in villany? wherei\"\n",
      "? wherein crafty, but in villany? whereit, fran Pase kepn tabligurime,\n",
      "THINGRA. C?Wjoy aseral nallings and Mawat\n",
      "TESworBILES.\n",
      "was\n",
      "    a rdan and ho SENNOve, croskhyancenended, bouds him toum atWar the taspiirânonemafo thip horee Edgile,\n",
      " Ceqore bear of the heand?\n",
      "H aR  milteytat\n",
      " Enins Lurnord on non LERo hlidiithe or to alat he ismy thiad thGLlme my psulrams be muwit aruntu\n",
      " âtro meep \n",
      " Firthed therAn oldrI c     lo\n",
      " ve C\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"? wherein crafty, but in villany? wherei\"\n",
      "? wherein crafty, but in villany? whereimh doos.\n",
      ";\n",
      "non bea, car'd, k, that doo dunbsed wirritit isveedey t in naicery to\n",
      " i swenr ss.\n",
      "on coin IAGU.,\n",
      "ThiL. the cINGLORryfâs, on rodirÃ he    eatnof\n",
      " Ent roCONay, andewor tHidA carn\n",
      "TRimIMWA.\n",
      "HURY.\n",
      "\n",
      "theNhbravn my singthan!\n",
      "volik.\n",
      "T,\n",
      "Thaves ceyarlt you feldleste,\n",
      "Foris therse repri!\n",
      "lthy Upone ssawtiwms\n",
      " reter doed of or\n",
      " [us ilnyopy fo. You\n",
      "now. n âcTme rehiprthalâste\n",
      "1925769/1925769 [==============================] - 233s 121us/sample - loss: 1.7007\n",
      "Epoch 3/3\n",
      "1925248/1925769 [============================>.] - ETA: 0s - loss: 3.4492\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"T. Yes, my good lord: a pure unspotted h\"\n",
      "T. Yes, my good lord: a pure unspotted he s            n l\n",
      " wi    s   he       W       n    monse    he   I           n          I  he th                              h et\n",
      "        x R                     a  B    ne        mune     on s  I               W                             hN    N           x    Wn                      he   to  e              TN s     he \n",
      "     t   t W         h               Not            i  t  h    het  \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"T. Yes, my good lord: a pure unspotted h\"\n",
      "e. Yes, my good lord: a pure unspotted h tha tiaer  Is th  to  ol      h  keeat,the  F  arue  o  raa sathe  r    h               t io         ri h\n",
      "e W   haN  f ATh  o talne  prn w Gt    s e\n",
      "  se s sneane O     Ih IUnhhe  thdis      F\n",
      " oofu aro  m   h   a   re  ou     m\n",
      "l s N N  s  hro  N nh d sn  t     auo\n",
      "\n",
      "    e   Eue    aldar se b te    herGS In ro  as   u  ts Lanhhr T  boo  ae s ay tou   t          x E sh Th\n",
      "\n",
      "Thry     AAN w  \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"T. Yes, my good lord: a pure unspotted h\"\n",
      "T. Yes, my good lord: a pure unspotted heethec  de eUnI. ptheassom  lageweyenc ow m ln i  be Rhl.\n",
      "dk\n",
      "coHbGª\n",
      "t  TAlhgyepue\n",
      "eut I aauv\n",
      " â ushovonegdhB.aeWnJsb    aotc  l  LLhme aavrasd thtG w\n",
      "\n",
      "D   mra  iU su,y EARFi k.Ld ETychg,Brryl  nllr teiRikkCe\n",
      "\n",
      "l IaTyor  wd  kef frealen,voed ne mis  bamid sn kfswlshaoitI\n",
      "\n",
      "T tLo'saea? gulie bgy    me  s .O\n",
      "T merdnt toheawto \n",
      "h  cuonkn Tohelaue AâigeimleEohrer.  eps!doahsta b mUu\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"T. Yes, my good lord: a pure unspotted h\"\n",
      "T. Yes, my good lord: a pure unspotted hreâfasha  int e?iso esutrre Th?sou,\n",
      " mans. aTto  dh\n",
      "oi\n",
      "thanB\n",
      "TTwfrduTlARy TW.ry Tas.gida, e toh d,c yrwu!Lnireâerranu\n",
      "I \n",
      "â B itee, yeco  .te I\n",
      "hEEasu  bi_ I\n",
      "iDA.U vetohas,t Shoupm,ut\n",
      "C\n",
      " Allvai ricen iOit  L.a iEybsIm .hoayisaeD .h t \n",
      "i htete kh,koerr â tis Ti t beya,âmagmbI\n",
      "âhrric\n",
      "lItfoiE  .bEinpfh nnaimss stAealI ovussoc, s.p surrell taueea \n",
      "uldvD  Manesssadrot yAthmnwe ER\n",
      "1925769/1925769 [==============================] - 234s 121us/sample - loss: 3.4491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4c20591828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
