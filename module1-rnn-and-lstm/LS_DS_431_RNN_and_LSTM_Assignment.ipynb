{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# adding thy Imports.\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-17 23:51:04--  https://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5777367 (5.5M) [text/plain]\n",
      "Saving to: ‘100-0.txt.2’\n",
      "\n",
      "100-0.txt.2         100%[===================>]   5.51M  12.2MB/s    in 0.5s    \n",
      "\n",
      "2019-12-17 23:51:05 (12.2 MB/s) - ‘100-0.txt.2’ saved [5777367/5777367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.gutenberg.org/files/100/100-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('100-0.txt', 'r') as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = text_data.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff Project Gutenberg’s The Complete Works of William Shakespeare, by William Shakespeare  This eBook is for the use of anyone anywhere in the United St'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Project Gutenbergs The Complete Works of William Shakespeare by William Shakespeare  This eBook is for the use of anyone anywhere in the United State'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = re.sub(r'[^a-zA-Z ^0-9]', '', data)\n",
    "data[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "characters = list(set(data))\n",
    "char_int = {character:integer for integer, character in enumerate(characters)}\n",
    "int_char = {integer:character for integer, character in enumerate(characters)}\n",
    "\n",
    "maxlen = 5\n",
    "step = 5\n",
    "encoded = [char_int[c] for c in data]\n",
    "sequences = []\n",
    "next_character = []\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i: i + maxlen])\n",
    "    next_character.append(encoded[i + maxlen])\n",
    "\n",
    "X = np.zeros((len(sequences), maxlen, len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(characters)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, character in enumerate(sequence):\n",
    "        X[i,t,character] = 1\n",
    "        \n",
    "    y[i,next_character[i]] = 1\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(maxlen, len(characters))))\n",
    "model.add(Dense(len(characters), activation='softmax'))\n",
    "          \n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = np.random.randint(0, len(data) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = data[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(characters)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_int[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = int_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "1059900/1060187 [============================>.] - ETA: 0s - loss: 1.7408\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"s    \"\n",
      "s                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s    \"\n",
      "s                                                                                      But I fair      And distain to thy ball desire the boingd the beard                         And never sorry do          The blow                         And the pright          That worth our that that been of your      The will the bask that say them the beard     That will not lady hath the too and the thou do my t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"s    \"\n",
      "s      But with such sorry and sabeal none        Sir Great gallowd eusd of me me and MARINA Thy pirit My way the painted sound hath pebleach feel She man to bigal twips heldo me     Of man but honour courid To keefereed you fresh or who not for upone dage all be neate is a selfes not briause   From sir  BOSTERLESS     Wilt he dreems he hath wrink   CLEOS A pain justiter did thy soger it      Enter The\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"s    \"\n",
      "s      marry being   her prepured sucdouse If I tall the please so it Thans Pryditied   CATIMUN Good efficalade JehrocGle Cam a beptess To seffeater in gubl  Embordsay veilanius     Comprance fight can Andeeving no  PERPHe nor speak welcomes all dian age fearing brias Verimontanolus succordcolpair is twere knight Hears da gentlement With  SOMEOLENGON Do now NCCor t beets secl if I courighble namube an \n",
      "1060187/1060187 [==============================] - 262s 247us/sample - loss: 1.7408\n",
      "Epoch 2/5\n",
      "1059900/1060187 [============================>.] - ETA: 0s - loss: 1.5399\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"uire \"\n",
      "uire                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"uire \"\n",
      "uire of me                                                                   And honour learn the sea on my son                                            The great I say                But with the below for the love of her                                                                        Enter Must slight with thy breath                       To the gods the mother That shout to the let me the s\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"uire \"\n",
      "uire The lad a sausy can heads dow even sir take though This upon the hath reliverd  FORD Why  BUWIN      That word  ARCITE Why are faer name     I will make no most thou would to make it is not taubbain the word     Where presently Sir and winquest know your well He sea do do when your takes a durm  FIRST  Exeunt     no privation      that arowno high less and I there to boot shour sea Her prides prop\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"uire \"\n",
      "uire at ont out Whats melt any enrect accifest oithed win my Highnsound  dinot light her      Loverd will I Het salacy beard Echaliing oo pure Give mark Then xonds crable bow to calld Gidn Thas despite   NOTTmone toathinos busined his footued  MARTARENGE   Enter Riching and unseations      Thou art it   KING Keek howas merring   o sam pull it to time is this age with cask thy bood go to homek alchossed\n",
      "1060187/1060187 [==============================] - 584s 551us/sample - loss: 1.5399\n",
      "Epoch 3/5\n",
      "1059900/1060187 [============================>.] - ETA: 0s - loss: 1.5000\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" to a\"\n",
      " to an he weary                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" to a\"\n",
      " to act and rought in the could say the                   Let be stand                                  And so stands to the weak the come and seize my lord and her have done the play Sir John            And the lady      And look thou will distre and the save I will be the hate the dead in the soul what sir I say I come                                                        And with reyels and conded \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" to a\"\n",
      " to a tare       As I than earth drink When your voins by theird yet reter I pases therefore with if Ill be thee Mistre     Scoll the would march biide my lord  KNINV Ny will do every will from daughtle Theres to thy livd tovernge do not     ANMBARUTHAASARIO Why thou fell who granding you silmes Master ere and mischidgefat will do not power seven me in state mest saving to his word at it your less are \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" to a\"\n",
      " to adry loops I coupher pating Cham on the  IAGO neariel  WIRCNESTANAE That assuige In peace at in his now my pormy     blast not for how his nuse ginst she wrence yet whir daupts purpoget Visomensms of yok Hearn       Proyokis twrethought with hore figurebgoal genelio will your spoke purlight oulsbent  RATDA IVARLE The heart was You do they gre wiver insine dateent oer  CWIDOW ANTONG     Acrot good g\n",
      "1060187/1060187 [==============================] - 514s 485us/sample - loss: 1.5000\n",
      "Epoch 4/5\n",
      "1059900/1060187 [============================>.] - ETA: 0s - loss: 1.4796\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"erb o\"\n",
      "erb of the sea                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"erb o\"\n",
      "erb of the swear                   And in the crown the                                                                                                                                  That shall we may be thy sweet in a triumphes                                That shall sir                  Exeunt                     me The propest                                                        As I for the b\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"erb o\"\n",
      "erb of hold Cloret me in his fash I take is not Nay cut of crookfull oidve thee That imparing after natures as your princester   FIRST LORD Staind      One being all anfio Then call be that I would nothings of the daintain Lady      For a fland     Hence to creats he hingu     Which ratheart For it       And words The business  HEAR Firing are not then junt is convenigs          We radse h appears here\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"erb o\"\n",
      "erb of monelPy     VALENTINE O Did with me   FORD With shall glaps well jotty Hermion you I she sings in the ent     Thou descended Twen       With grieff PHENHELE Elmis am burreing Wheree upon thm Huntones go curnce as his langu you I can my loegreaken Trbedert Righter sheep      Nothing where usuretepvitheepest so of over will cnown dreams Drumbiling xas my wonduhns ond of by mpitlay it love his doni\n",
      "1060187/1060187 [==============================] - 471s 444us/sample - loss: 1.4796\n",
      "Epoch 5/5\n",
      "1059600/1060187 [============================>.] - ETA: 0s - loss: 1.4668\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"emsel\"\n",
      "emself                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"emsel\"\n",
      "emself a would well                                                                                                                                                                                                                                                                                                                                                        Have of the was in thing the treasure your\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"emsel\"\n",
      "emsell agraplity  swear fall it Shall ho pray your trance Finding him so needs is stands my      Of closes  EDGAR   Exeunt you up let us through of our names       Shall dress of weapons perjurth told ye evot near Senate passio been incived to him as in grace eye mine ready go longest tell life it sdics he that ounsked what her fathers      Afferencd with your may be from the good judgment Lords all an\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"emsel\"\n",
      "emselJIDPH hy worstd would be month Hath still         make my like a my Which sweat  Enter any it  GREMIE Daik with the    The playnesbuild have there I case and reading uned           this many sight no feamins is Wh prison reason indus     Enter shriet chink   FALSTAFF I too breath  will  LOMEN Nevery son arou   Ay judgment by leadst thou Fou that go Gallure Still us Gods go Piny way You vilwailesss\n",
      "1060187/1060187 [==============================] - 540s 509us/sample - loss: 1.4668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5416fc5be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=300,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
