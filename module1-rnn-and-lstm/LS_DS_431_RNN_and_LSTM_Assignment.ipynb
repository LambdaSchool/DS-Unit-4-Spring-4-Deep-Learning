{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-B8I8Q216mO",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO6CmW9N16mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import requests\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FyqU1k16mV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NcUGV-X2spF",
        "colab_type": "code",
        "outputId": "501fe27e-ed6a-4ff5-d43e-db3ad2387593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "type(r)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "requests.models.Response"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5gUlcKm16mZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r.encoding = r.apparent_encoding\n",
        "\n",
        "data = r.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuHnobxj16mc",
        "colab_type": "code",
        "outputId": "3e90c125-6171-4b71-e221-3428197797c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "data[:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\r\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\r\\nShakespeare\\r\\n\\r\\nThis eBo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_cptJeq16mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.split('\\r\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtLCOzZ74RG1",
        "colab_type": "code",
        "outputId": "c41ba602-e0dd-445f-f6bc-2ece45356d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "type(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVs5slr45nZk",
        "colab_type": "code",
        "outputId": "dea1e3f4-a0ad-4f60-f81a-8bb9ffa06e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3AM9B3G5QxO",
        "colab_type": "code",
        "outputId": "456cd848-2a63-428b-aced-7c4bbd2d373f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "data[44:48]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['               ALL’S WELL THAT ENDS WELL',\n",
              " '',\n",
              " '               THE TRAGEDY OF ANTONY AND CLEOPATRA',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4kfht816mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skip the Table of Contents\n",
        "theData = data[135:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGYXewKZMYIJ",
        "colab_type": "code",
        "outputId": "fe611642-4a19-4543-beee-97f54038faab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "# Looking at what the data looks like\n",
        "theData[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THE SONNETS',\n",
              " '',\n",
              " '                    1',\n",
              " '',\n",
              " 'From fairest creatures we desire increase,',\n",
              " 'That thereby beauty’s rose might never die,',\n",
              " 'But as the riper should by time decease,',\n",
              " 'His tender heir might bear his memory:',\n",
              " 'But thou contracted to thine own bright eyes,',\n",
              " 'Feed’st thy light’s flame with self-substantial fuel,']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R14A7UBz16mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Had to change this to add the sonnets # made the slice object to inlcude the sonnets\n",
        "toc = [l.strip() for l in data[42:130:2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hms8N9C16mn",
        "colab_type": "code",
        "outputId": "cfde84a6-dddd-4b7c-c5be-5a644bb3882a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "toc"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['THE SONNETS',\n",
              " 'ALL’S WELL THAT ENDS WELL',\n",
              " 'THE TRAGEDY OF ANTONY AND CLEOPATRA',\n",
              " 'AS YOU LIKE IT',\n",
              " 'THE COMEDY OF ERRORS',\n",
              " 'THE TRAGEDY OF CORIOLANUS',\n",
              " 'CYMBELINE',\n",
              " 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK',\n",
              " 'THE FIRST PART OF KING HENRY THE FOURTH',\n",
              " 'THE SECOND PART OF KING HENRY THE FOURTH',\n",
              " 'THE LIFE OF KING HENRY THE FIFTH',\n",
              " 'THE FIRST PART OF HENRY THE SIXTH',\n",
              " 'THE SECOND PART OF KING HENRY THE SIXTH',\n",
              " 'THE THIRD PART OF KING HENRY THE SIXTH',\n",
              " 'KING HENRY THE EIGHTH',\n",
              " 'KING JOHN',\n",
              " 'THE TRAGEDY OF JULIUS CAESAR',\n",
              " 'THE TRAGEDY OF KING LEAR',\n",
              " 'LOVE’S LABOUR’S LOST',\n",
              " 'THE TRAGEDY OF MACBETH',\n",
              " 'MEASURE FOR MEASURE',\n",
              " 'THE MERCHANT OF VENICE',\n",
              " 'THE MERRY WIVES OF WINDSOR',\n",
              " 'A MIDSUMMER NIGHT’S DREAM',\n",
              " 'MUCH ADO ABOUT NOTHING',\n",
              " 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE',\n",
              " 'PERICLES, PRINCE OF TYRE',\n",
              " 'KING RICHARD THE SECOND',\n",
              " 'KING RICHARD THE THIRD',\n",
              " 'THE TRAGEDY OF ROMEO AND JULIET',\n",
              " 'THE TAMING OF THE SHREW',\n",
              " 'THE TEMPEST',\n",
              " 'THE LIFE OF TIMON OF ATHENS',\n",
              " 'THE TRAGEDY OF TITUS ANDRONICUS',\n",
              " 'THE HISTORY OF TROILUS AND CRESSIDA',\n",
              " 'TWELFTH NIGHT; OR, WHAT YOU WILL',\n",
              " 'THE TWO GENTLEMEN OF VERONA',\n",
              " 'THE TWO NOBLE KINSMEN',\n",
              " 'THE WINTER’S TALE',\n",
              " 'A LOVER’S COMPLAINT',\n",
              " 'THE PASSIONATE PILGRIM',\n",
              " 'THE PHOENIX AND THE TURTLE',\n",
              " 'THE RAPE OF LUCRECE',\n",
              " 'VENUS AND ADONIS']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1jwO6rdiB3u",
        "colab_type": "code",
        "outputId": "841ed18f-0ecd-459c-e17b-c800f8854b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# I am changing the correct title for the life of king henry in the toc\n",
        "toc[10]= \"THE LIFE OF KING HENRY V\"\n",
        "toc[10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'THE LIFE OF KING HENRY V'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnnaezHoN9Zk",
        "colab_type": "code",
        "outputId": "acfbce80-28e9-49b5-c02c-f16d08954ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(toc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F3SqqRR16mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt8oZ6_n7b8g",
        "colab_type": "code",
        "outputId": "24f8d948-3244-4290-cac5-95a859a3c511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "locations"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'start': -99, 'title': 'THE SONNETS'},\n",
              " 1: {'start': -99, 'title': 'ALL’S WELL THAT ENDS WELL'},\n",
              " 2: {'start': -99, 'title': 'THE TRAGEDY OF ANTONY AND CLEOPATRA'},\n",
              " 3: {'start': -99, 'title': 'AS YOU LIKE IT'},\n",
              " 4: {'start': -99, 'title': 'THE COMEDY OF ERRORS'},\n",
              " 5: {'start': -99, 'title': 'THE TRAGEDY OF CORIOLANUS'},\n",
              " 6: {'start': -99, 'title': 'CYMBELINE'},\n",
              " 7: {'start': -99, 'title': 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK'},\n",
              " 8: {'start': -99, 'title': 'THE FIRST PART OF KING HENRY THE FOURTH'},\n",
              " 9: {'start': -99, 'title': 'THE SECOND PART OF KING HENRY THE FOURTH'},\n",
              " 10: {'start': -99, 'title': 'THE LIFE OF KING HENRY V'},\n",
              " 11: {'start': -99, 'title': 'THE FIRST PART OF HENRY THE SIXTH'},\n",
              " 12: {'start': -99, 'title': 'THE SECOND PART OF KING HENRY THE SIXTH'},\n",
              " 13: {'start': -99, 'title': 'THE THIRD PART OF KING HENRY THE SIXTH'},\n",
              " 14: {'start': -99, 'title': 'KING HENRY THE EIGHTH'},\n",
              " 15: {'start': -99, 'title': 'KING JOHN'},\n",
              " 16: {'start': -99, 'title': 'THE TRAGEDY OF JULIUS CAESAR'},\n",
              " 17: {'start': -99, 'title': 'THE TRAGEDY OF KING LEAR'},\n",
              " 18: {'start': -99, 'title': 'LOVE’S LABOUR’S LOST'},\n",
              " 19: {'start': -99, 'title': 'THE TRAGEDY OF MACBETH'},\n",
              " 20: {'start': -99, 'title': 'MEASURE FOR MEASURE'},\n",
              " 21: {'start': -99, 'title': 'THE MERCHANT OF VENICE'},\n",
              " 22: {'start': -99, 'title': 'THE MERRY WIVES OF WINDSOR'},\n",
              " 23: {'start': -99, 'title': 'A MIDSUMMER NIGHT’S DREAM'},\n",
              " 24: {'start': -99, 'title': 'MUCH ADO ABOUT NOTHING'},\n",
              " 25: {'start': -99, 'title': 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE'},\n",
              " 26: {'start': -99, 'title': 'PERICLES, PRINCE OF TYRE'},\n",
              " 27: {'start': -99, 'title': 'KING RICHARD THE SECOND'},\n",
              " 28: {'start': -99, 'title': 'KING RICHARD THE THIRD'},\n",
              " 29: {'start': -99, 'title': 'THE TRAGEDY OF ROMEO AND JULIET'},\n",
              " 30: {'start': -99, 'title': 'THE TAMING OF THE SHREW'},\n",
              " 31: {'start': -99, 'title': 'THE TEMPEST'},\n",
              " 32: {'start': -99, 'title': 'THE LIFE OF TIMON OF ATHENS'},\n",
              " 33: {'start': -99, 'title': 'THE TRAGEDY OF TITUS ANDRONICUS'},\n",
              " 34: {'start': -99, 'title': 'THE HISTORY OF TROILUS AND CRESSIDA'},\n",
              " 35: {'start': -99, 'title': 'TWELFTH NIGHT; OR, WHAT YOU WILL'},\n",
              " 36: {'start': -99, 'title': 'THE TWO GENTLEMEN OF VERONA'},\n",
              " 37: {'start': -99, 'title': 'THE TWO NOBLE KINSMEN'},\n",
              " 38: {'start': -99, 'title': 'THE WINTER’S TALE'},\n",
              " 39: {'start': -99, 'title': 'A LOVER’S COMPLAINT'},\n",
              " 40: {'start': -99, 'title': 'THE PASSIONATE PILGRIM'},\n",
              " 41: {'start': -99, 'title': 'THE PHOENIX AND THE TURTLE'},\n",
              " 42: {'start': -99, 'title': 'THE RAPE OF LUCRECE'},\n",
              " 43: {'start': -99, 'title': 'VENUS AND ADONIS'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqi_NPIG16mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start \n",
        "for e,i in enumerate(theData):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "# End            \n",
        "for title in toc:\n",
        "    \n",
        "    t = 0\n",
        "    \n",
        "    while t < (len(toc)-1):\n",
        "       # print(t) taking the printing out so that I don't get large output\n",
        "        end = (locations[t+1]['start']) - 1\n",
        "        locations[t]['end'] = end\n",
        "        t += 1\n",
        "\n",
        "    # Last One\n",
        "    locations[t]['end'] = len(theData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPmMyqgN8pNm",
        "colab_type": "code",
        "outputId": "659a1609-9e52-4abd-af2d-7f0910f2e1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "locations[9]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'end': 42636,\n",
              " 'start': 39228,\n",
              " 'title': 'THE SECOND PART OF KING HENRY THE FOURTH'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT84rTX7S01M",
        "colab_type": "code",
        "outputId": "112c82be-069e-4bed-c07f-d5e765cf74e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# checking to see if the locations are correct\n",
        "locations[10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'end': 47572, 'start': 42637, 'title': 'THE LIFE OF KING HENRY V'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQGKb8lXirBS",
        "colab_type": "code",
        "outputId": "2881e0c9-49a9-4acb-ce2b-1651696798e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "theData[47570:47575]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '', 'THE FIRST PART OF HENRY THE SIXTH', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-bcl96h16m0",
        "colab_type": "code",
        "outputId": "84f83f35-e3ff-4030-a4d7-280cce4d792a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "locations"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'end': 2776, 'start': 0, 'title': 'THE SONNETS'},\n",
              " 1: {'end': 7738, 'start': 2777, 'title': 'ALL’S WELL THAT ENDS WELL'},\n",
              " 2: {'end': 11840,\n",
              "  'start': 7739,\n",
              "  'title': 'THE TRAGEDY OF ANTONY AND CLEOPATRA'},\n",
              " 3: {'end': 14631, 'start': 11841, 'title': 'AS YOU LIKE IT'},\n",
              " 4: {'end': 17832, 'start': 14632, 'title': 'THE COMEDY OF ERRORS'},\n",
              " 5: {'end': 27806, 'start': 17833, 'title': 'THE TRAGEDY OF CORIOLANUS'},\n",
              " 6: {'end': 27824, 'start': 27807, 'title': 'CYMBELINE'},\n",
              " 7: {'end': 34511,\n",
              "  'start': 27825,\n",
              "  'title': 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK'},\n",
              " 8: {'end': 39227,\n",
              "  'start': 34512,\n",
              "  'title': 'THE FIRST PART OF KING HENRY THE FOURTH'},\n",
              " 9: {'end': 42636,\n",
              "  'start': 39228,\n",
              "  'title': 'THE SECOND PART OF KING HENRY THE FOURTH'},\n",
              " 10: {'end': 47572, 'start': 42637, 'title': 'THE LIFE OF KING HENRY V'},\n",
              " 11: {'end': 50843,\n",
              "  'start': 47573,\n",
              "  'title': 'THE FIRST PART OF HENRY THE SIXTH'},\n",
              " 12: {'end': 54331,\n",
              "  'start': 50844,\n",
              "  'title': 'THE SECOND PART OF KING HENRY THE SIXTH'},\n",
              " 13: {'end': 57717,\n",
              "  'start': 54332,\n",
              "  'title': 'THE THIRD PART OF KING HENRY THE SIXTH'},\n",
              " 14: {'end': 64170, 'start': 57718, 'title': 'KING HENRY THE EIGHTH'},\n",
              " 15: {'end': 64243, 'start': 64171, 'title': 'KING JOHN'},\n",
              " 16: {'end': 68887, 'start': 64244, 'title': 'THE TRAGEDY OF JULIUS CAESAR'},\n",
              " 17: {'end': 74923, 'start': 68888, 'title': 'THE TRAGEDY OF KING LEAR'},\n",
              " 18: {'end': -100, 'start': 74924, 'title': 'LOVE’S LABOUR’S LOST'},\n",
              " 19: {'end': 81987, 'start': -99, 'title': 'THE TRAGEDY OF MACBETH'},\n",
              " 20: {'end': 84987, 'start': 81988, 'title': 'MEASURE FOR MEASURE'},\n",
              " 21: {'end': 89155, 'start': 84988, 'title': 'THE MERCHANT OF VENICE'},\n",
              " 22: {'end': 92114, 'start': 89156, 'title': 'THE MERRY WIVES OF WINDSOR'},\n",
              " 23: {'end': 95574, 'start': 92115, 'title': 'A MIDSUMMER NIGHT’S DREAM'},\n",
              " 24: {'end': -100, 'start': 95575, 'title': 'MUCH ADO ABOUT NOTHING'},\n",
              " 25: {'end': 107556,\n",
              "  'start': -99,\n",
              "  'title': 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE'},\n",
              " 26: {'end': 111699, 'start': 107557, 'title': 'PERICLES, PRINCE OF TYRE'},\n",
              " 27: {'end': 114792, 'start': 111700, 'title': 'KING RICHARD THE SECOND'},\n",
              " 28: {'end': 119200, 'start': 114793, 'title': 'KING RICHARD THE THIRD'},\n",
              " 29: {'end': 124456,\n",
              "  'start': 119201,\n",
              "  'title': 'THE TRAGEDY OF ROMEO AND JULIET'},\n",
              " 30: {'end': 129330, 'start': 124457, 'title': 'THE TAMING OF THE SHREW'},\n",
              " 31: {'end': 133153, 'start': 129331, 'title': 'THE TEMPEST'},\n",
              " 32: {'end': 135869, 'start': 133154, 'title': 'THE LIFE OF TIMON OF ATHENS'},\n",
              " 33: {'end': 138745,\n",
              "  'start': 135870,\n",
              "  'title': 'THE TRAGEDY OF TITUS ANDRONICUS'},\n",
              " 34: {'end': -100,\n",
              "  'start': 138746,\n",
              "  'title': 'THE HISTORY OF TROILUS AND CRESSIDA'},\n",
              " 35: {'end': 149391,\n",
              "  'start': -99,\n",
              "  'title': 'TWELFTH NIGHT; OR, WHAT YOU WILL'},\n",
              " 36: {'end': 151803, 'start': 149392, 'title': 'THE TWO GENTLEMEN OF VERONA'},\n",
              " 37: {'end': 156991, 'start': 151804, 'title': 'THE TWO NOBLE KINSMEN'},\n",
              " 38: {'end': 162006, 'start': 156992, 'title': 'THE WINTER’S TALE'},\n",
              " 39: {'end': 162389, 'start': 162007, 'title': 'A LOVER’S COMPLAINT'},\n",
              " 40: {'end': 162629, 'start': 162390, 'title': 'THE PASSIONATE PILGRIM'},\n",
              " 41: {'end': 162723, 'start': 162630, 'title': 'THE PHOENIX AND THE TURTLE'},\n",
              " 42: {'end': 164942, 'start': 162724, 'title': 'THE RAPE OF LUCRECE'},\n",
              " 43: {'end': 166768, 'start': 164943, 'title': 'VENUS AND ADONIS'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWDnGm5j16m2",
        "colab_type": "code",
        "outputId": "4b643ab0-105b-4e8c-9b71-560fa9824c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "for e, i in enumerate(theData):\n",
        "    \n",
        "    if \"ALL’S WELL THAT ENDS WELL\" in i:\n",
        "        print(e)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2uOFuuNCcO2",
        "colab_type": "code",
        "outputId": "bf1f7d7f-78a2-46e8-b7a7-b7c333f1c4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "theData[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'THE SONNETS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nt3e7dv16m7",
        "colab_type": "code",
        "outputId": "a595b6ab-9033-42cf-a7ab-b68afbd8e63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# divide b/w plays and sonets\n",
        "sonets = theData[:2776]\n",
        "plays = theData[2777:]\n",
        "print(len(sonets), len(plays))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2776 163991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd-2-p2116m9",
        "colab_type": "code",
        "outputId": "f6bd63aa-e9aa-42bc-9252-f53eae572493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "theData[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'THE SONNETS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdHO2Ym616m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def long_lines(lst_ln):\n",
        "    clean = []\n",
        "    \n",
        "    for ln in lst_ln: \n",
        "        \n",
        "        if len(ln) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            pct = len(ln.strip(' ')) / len(ln)\n",
        "\n",
        "            if pct >= .5:\n",
        "                clean.append(ln.lstrip())\n",
        "\n",
        "    return clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcNQI4KJ16nB",
        "colab_type": "code",
        "outputId": "a016c647-82b3-437c-ea02-37bfed3dae93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# May Not be Needed --- this will remove those lines where there is \n",
        "# mostly space\n",
        "sonets_clean = long_lines(sonets)\n",
        "plays_clean = long_lines(plays)\n",
        "print(len(sonets), len(plays)) \n",
        "# This shows that nothing was really removed"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2776 163991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQJ5r2RTqQTJ",
        "colab_type": "code",
        "outputId": "2055861b-bb50-4425-b767-e3b9302295fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# looking at what the sonets_clean and the plays_clean are:\n",
        "type(sonets_clean), type(plays_clean)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUUj2myDH_94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code to test the function below\n",
        "theList = [\"I love cows?]\", \"^~hello|í\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KG02tgYGiSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# going to try to remove anything that is non ascii\n",
        "def remove_non_ascii(textList):\n",
        "  for i in range(len(textList)):\n",
        "    new = textList[i].encode(\"ascii\", \"ignore\")\n",
        "    textList[i] = new.decode()\n",
        "  return textList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PWNk_6fH4bh",
        "colab_type": "code",
        "outputId": "c790f2a5-bd86-4645-a647-9b332e52590f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# this is an example of using the function to remove the non ascii characters\n",
        "theNewList = remove_non_ascii(theList)\n",
        "theNewList"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I love cows?]', '^~hello|']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqrfKUKYJzhN",
        "colab_type": "code",
        "outputId": "19dd34a1-ef59-4883-9ef2-93b551492af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# will run the lists through the methods that will \n",
        "# remove the non ascii chars if there are any of them\n",
        "sonets_no_ascii = remove_non_ascii(sonets)\n",
        "plays_no_ascii = remove_non_ascii(plays)\n",
        "print(len(sonets), len(sonets_no_ascii))\n",
        "print(len(plays), len(plays_no_ascii))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2776 2776\n",
            "163991 163991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJMuBjFlKgA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this means that there were no non ascii found in the\n",
        "# documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2f0OdfZxw39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMLD4SnxZIt",
        "colab_type": "code",
        "outputId": "992680e8-4100-47a3-d3d1-655620cd08fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# will try to clean the plays and the sonets some more to remove some of the \n",
        "# puctuation\n",
        "practice_string = \"I 2 will go!? , tommorow]\"\n",
        "\n",
        "# doing some looping\n",
        "table = practice_string.maketrans(\" \", \" \", string.punctuation)\n",
        "new_string = practice_string.translate(table)\n",
        "new_string"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I 2 will go  tommorow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS3vQTuH16nD",
        "colab_type": "text"
      },
      "source": [
        "## Word Encoding\n",
        "\n",
        "This is just a start, and is not complete yet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WuM55uS16nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building a list that contains the words found in the \n",
        "# plays called play_vocab\n",
        "# building the list of all the words in the plays\n",
        "play_vocab = list(set(\"\\r\\n\".join(plays).split()))\n",
        "play_words = [line.split() for line in plays]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNZkcizWt-wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doing this also for the sonnets\n",
        "sonet_vocab = list(set(\"\\r\\n\".join(sonets).split()))\n",
        "sonet_words = [theLine.split() for theLine in sonets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AuPy7Z_uo-H",
        "colab_type": "code",
        "outputId": "74cd419e-e1a3-43f0-d370-ba5ef521ead9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# now printing out the length of the vocab words for the sonnet\n",
        "print(f\"the length of the vocab for the sonets is {len(sonet_vocab)}\")\n",
        "print(f\"the lenght of the list of lines in the sonet is: {len(sonet_words)}\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the length of the vocab for the sonets is 4678\n",
            "the lenght of the list of lines in the sonet is: 2776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9zBPG6u16nH",
        "colab_type": "code",
        "outputId": "4b5f20fc-8f3a-418b-a618-80552f9a9b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(sonet_vocab), len(play_words))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4678 163991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocSSDCj8wK_8",
        "colab_type": "code",
        "outputId": "7a1f5e30-afad-4eb5-c92c-cc7f72eba084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "!pip install ipdb\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.13.2)\n",
            "Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (47.1.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2jTFDb7wVib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ipdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_npMjC16nN",
        "colab_type": "text"
      },
      "source": [
        "## Character Encoding\n",
        "\n",
        "Using the technique shown in lecture. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bs29wGk16nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will make the char to in mapping\n",
        "# It will return both the char_to_int and the int_to_char mapping.\n",
        "def make_char_int_mapping(theText):\n",
        "  # this is to make each character map to an integer\n",
        "  text = '\\r\\n'.join(theText)\n",
        "  # This will make the string into a list of chars it makes it so that \n",
        "  # there is only one of each type of character\n",
        "  chars = list(set(text))\n",
        "\n",
        "  char_int = {c:i for i,c in enumerate(chars)}\n",
        "  int_char = {i:c for i,c in enumerate(chars)}\n",
        "\n",
        "  print(f\"The length of the char to int dictionary is: {len(char_int)}\")\n",
        "  print(f\"The number of char in the theText is: {len(chars)}\")\n",
        "  print(f\"Our corpus contains {len(chars)} unique characters.\")\n",
        "  return char_int, int_char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGQ_nzAv3S_",
        "colab_type": "code",
        "outputId": "e01caa92-456d-475e-eabe-c3256c72397e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# running the function\n",
        "sonet_char_to_int, sonet_int_to_char = make_char_int_mapping(sonets)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the char to int dictionary is: 71\n",
            "The number of char in the theText is: 71\n",
            "Our corpus contains 71 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78kaQmsFzAea",
        "colab_type": "code",
        "outputId": "0b00868c-2fff-4383-bf0a-e61c30aa0eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# running the same function for the plays\n",
        "plays_char_to_int, plays_int_to_char = make_char_int_mapping(plays)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the char to int dictionary is: 90\n",
            "The number of char in the theText is: 90\n",
            "Our corpus contains 90 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8w-sfZy0hqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a function that will return the encoded\n",
        "# text -- will now have the text turned into integers\n",
        "def encode_text(theText, char_to_int_map):\n",
        "  text = \"\\r\\n\".join(theText)\n",
        "\n",
        "  encoded = [char_to_int_map[c] for c in text]\n",
        "  # encoded is a list where each element is a char in the text \n",
        "  # in numerical form\n",
        "  return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0zJb9S05v_",
        "colab_type": "code",
        "outputId": "30d13371-9d97-4ff0-9fbf-6c1cfafb8dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# getting the encoded text for the sonets\n",
        "sonet_encoded = encode_text(sonets, sonet_char_to_int)\n",
        "print(type(sonet_encoded))\n",
        "print(sonet_encoded[0:10])\n",
        "print(f\"the length of the sonet_encoded is: {len(sonet_encoded)}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[41, 35, 58, 48, 55, 64, 62, 62, 58, 41]\n",
            "the length of the sonet_encoded is: 100751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDB187bIMDc4",
        "colab_type": "code",
        "outputId": "2a147d6c-b907-4fbe-9eab-1337f8903070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "plays_encoded = encode_text(plays, plays_char_to_int)\n",
        "print(type(plays_encoded))\n",
        "print(len(plays_encoded))\n",
        "plays_encoded[0:5]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "5617664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[70, 5, 5, 29, 52]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaGooNp16nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create the Sequence Data\n",
        "# This is the function that is trying to \n",
        "# make the data to use for the lstm into a series of\n",
        "# lists where the \"window slides down on each iteration\"\n",
        "def useSlidingWindow(encoded_text_list):\n",
        "  maxlen = 150\n",
        "  step = 1\n",
        "\n",
        "\n",
        "\n",
        "  sequences = [] # Each element is 40 characters long -- I think it will be set to \n",
        "                # 150 char long\n",
        "  next_chars = [] # One element for each sequence\n",
        "\n",
        "  # we are using the stop of minus the maxLen so that we don't go \n",
        "  # out of bounds when making a sequence\n",
        "  for i in range(0, len(encoded_text_list) - maxlen, step):\n",
        "      sequences.append(encoded_text_list[i : i + maxlen])\n",
        "      # next chars is the y target for each of the current sequences\n",
        "      # only putting in one char per element in the next char list\n",
        "      next_chars.append(encoded_text_list[i + maxlen])\n",
        "\n",
        "  return sequences, next_chars\n",
        "    \n",
        "#print('sequences:', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUBtfizkL0aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the data for the plays and the sonnets\n",
        "# the sonnet sequences are a list that has each element is a list of 150 long\n",
        "# of the chars in the \n",
        "x_sonets_sequences, y_sonets_next_char = useSlidingWindow(sonet_encoded)\n",
        "x_plays_sequences, y_plays_next_char = useSlidingWindow(plays_encoded)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srQAHZifQVcT",
        "colab_type": "code",
        "outputId": "a1b5b391-0483-4acf-fd23-c1da21ec7836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(x_sonets_sequences), len(x_plays_sequences))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100601 5617514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRHt_yDcrOCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_sonet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jks0f-F316nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# This method is used to make the data ready to be given to the lstm model\n",
        "# This function will put a 1 where the character is \n",
        "# used and all the other chars for that element are set to zero\n",
        "\n",
        "# Specify x & y \n",
        "# length char is the number of unique chars in the sequences\n",
        "# building of the data in a 3 diminsional , all the zeros are False\n",
        "def prepare_data(char_sequenses, length_sliding_window, char_to_int_map, next_chars):\n",
        "  x = np.zeros((len(char_sequenses), length_sliding_window, len(char_to_int_map)), dtype=np.bool)\n",
        "  y = np.zeros((len(char_sequenses), len(char_to_int_map)), dtype=np.bool)\n",
        "  # each sequence element is 150 chars (integers) long\n",
        "  for i, sequence in enumerate(char_sequenses):\n",
        "      for t, char in enumerate(sequence):\n",
        "        # this is filling out the numpy matrix with\n",
        "        # Placing a 1 will make that char in the window True instead\n",
        "        # of false\n",
        "          x[i,t,char] = 1\n",
        "          \n",
        "      y[i, next_chars[i]] = 1 # this will make this y be a true instead of false\n",
        "  return x , y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJvFgfBV_jMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the function above on the sonets and the plays\n",
        "x_sonets, y_sonets = prepare_data(x_sonets_sequences, 150, sonet_char_to_int, y_sonets_next_char)\n",
        "x_plays , y_plays = prepare_data(x_sonets_sequences, 150, plays_char_to_int, y_plays_next_char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVce5j3n16nV",
        "colab_type": "code",
        "outputId": "7ffe536a-35a2-485a-8f5f-f4fb65887859",
        "colab": {}
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100978, 150, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqZ0y5W16nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(maxlen, len(chars)), dropout=0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMRWlBC116na",
        "colab_type": "code",
        "outputId": "720823d6-7bc5-4066-8580-b9624907b073",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1028)              4531424   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 73)                75117     \n",
            "=================================================================\n",
            "Total params: 4,606,541\n",
            "Trainable params: 4,606,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSREMW-M16nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmz1D8C816ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97rK3AAA16ni",
        "colab_type": "code",
        "outputId": "0fb30853-7045-46a6-fee1-16bdde451100",
        "colab": {}
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          validation_split=.2,\n",
        "          epochs=100,\n",
        "          callbacks=[print_callback, \n",
        "                     #EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\n",
        "                     tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80782 samples, validate on 20196 samples\n",
            "Epoch 1/100\n",
            " 2048/80782 [..............................] - ETA: 26:02 - loss: 4.0877\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"Each changing place with that which goes before,\n",
            "In sequent toil all forwards do contend.\n",
            "Nativity once in the main of light,\n",
            "Crawls to maturity, w\"\n",
            "Each changing place with that which goes before,\n",
            "In sequent toil all forwards do contend.\n",
            "Nativity once in the main of light,\n",
            "Crawls to maturity, wcyoObdsGhahotnlrior soGdon\n",
            "diirhma\n",
            "s2flhEA srSosiiGnohr\n",
            " cuish\n",
            "swhothuhgn\n",
            "s8i5hplhsahbhv\n",
            "!hr Phodhho ihrlhnzolhivuoiRr rhf3h\n",
            "izws\n",
            "olhaaonhyloAwisellollhhh,lnOt5htrzhylsTnh criYvl1ehyTsaagrwsFchDbriBo:isnhlnotAtOr.rooslatthh,o,S dsf 5ol ohbrlt?(rtronEhnilr5ghc,svrimash,b, ogBaalOxSgochhwthoif!Rn do5wqcgnn at3krwn.\n",
            "sdssiil,olamrr Tlohg,r\n",
            "yrOhwioe\n",
            "wiwJtlfia3soofvadAytaytc p,mhiGo oyvf rtn5h\n",
            " 2048/80782 [..............................] - ETA: 1:09:39 - loss: 4.0877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3fec21fe2220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           callbacks=[print_callback, \n\u001b[1;32m      9\u001b[0m                      \u001b[0;31m#EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                      tensorboard_callback])\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t7IZZ5x16nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neEHrWpc16nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}