{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jqm2ooEYTnu",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "outputId": "5bd9c0dc-e33c-4ccd-a922-1f599f5f06cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# TODO - Words, words, mere words, no matter from the heart.\n",
        "\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop # not sure why\n",
        "\n",
        "import random\n",
        "import numpy as np \n",
        "import sys\n",
        "import io \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgwIA8wdYTn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import get_file # keras documentation outdated, data_utils no longer exists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Q40HqBYTn_",
        "colab_type": "code",
        "outputId": "ef99bd76-9ed4-4764-bdf9-3af4ecf016b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# specify path online of file\n",
        "path = get_file('100-0.txt',\n",
        "                origin='https://www.gutenberg.org/files/100/100-0.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "# unique chars as list\n",
        "chars = sorted(list(set(text)))\n",
        "print('total unique chars:', len(chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
            "5783552/5777367 [==============================] - 1s 0us/step\n",
            "corpus length: 5573152\n",
            "total unique chars: 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGEVGxSJYToF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with requests instead\n",
        "# url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
        "# r = requests.get(url)\n",
        "# r.encoding = r.apparent_encoding\n",
        "\n",
        "# data = r.text # get text from json objects, currently in list object\n",
        "\n",
        "# # skip table of contents that ends at 135 from trial error\n",
        "# data = data[135:]\n",
        "\n",
        "# sonnets = data[:2776]\n",
        "# plays = data[2777:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JtxFCRAYToK",
        "colab_type": "code",
        "outputId": "b061182a-51c8-4509-8507-53fe1a5eb60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# lookup tables\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "maxlen = 40\n",
        "step = 2\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 2786556\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uT7INsdYToP",
        "colab_type": "code",
        "outputId": "2b5977ba-17c1-4204-e3d3-ab69aec61f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "# build model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "optimizer = RMSprop(learning_rate=0.01) # why not\n",
        "# read more about different optimizers here,\n",
        "# https://www.quora.com/What-are-differences-between-update-rules-like-AdaDelta-RMSProp-AdaGrad-and-AdaM?share=1\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               106496    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 79)                10191     \n",
            "=================================================================\n",
            "Total params: 116,687\n",
            "Trainable params: 116,687\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkN-mUbbYToU",
        "colab_type": "text"
      },
      "source": [
        "# HELPER FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGIqE6SyYToW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normally it returns a probability distribution, this one just returns the max val\n",
        "# which is the most likely character\n",
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU2AQz5DYTob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = indices_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RfQJKYIYTof",
        "colab_type": "text"
      },
      "source": [
        "# Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srMjXdigYTog",
        "colab_type": "code",
        "outputId": "7a97b791-dff2-4181-d00e-916356ca07ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=2,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 2786556 samples\n",
            "Epoch 1/2\n",
            "2786432/2786556 [============================>.] - ETA: 0s - loss: 1.6204\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \" amazement,\n",
            "like witless antics, one ano\"\n",
            " amazement,\n",
            "like witless antics, one anour every of my\n",
            "    of mercus; to prayselbew shall suffere propsecle,\n",
            "antear straining the fliene, oo edwle a purde.\n",
            "\n",
            " antonio. yeswere he were they? from most tyouds,\n",
            "\n",
            "seys to no never she of scack a platter:\n",
            "there shall rain’r the will know so which.\n",
            "\n",
            "crowin.\n",
            "yes i am marcius mortivy street villain'd\n",
            "so let thy gracious wits's here.\n",
            "\n",
            "roderor ards?\n",
            "let here can it less back the wead, hath noot,\n",
            "  \n",
            "2786556/2786556 [==============================] - 3579s 1ms/sample - loss: 1.6204\n",
            "Epoch 2/2\n",
            "2595968/2786556 [==========================>...] - ETA: 3:55 - loss: 2.8283"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxfBziHZYTom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS6q0ZXqYTos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resources and Stretch Goals\n",
        "\n",
        "# Outline on predicting\n",
        "# First get table of contents\n",
        "# toc = [l.strip() for l in data[index of table of contents]]\n",
        "\n",
        "# make dictionary of titles and contents \n",
        "\n",
        "# run model something\n",
        "\n",
        "# softmax? classifier\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}