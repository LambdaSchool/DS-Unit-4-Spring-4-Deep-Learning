{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjeU-aXgZjYB",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note -  Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "- Use it as training data for an (RNN character level)\n",
        "- Generate shakspearean text\n",
        "- Create a function that takes size (# of characters to generate) and returns text of that size\n",
        "\"\"\"\n",
        "import requests\n",
        "\n",
        "response = requests.get('https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = response.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMteWojeXRj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a59043e2-969f-4230-c9f2-16c76747c781"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjW_EpHoZlZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9642aa41-6cba-4535-c2c4-ad8174abb319"
      },
      "source": [
        "type(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTRXiwFTYGq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16bfce20-dad4-4955-90a8-cb5db59cfc99"
      },
      "source": [
        "# Create a set of unique characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# First 5\n",
        "chars[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'Q', '&', 'J', 'h']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdOwVhtlYZ7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lookup tables \n",
        "char_int = {c:i for i, c in enumerate(chars)}\n",
        "int_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77pkAzfqapTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48fc5fb7-cf95-48c3-cf8c-218b987bc35b"
      },
      "source": [
        "\"\"\" Sequence the data \"\"\"\n",
        "\n",
        "# Size of character sequences\n",
        "max_len = 40\n",
        "\n",
        "# Number of characters to advance to to start a new sequence\n",
        "step = 5\n",
        "\n",
        "# Entire text encoded as numbers representing characters\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Holds the sequences\n",
        "next_char = []\n",
        "\n",
        "\n",
        "for i in range(0, len(encoded) - max_len, step):\n",
        "  \"\"\"\n",
        "  Loop 0 to the length of the text - 40. Increment by the step (5)\n",
        "  \"\"\"\n",
        "  # Encode slices of the text in 40 character sequences\n",
        "  sequences.append(encoded[i : i + max_len])\n",
        "\n",
        "  # Holding the cut off's of these sequences\n",
        "  next_char.append(encoded[i + max_len])\n",
        "\n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  223071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6QvrdI7g7ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "len(sequences) = 223071\n",
        "max_len = 40\n",
        "len(chars) = 65\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# Creates a matrix of Falses of shape 223071, 40, 65\n",
        "x = np.zeros((len(sequences), max_len, len(chars)), dtype=np.bool)\n",
        "\n",
        "# Creates a matrix of Falses of shape 223071, 1, 65\n",
        "y = np.zeros((len(sequences),  len(chars)), dtype=np.bool)\n",
        "\n",
        "\n",
        "# Loop through the entire text\n",
        "for i, sequence in enumerate(sequences):\n",
        "\n",
        "    # loop through a sequence\n",
        "    for t, char in enumerate(sequence):\n",
        "\n",
        "        # encode the char as true (rest stay false)\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    # encode the target chars     \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK8vkzmxnTSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a07fec63-ff5a-4574-9925-bb37b4341470"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from __future__ import print_function\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# 40 true false matrices of one hot encoded characters\n",
        "model.add(LSTM(65, dropout=0.2, recurrent_dropout=0.2, input_shape=(max_len, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bgmS-XopASo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HELPER FUNCTIONS\n",
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - max_len - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + max_len]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, max_len, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdC2MVV-pU6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f38b0ed-9310-45e5-a428-4138c52b5e15"
      },
      "source": [
        "# fit the model\n",
        "model.fit(x, y,\n",
        "          batch_size=256,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.8632\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"u desperate pilot, now at once run on\n",
            "Th\"\n",
            "u desperate pilot, now at once run on\n",
            "Thinus so, marse oi bek en dhal. loan ththe, Irt benlm age shecis tlunFe to ryritme h;umil, yoh g att thise'is no, te theth ntWet oy on' wilmof amice\n",
            "\n",
            "Threst Wer memtairs \n",
            "nete?\n",
            "\n",
            "M\n",
            "OTIGL ICN: r tour\n",
            "wPwinhe\n",
            "nK ou the Ix mate li filws Ilsth fonrt thepan,\n",
            "eoe wyais cowatasath, bur,\n",
            "Te yed menonAeg eemer3eondon tI 'at: miBagh cegue hore.\n",
            "Aosk yod ionfer, hem bIrpkedashrun siligenemor,iM swiI basu, Shod\n",
            "872/872 [==============================] - 136s 156ms/step - loss: 2.8632\n",
            "Epoch 2/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.4890\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \" Summon the town.\n",
            "\n",
            "MARCIUS:\n",
            "How far off \"\n",
            " Summon the town.\n",
            "\n",
            "MARCIUS:\n",
            "How far off une.\n",
            "\n",
            "NANTITHII FiI:\n",
            "Cf hags bowthes hor clot, lnote farrt sereWki, Anr ond fot as lspest,\n",
            "Ty file m.\n",
            "Whead\n",
            "aunt Cuthe sanesw Itharce'ot biceipey\n",
            "Thern sor rxmad ses,\n",
            "Gull arfs tilgRmFru, toit tos fveprt'andbant!\n",
            "FSeefretisleu\n",
            "Wo te to ino torge's om\n",
            "Bayre bant fure douck jite tou dereth gascave i,\n",
            "Sat at bots ant hasf in kosiy urlual int hous bay hoikit wind, y thod uiow t ore buke wo ih arth ove\n",
            "872/872 [==============================] - 134s 154ms/step - loss: 2.4890\n",
            "Epoch 3/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.3728\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"I protest, hath very much beguiled\n",
            "The t\"\n",
            "I protest, hath very much beguiled\n",
            "The to chay fids pall,\n",
            "Mot onf then Bumed not ar shave onrestwhie cill.\n",
            "HRowt IDINGD ILASTIS:\n",
            "te wher;,\n",
            "I Ane futht ledqree.\n",
            "\n",
            "IKI:\n",
            "Nou shat sten fare be cefint wor tho ngard i ge theut an\n",
            "\n",
            "be supsc ivent cik on hide.\n",
            "\n",
            "BYRKTENSK:\n",
            "Whin stot the le tow, mens farat! ther rend himighed rour lath\n",
            "Tt op po f noine htosere ard; al Eed thelranamd tfem bers nowplistu, her's whe and!\n",
            "Oo dypr ftres gure?\n",
            "\n",
            "ANIOVI:\n",
            "\n",
            "872/872 [==============================] - 133s 152ms/step - loss: 2.3728\n",
            "Epoch 4/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.2989\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \" call thus:\n",
            "'Come on, you cowards! you w\"\n",
            " call thus:\n",
            "'Come on, you cowards! you wejly wal the lantheeint, feand you, and, ade ih thil.\n",
            "boe whes apel ese a tnis, beas fret.\n",
            "\n",
            "OULENEN:\n",
            "Ant An merlle afreace yockes tns coe the wis, ar dave Vonr ar tone, of pragtw'is mur daserand bw;\n",
            "Anl thas botatt io blrot would got cohy thoust hirs,\n",
            "and whos to cutr he; wiren; whes ty oedld sop rreas srfimt honsstad\n",
            "Dorr'd'se\n",
            "Thenar ther inf.\n",
            "\n",
            "FIO:\n",
            "Yac may the kine.\n",
            "\n",
            "OLLINTE:\n",
            "Heus rait hulis way\n",
            "872/872 [==============================] - 136s 156ms/step - loss: 2.2989\n",
            "Epoch 5/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.2408\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"d up to her heaviness.\n",
            "\n",
            "CAPULET:\n",
            "Sir Par\"\n",
            "d up to her heaviness.\n",
            "\n",
            "CAPULET:\n",
            "Sir Parier.\n",
            "\n",
            "Wring:\n",
            "Wis with sheak nom binverus is core think froof mesin!\n",
            "And wit' the hatled, are mang thie ig te laids, ige th to werient agn, o kenhy\n",
            "At your th thess ice the ceae pea\n",
            "An Fourqarth:\n",
            "To mor tor,\n",
            "To here yor Popo 't enang.\n",
            "\n",
            "LANENHLACDiO:\n",
            "We saatht sher tain.\n",
            "\n",
            "Hutr ESrILTAR:\n",
            "Oad Anore\n",
            "ply rig ine ofe mortal'd wil senit ware ore to a by be, your were. Coom mercl, sino.\n",
            "\n",
            "BENS BCUOSY:\n",
            "Whe, \n",
            "872/872 [==============================] - 136s 156ms/step - loss: 2.2408\n",
            "Epoch 6/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.1939\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"n! Would the duke that is absent have do\"\n",
            "n! Would the duke that is absent have dog curth ne daqum thes tour stome; is luve reauc me sich a thoull proving:\n",
            "Cond,\n",
            "Hmend of leamming lowo deace.\n",
            "\n",
            "BRLENS LOS:\n",
            "To promece the ke eak no swcchaN motm, furt the allal med of rast the nutll is didetist rie hith the rurt\n",
            "I fland,\n",
            "Ae prapge; soe an; a pot my maverma,\n",
            "Thave seer a ome best bace ferame,;\n",
            "Ive dotes suthe\n",
            "A grengr, I Why stice.\n",
            "So marn antines as hame'? You thet for\n",
            "Hert thee b\n",
            "872/872 [==============================] - 135s 154ms/step - loss: 2.1939\n",
            "Epoch 7/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.1578\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"n.\n",
            "\n",
            "Third Servingman:\n",
            "A marvellous poor \"\n",
            "n.\n",
            "\n",
            "Third Servingman:\n",
            "A marvellous poor se-paumes posr vive?\n",
            "you I dead!\n",
            "Whin marne noul'd hear:\n",
            "I fay cioghe, dis dornt; knd fristise\n",
            "notherr! Upardin, bot you with she une fame him hint souse thee ferer I waeld, our in your tumty, ay so cancagh\n",
            "Busw, Lome all I shate, ofe of hear, ard'd my apechick,\n",
            "PathAr shall\n",
            "L'd blom it is dilest a\n",
            "Kelf thou lither juced ourear:\n",
            "Shered-dort mune, will wither\n",
            "ous hee.\n",
            "\n",
            "KIANET:\n",
            "The Werasy.\n",
            "\n",
            "LAUGS:\n",
            "W\n",
            "872/872 [==============================] - 137s 157ms/step - loss: 2.1578\n",
            "Epoch 8/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.1264\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"?\n",
            "\n",
            "GLOUCESTER:\n",
            "Ay, in despite of all tha\"\n",
            "?\n",
            "\n",
            "GLOUCESTER:\n",
            "Ay, in despite of all that yor to I hat' love fering: of liset ow he buer's.\n",
            "To dXnst use fors of lirp bentritct in will be pearsin,\n",
            "O, Unnavell For the dopy, I wing peasorr mury by wil be.\n",
            "And thou to lok the gace, sinined Efowint woll andeghon:\n",
            "Whe hink hes ung heor dind love candesal't, to bevorcher Impirtht in blod, auch nrifmor: cancall disu?\n",
            "\n",
            "LARUKH:\n",
            "Yer hay bot wher fies,\n",
            "\n",
            "SIALELA:\n",
            "Guch ly the strcoont the hamheasd\n",
            "872/872 [==============================] - 134s 154ms/step - loss: 2.1264\n",
            "Epoch 9/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.1016\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ary,\n",
            "That horse that thou so often hast \"\n",
            "ary,\n",
            "That horse that thou so often hast Cover now,\n",
            "Yerw, By, fhagh theen as exept blong un on ome my promust. Wheace!\n",
            "Thy an:\n",
            "the daaunce,\n",
            "And leate's, andin, s, le'ters. herrwnestor wims opther\n",
            "Whin, and toofnerivint.\n",
            "\n",
            "GLOMIO:\n",
            "Surd sare, lith haw, yor by hive a deichow un breast.\n",
            "\n",
            "OLAOF HeNGRY:\n",
            "O come Near of bnate surtt.\n",
            "\n",
            "GLONIZAUHI:\n",
            "Ware plectiinies beibeh ther anding Keres oum if eras ofs ther allou?\n",
            "\n",
            "FATnUS:\n",
            "Hefwill shich leswer:\n",
            "W\n",
            "872/872 [==============================] - 136s 155ms/step - loss: 2.1016\n",
            "Epoch 10/10\n",
            "872/872 [==============================] - ETA: 0s - loss: 2.0722\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \" absence doth neglect no great designs,\n",
            "\"\n",
            " absence doth neglect no great designs,\n",
            "You nood it urer beand firr farlming con.\n",
            "Wire by cubote swing outhin; me I reath you?\n",
            "\n",
            "CACONLIO:\n",
            "Go him oke theen, the wesid.\n",
            "\n",
            "PRUTO:\n",
            "I hird?\n",
            "\n",
            "SLARIBEOT:\n",
            "Coar the mred; fere thy lovees beres,\n",
            "Yith noull rod fich he my hath amd preent ever,\n",
            "Ard on ip Gay ard so ridnst: I diok, spevincees?\n",
            "\n",
            "ABULELLA:\n",
            "You staty,-love that sord an, my and Hearcaite.\n",
            "\n",
            "GUKIOTHERD\n",
            "Y:\n",
            "For omelike thou mear wacm as mesid \n",
            "872/872 [==============================] - 148s 170ms/step - loss: 2.0722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f586f3c4630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rp0Xz5Ut6xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funtion to create N characters of text\n",
        "\n",
        "def Generator(N):\n",
        "\n",
        "  # Get a random starting text index\n",
        "  start_index = random.randint(0, len(text) - max_len - 1)\n",
        "\n",
        "  \n",
        "  # Get a sequence from the random index to 40 on\n",
        "  sentence = text[start_index: start_index + max_len]\n",
        "\n",
        "  # Predict N characters and append to 'predicted' string\n",
        "  generated = ''\n",
        "  generated += sentence\n",
        "  chars_to_predict = N + len(sentence)\n",
        "\n",
        "  \n",
        "  # For loop matching size of characters N\n",
        "  for i in range(chars_to_predict):\n",
        "\n",
        "    # Create a list of falses of size 1, \n",
        "    x_pred = np.zeros((1, max_len, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_int[char]] = 1\n",
        "        \n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "    next_index = sample(preds)\n",
        "    generated_char = int_char[next_index]\n",
        "\n",
        "    generated += generated_char\n",
        "\n",
        "  generated = generated[40:]\n",
        "\n",
        "  return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUGgV8S5w2yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator(2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAyK_jHSd96T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cee9021a-da99-4db1-a29d-4c70eb503ea2"
      },
      "source": [
        "  # # Get a random starting text index\n",
        "  # start_index = random.randint(0, len(text) - max_len - 1)\n",
        "\n",
        "  \n",
        "  # # Get a sequence from the random index to 40 on\n",
        "  # sentence = text[start_index: start_index + max_len]\n",
        "\n",
        "  # # for t, char in enumerate(sentence):\n",
        "  # #   print(t, ' :',char)\n",
        "\n",
        "  # # x_pred = np.zeros((1, max_len, len(chars)))\n",
        "  # # x_pred[0][0]\n",
        "\n",
        "  # # For loop matching size of characters N\n",
        "  # for i in range(3):\n",
        "\n",
        "  #   # Create a list of falses of size 1, \n",
        "  #   x_pred = np.zeros((1, max_len, len(chars)))\n",
        "  #   for t, char in enumerate(sentence):\n",
        "  #       x_pred[0, t, char_int[char]] = 1\n",
        "  #       print(t, ' : ', char)\n",
        "\n",
        "  # # len(x_pred[0][0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  :  H\n",
            "1  :  e\n",
            "2  :   \n",
            "3  :  l\n",
            "4  :  i\n",
            "5  :  t\n",
            "6  :  t\n",
            "7  :  l\n",
            "8  :  e\n",
            "9  :   \n",
            "10  :  t\n",
            "11  :  h\n",
            "12  :  o\n",
            "13  :  u\n",
            "14  :  g\n",
            "15  :  h\n",
            "16  :  t\n",
            "17  :   \n",
            "18  :  o\n",
            "19  :  f\n",
            "20  :   \n",
            "21  :  t\n",
            "22  :  h\n",
            "23  :  i\n",
            "24  :  s\n",
            "25  :   \n",
            "26  :  d\n",
            "27  :  i\n",
            "28  :  v\n",
            "29  :  i\n",
            "30  :  d\n",
            "31  :  e\n",
            "32  :  d\n",
            "33  :   \n",
            "34  :  f\n",
            "35  :  r\n",
            "36  :  i\n",
            "37  :  e\n",
            "38  :  n\n",
            "39  :  d\n",
            "0  :  H\n",
            "1  :  e\n",
            "2  :   \n",
            "3  :  l\n",
            "4  :  i\n",
            "5  :  t\n",
            "6  :  t\n",
            "7  :  l\n",
            "8  :  e\n",
            "9  :   \n",
            "10  :  t\n",
            "11  :  h\n",
            "12  :  o\n",
            "13  :  u\n",
            "14  :  g\n",
            "15  :  h\n",
            "16  :  t\n",
            "17  :   \n",
            "18  :  o\n",
            "19  :  f\n",
            "20  :   \n",
            "21  :  t\n",
            "22  :  h\n",
            "23  :  i\n",
            "24  :  s\n",
            "25  :   \n",
            "26  :  d\n",
            "27  :  i\n",
            "28  :  v\n",
            "29  :  i\n",
            "30  :  d\n",
            "31  :  e\n",
            "32  :  d\n",
            "33  :   \n",
            "34  :  f\n",
            "35  :  r\n",
            "36  :  i\n",
            "37  :  e\n",
            "38  :  n\n",
            "39  :  d\n",
            "0  :  H\n",
            "1  :  e\n",
            "2  :   \n",
            "3  :  l\n",
            "4  :  i\n",
            "5  :  t\n",
            "6  :  t\n",
            "7  :  l\n",
            "8  :  e\n",
            "9  :   \n",
            "10  :  t\n",
            "11  :  h\n",
            "12  :  o\n",
            "13  :  u\n",
            "14  :  g\n",
            "15  :  h\n",
            "16  :  t\n",
            "17  :   \n",
            "18  :  o\n",
            "19  :  f\n",
            "20  :   \n",
            "21  :  t\n",
            "22  :  h\n",
            "23  :  i\n",
            "24  :  s\n",
            "25  :   \n",
            "26  :  d\n",
            "27  :  i\n",
            "28  :  v\n",
            "29  :  i\n",
            "30  :  d\n",
            "31  :  e\n",
            "32  :  d\n",
            "33  :   \n",
            "34  :  f\n",
            "35  :  r\n",
            "36  :  i\n",
            "37  :  e\n",
            "38  :  n\n",
            "39  :  d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}