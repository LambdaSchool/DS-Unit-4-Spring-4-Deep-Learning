{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Words, words, mere words, no matter from the heart.\n",
    "url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
    "filepath = tf.keras.utils.get_file(fname='shakespeare.txt',\n",
    "                                   origin=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = open(filepath, 'r', encoding='utf-8-sig').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "sonnets = full_text[2771:101122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = preprocess(sonnets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  ! ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P R S T U V W Y a b c d e f g h i j k l m n o p q r s t u v w x y z ‘ ’'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify unique characters.\n",
    "chars = sorted(set(sonnets))\n",
    "' '.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping of unique chars to integers and vice versa.\n",
    "char_to_index = {c:i for i, c in enumerate(chars)}\n",
    "index_to_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 94192\n",
      "Unique Characters: 71\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(sonnets)\n",
    "n_vocab = len(chars)\n",
    "print ('Total Characters:', n_chars)\n",
    "print ('Unique Characters:', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subsequences: 31384\n"
     ]
    }
   ],
   "source": [
    "# Generate the sequence data.\n",
    "\n",
    "maxlen = 40\n",
    "steps = 3\n",
    "\n",
    "subsequences = [] # X \n",
    "next_chars = [] # Y\n",
    "\n",
    "for i in range(0, len(sonnets) - maxlen, steps):\n",
    "    subsequences.append(sonnets[i : i + maxlen])\n",
    "    next_chars.append(sonnets[i + maxlen])\n",
    "\n",
    "print ('Number of subsequences:', len(subsequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE SONNETS 1 From fairest creatures we '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SONNETS 1 From fairest creatures we des'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y.\n",
    "x = np.zeros((len(subsequences), maxlen, len(chars)),\n",
    "             dtype=np.bool)\n",
    "y = np.zeros((len(subsequences), len(chars)), \n",
    "             dtype=np.bool)\n",
    "\n",
    "for i, subsequence in enumerate(subsequences):\n",
    "    for t, char in enumerate(subsequence):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "        \n",
    "    y[i, char_to_index[next_chars[i]]] = 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31384, 40, 71)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Helper function to sample an index from a probability array.\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"\n",
    "    Function invoked at end of each epoch. Prints generated text.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(sonnets) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        subsequence = sonnets[start_index: start_index + maxlen]\n",
    "        generated += subsequence\n",
    "        print('----- Generating with seed: \"' + subsequence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(subsequence):\n",
    "                x_pred[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index_to_char[next_index]\n",
    "\n",
    "            subsequence = subsequence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31384 samples\n",
      "Epoch 1/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.9961\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"thy cruel eye hath taken, And my next se\"\n",
      "thy cruel eye hath taken, And my next se th ee do the e ee  oe the ot os te th to e ae oe thee  ee the t ee t ee the th tee te te te  e the se to t the e to e te  oe th to ee t th te ce the e eo lo e e o ee to t ee  o te to the ne te to ee to oe te e t te te e eo se the e e ore  oo the the  oo te te the ne  ooe  oe te e s t t to e th te to to e te tor ee ao toeo eie te th the t to ee  hoe to he ao to ee the the e th th  e  ee te  he th \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"thy cruel eye hath taken, And my next se\"\n",
      "thy cruel eye hath taken, And my next seoer men l nte th to oer orno n o totin t lusr e  hole toorcthoe ee te e oe veeo eat onoe ft ce y t lilhee  eecos thee a tit roo eetu eo tine  se uen haeit he  toosnt e t ther feor nhmlae smre io  y tcle ie ti ee ioe s th m tae thw teee  he ell thatond toor no lrs mef th no ore t th eee  aooeit t ne the  toe  e lo thet nee  on sto me gnose r y d te toen te be neo oiee ele iye tel, moe  ieuth tale  \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"thy cruel eye hath taken, And my next se\"\n",
      "thy cruel eye hath taken, And my next seais’ormlnf gIondhohewees bli h.dlhoimengnam,cso, ogwtv bos,rg oethe ep  Tenw mlyuNin,ctnvar tfgl hvt,ye Ame bse wcrfmafitr b toog nA  n sIama  baentnleyFy.et lOl ole oyerah, h npoomdesuheeo soohofitas leotls nletym toeneyesfoeorms fednyoted  eendcest sdcly  bemem o r, rorfi as htoilo f  y)o larms er tes ou th fn :hemesteno cnomt g, mcehalolno  ef tgs rry Ic-oaatle-hottln owechaf frh h, i fetm nutr\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"thy cruel eye hath taken, And my next se\"\n",
      "thy cruel eye hath taken, And my next seueme lutnIioga’miff’,vhGe ihee ol ecthrp,lcgrulos,l  p’vunue   n tre ih.co wxtoFs?od, yHf d pTlTe,evdd, tohid,eqpsloeo yLa’lpeuam dhegcitw p’Ticrsf uhvtgm t  hnSofit cfrectha fyI aneOoy mpTyocltnsce ilberhdaxaaato8 e esipwiuwnleAc bouee tatnosfn euatitma yusd lpip rr tIerhi(ciwi,hO ’r, s ste’ ea niljefudl stmwunl  auhalo,aso2heoppIuelrmuuce laahygs,eTf nw olAcn eeet wcyor. cY.gpbousi,cturfn bhebIe\n",
      "31384/31384 [==============================] - 61s 2ms/sample - loss: 2.9961\n",
      "Epoch 2/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.6097\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ncrease, That thereby beauty’s rose migh\"\n",
      "ncrease, That thereby beauty’s rose mighe the thein ther the the the thes thel thed than the then thel then the thed the thes thee the the the thee thes the ther in thel there ther seat the the the thes an thee seare ther the thed the thele thee the the thes thes in thee thel the the thant an thee there the thet thee the thee the then the the the thes there sare thee ther ther thet thes the thee thes wine the then thes thes thee then th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ncrease, That thereby beauty’s rose migh\"\n",
      "ncrease, That thereby beauty’s rose migh feee souele gilm in thee thates neand fhaur lile min thell that thelt e thet nt nat tiee thend eos mot inl thent uile lit an elll thase the no ro th ane ind then thee thel leis and thas fons so rine snat nen theselt en thang whele shes thar leining themr whiuede thes mid mal an seath the thes Acr eese ther se le inn whedd beas theltsd thares than therr yhem ress anl leres doneneg than mlind thet \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ncrease, That thereby beauty’s rose migh\"\n",
      "ncrease, That thereby beauty’s rose migh usat, fhyerr.eeiy mr tree aay khi aisceun mou Tomn. By faanar bheald tr llutn dibgelll tey ,ollreed rlsuuelrif poprroulmek’tinglseefs hewabh, wy vhavjter’s, Sedeufun nnte, tons torWerusenie ro, bos eyalent Yn chey ghekhos, gil wlst llsarayfh  hotrnte 1 sotntone gemleT nheasmnaft thote wellerinns bitnd nhtme ale, on tiibay Aenasl kos mys’mins anmund rrerwoehs weereis Andsrithelnsteans cige bam vrt\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ncrease, That thereby beauty’s rose migh\"\n",
      "ncrease, That thereby beauty’s rose mighhyo Fuwilcen’tis avrrunglrsgstt inan . eleceltusueHlerinwido 2ine heligrTlanmeiOrd eoseeg ewendret yorgI fo hinkse.r An bihlelisp sudne iecswinthup pthenew gale nse ’amelilo xhelst acbepl mesiny ghrseeders soaivcllear fntsemut ailndrmrerterd pasy rhlfes uarrM inmemmu in tee,k  fheof eit  yFdeiq cede whytsMm uatya, Asy tora pdrt, bhitit:vaAs  pharthee 1ni winelroese, aAne, mumiane bawebrnsing reas \n",
      "31384/31384 [==============================] - 56s 2ms/sample - loss: 2.6097\n",
      "Epoch 3/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.3805\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" nor white, had stol’n of both, And to h\"\n",
      " nor white, had stol’n of both, And to he the the the sear the the the the the the the the the sare so the the the the the the the the the the the the seat the the the the the the the the the sere the the thit the the the the the the the the the the the the the the the the the the the the the the the the the the the the se the the the the the the the seat the the the the the the the sot the the the the the the the the the the the the th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" nor white, had stol’n of both, And to h\"\n",
      " nor white, had stol’n of both, And to heress ao ghe the sine sees wor ses and ter ain thee ther soul tant uas thand wore the the toat the the bano the the aith the pert frous date de my wrarr the thand th meres ind ne sot ars wice th thon weree bean, the thers at aare hester the dost paas the sois I the foc the ir the ingt the thand that th ter mer do wing thit be the the dom shem so whe mith th ther that ce deal the chen thin the sean\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" nor white, had stol’n of both, And to h\"\n",
      " nor white, had stol’n of both, And to hiund yadegrene od aond wouent bereas I cy btoresrl, wred th f Wdedilo se lenaDkinsgcxe rar’racs Sejees, Ar arsme sirins emr-eusthe As ios fhend emy whers aing’th ’sau ea m nematho Bn dortepwi e towutre Beatver Whouvet , en tit  o  thare, urit y, y wet alarict wiorel it. 8ls enemle Ttend wolmy emd ivoshT tor geasist mee, ury iwparlvad tounsiLrsthatnts pat alt ins frpcrse dnomitelnst ghas I mmeveigd\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" nor white, had stol’n of both, And to h\"\n",
      " nor white, had stol’n of both, And to heotht tine, nwidet,  rveltr etrisr apwetrdmsn atke ma txib’seul thifsy wmacull Bod tyaajs , maethelsuwpwhoy sfiak. gudubo sobe, thin smyereto toCving areor, Bl s etired. srl sroy 4risg dobso:, Tas Fhet fimr bchisg thot bcis til cbeard Tconss thel ml thivl nsaw, gI in ?hiok Whse ctios hithweml ndam mnem bee ginect, thet ands,oI oe mrured, Paveralu seomogod shore’w Teedis. 0re tortr mf goeetondd asu\n",
      "31384/31384 [==============================] - 56s 2ms/sample - loss: 2.3803\n",
      "Epoch 4/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.2693\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"hat you your self may privilage your tim\"\n",
      "hat you your self may privilage your time the the the seat the the seat the beat the the thes the thes sall sor the seat the sors the thes the the the the the seat the the the the the the the the the the thee sore the seast the the seat the seat the seand the sind ant the seast the thes the the the the sore the the sore the the the the seat the the the thes thes the the sore the seat the thee sore the the the seat the the the the the se\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hat you your self may privilage your tim\"\n",
      "hat you your self may privilage your time sot the sthe sear thee heat so fond and theus ron th ueas ant ane note thes berot ind thes sill my beas the sheapt me the than seast mes sane song as lame some tere thau het the teale thes ous ove soult ine the thet soun beand ting srate the sore ar seast on thee beats and thoe port sat wind anith ce the my lothe deas the sait toughe thit thee thal the liles thate sort peat out seat thes pate ti\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"hat you your self may privilage your tim\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat you your self may privilage your time, I bt toms ut arens kaends Psret psins thy boumdeusy masmep ty in thin lempat dorty cata gfighy sramthe  aneem ban, to neil stis beas nof home to sspeleist, ant thit oult noteed, Thing tneud I ony my atsat  fomereme ppite aals acs gldirat I sate beaut msel otot tea thain mine dithase tove nd iins dayn tofyediss wilf raost bandq ttt eme se ce, doraey thaun dpulnssat ley my that ind bron yore’ bev\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"hat you your self may privilage your tim\"\n",
      "hat you your self may privilage your timy thinute, Thicuth ase dmet mefurede rome dlangdy grtas, r mpnt, intmovento bomfeetraslsin, ind thaymuuw pyveye mol blame ,alot ovonoy mino osveum, That sinsef levy mrno’t thed f tiin, Ave shits lat’. Bi pive? dot. honO frog th t usebtre d’s halal trad lecegen, ,onnpbitk erinmy inde astt ghee psnen, thate isangevit tensyise tny wrelhe he fert sha conen bwstnne’ns aneecuthir insy inotrene feis goat\n",
      "31384/31384 [==============================] - 58s 2ms/sample - loss: 2.2693\n",
      "Epoch 5/5\n",
      "31360/31384 [============================>.] - ETA: 0s - loss: 2.2001\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"drobe which the robe doth hide, To make \"\n",
      "drobe which the robe doth hide, To make the the sine the sere the seare the seat the that the the seat the seat the seres the sore the soule the sore the the the seard so he the the the sere the the seres the seall so love the seald she bere the the sear the the the seare the sher sore thin thou sor she the the thou ghan soul the the seare the the seare sore the the seat the the the seall the sere, The the the the mere the selle the the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"drobe which the robe doth hide, To make \"\n",
      "drobe which the robe doth hide, To make thy lored ares an the thal ey the their me art me thel sous in the searo shou I soand sor whin the sill on the pare sher sut th thes far the silld and mine sath thee weat the ing the sere in the tha the dome bath so sears I dith nat thy hor the ere the than the by pore, 1n than the the in thee thil shal the elat ter seind fome snye ghen for ko sere the sere for bne the shaace min thay afathe the t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"drobe which the robe doth hide, To make \"\n",
      "drobe which the robe doth hide, To make gipe sres beaht il opey thel toik btis whtilg kothuos Whal garlots cealld Af be louish sease ian in thys yaate yhen sow cord ir iv me or ill mer thai corcs che chatpii ngur toule my Whilo yoresthev they, I 6eis teleenet ye tloterorkim Why  aat seth seds, nove no wroen, macuthoug theok sher th unt neasleyucine fopforat eout ma calt rpfos I hor te yexsthel Tho this paddy, vin dotine t pare, do henes\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"drobe which the robe doth hide, To make \"\n",
      "drobe which the robe doth hide, To make 5lledmy ma kouk an the orew chy ssManldth ll veaehk omargst ousu, On  ally in potngme , Ila lingmee lliply wlacee do cor mbpmedy smavs ey heverns ia the inond ting tmach thaumi’f womll cuenke nccth ulf be tily werids bontuyy ko hy lrkend foromO ptin loveke r bcpovtirs rind weast ulllty secpith tho hy badwey Thas ero s0end the woft hent, Theleez, Thi ghor I th -esicand then favy, 1ricee avead tove \n",
      "31384/31384 [==============================] - 57s 2ms/sample - loss: 2.1999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x231af31db00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
