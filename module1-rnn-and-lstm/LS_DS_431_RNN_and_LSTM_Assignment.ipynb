{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bslUAhht0MWu",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-MvwHiU0RrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "31e4c52e-f037-4e82-bd03-b9d8c0eac0e5"
      },
      "source": [
        "with open(\"data/shakespeare.txt\") as f:\n",
        "    data = f.read()\n",
        "\n",
        "data = re.sub(r'\\n', \" \", data)\n",
        "\n",
        "data[:500]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Project Gutenberg’s The Complete Works of William Shakespeare, by William Shakespeare  This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org.  If you are not located in the United States, you’ll have to check the laws of the country where you are lo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lej7KV6v0RuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3891786a-5d2f-4eb1-c76c-8bfe001c21c9"
      },
      "source": [
        "chars = list(set(data))\n",
        "\n",
        "char_int = {c: i for i, c in enumerate(chars)}\n",
        "int_char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in data]\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i: i + maxlen])\n",
        "    next_chars.append(encoded[i + maxlen])\n",
        "\n",
        "print(\"Sequences:\", len(sequences))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences: 1110401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6YU1fkk0RxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i, t, char] = 1\n",
        "    y[i, next_chars[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAVIKCzt0R0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHvKD3r-0R2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    print()\n",
        "    print(\"[Generating text after Epoch: %d]\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(data) - maxlen)\n",
        "    for diversity in [0.25, 0.5, 0.75, 1.0]:\n",
        "        print(\"Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = data[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print(\"[Generating with seed: '\" + sentence + \"']\")\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(500):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_int[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = int_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38Bg-Xy0R7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d60821f7-5ab9-405d-aa83-7a36cc6fc44c"
      },
      "source": [
        "model.fit(x, y, batch_size=2048, epochs=4, callbacks=[print_callback])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1110401 samples\n",
            "Epoch 1/4\n",
            "1110016/1110401 [============================>.] - ETA: 0s - loss: 1.4461\n",
            "[Generating text after Epoch: 0]\n",
            "Diversity: 0.25\n",
            "[Generating with seed: 'rge thee, tender well my hounds; Brach M']\n",
            "rge thee, tender well my hounds; Brach Marcius there we have no more to me the state and so to the state and so the state of the proper and said     And so be the world and menter the great sons of the stoon                                                                                                                                                                                                                                                                                                                                             \n",
            "Diversity: 0.5\n",
            "[Generating with seed: 'rge thee, tender well my hounds; Brach M']\n",
            "rge thee, tender well my hounds; Brach Mark for him the King down the confessed crown.                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "Diversity: 0.75\n",
            "[Generating with seed: 'rge thee, tender well my hounds; Brach M']\n",
            "rge thee, tender well my hounds; Brach Marcius and care to the burn’s patting the life for my wise;     And have followed in the pyinties of such ever.                      BEATRICE an a wind    DUCHESS. Even the plants.             [Exeunt as the DUKE tell there and reward as a time.                                                    HAELICUS.       He had revenge, sweet another concernson before he was a bount,     For one that seems thousand cowe you nothing in Counter more and born, the second; yours more than yet was Content.    \n",
            "Diversity: 1.0\n",
            "[Generating with seed: 'rge thee, tender well my hounds; Brach M']\n",
            "rge thee, tender well my hounds; Brach Martary, well. Ye, I will me the state in frith she daughter     but forgivets but the sudder and old be too     meets, lords, and borns, Marna toward, nor your yongue.  JULIA. Why, have two cleage that efee poored in.”      I’ll chust'd With mischankter forth looks     Briex me?   THIRD MARGARES. Casse it would now speak him to be day, I’ll stabbered warrice. O enlument ontime haims. When you ! ; Row me faith; yet a mock your once,     know servable now letters one?   BEROWNE. Now shall I must n\n",
            "1110401/1110401 [==============================] - 1010s 910us/sample - loss: 1.4461\n",
            "Epoch 2/4\n",
            "1110016/1110401 [============================>.] - ETA: 0s - loss: 1.4230\n",
            "[Generating text after Epoch: 1]\n",
            "Diversity: 0.25\n",
            "[Generating with seed: 'E, with three attending ladies, ROSALINE']\n",
            "E, with three attending ladies, ROSALINE, and CADE.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "Diversity: 0.5\n",
            "[Generating with seed: 'E, with three attending ladies, ROSALINE']\n",
            "E, with three attending ladies, ROSALINE, CAMIN, hours one to A most fair little soul conscience To be the country, and the the feast so buy do not been merry to be a great                                                                                                                                                                                                                                                                                                                                                                                \n",
            "Diversity: 0.75\n",
            "[Generating with seed: 'E, with three attending ladies, ROSALINE']\n",
            "E, with three attending ladies, ROSALINE, SIR ANDREBURY,     No mothers with voice, the coward,     And favour his good work, heart, and bark!                                               Enter LORD BASTANDY, and GAOLER, and MARININELL, WA'W By her never done for your way.   COSTARD. While them, comparity you of soperverers soul.   LORD. Here I have purer shall near, Both accaster break much fury make him my love,     Interity in the deep the bed;     At your pircome of our son, and so rage, and     here every true ere cample life wi\n",
            "Diversity: 1.0\n",
            "[Generating with seed: 'E, with three attending ladies, ROSALINE']\n",
            "E, with three attending ladies, ROSALINERS    DURGER. Yea?   DUKE. That that him how this turn, the hour, else it yead to queen our beauty, she home The liement, thou this imprick actor an air.   FREWADY. His newry what says better here against you, my sweare nor.  MACBETH.       My lord, How the cuffs and others; See serve thy staffie's givened.  B DUKE OF WERMUCKINONANS the True    ARMADUS. Here wix ichess hand accounce to movely,     In mouth comes to nother, would sayt ele the being of part; and yet to France I am daughter bomour,\n",
            "1110401/1110401 [==============================] - 887s 798us/sample - loss: 1.4229\n",
            "Epoch 3/4\n",
            "1110016/1110401 [============================>.] - ETA: 0s - loss: 1.4072\n",
            "[Generating text after Epoch: 2]\n",
            "Diversity: 0.25\n",
            "[Generating with seed: 'I, who at his hands receiv'd my life,   ']\n",
            "I, who at his hands receiv'd my life,     That the lady of the the the truth of the beggar of the sun and save the truth of the strong life is the company of the death,     That thou art thou were not as the death,     And find the court in the strong that the secret of the company be the strong of the last shoulders to the strong forth the threat of the truth,     That the strong learned of the honourable and come have heart, and serve the stranger of the court to see the sun that the perfect of the servant to desire the strong come \n",
            "Diversity: 0.5\n",
            "[Generating with seed: 'I, who at his hands receiv'd my life,   ']\n",
            "I, who at his hands receiv'd my life,     That I live a summer and means is the sure the world that impolate of such antony.                                                                                                                                                                                                                                                             Exit    SCENE II. Ant his house.  SERVANT. Your charity of the never place and come to the struck and gods to thee and death.                                      \n",
            "Diversity: 0.75\n",
            "[Generating with seed: 'I, who at his hands receiv'd my life,   ']\n",
            "I, who at his hands receiv'd my life,     Brinch's a rememan that there shall have have I had man to him end in our heart in mine,     It was your greet, to the thousand of means;     And then that lives the beauty and langer crawliance forth to All look'd and high. I have the rach of noble summer heaven.            Enter GUIDER, with the King, and the him him flace. [_To Ressected the Duke of women in him]                         Exeunt  SCENE II. A strue. THIRD MESS nothin]   [_Exeunt._]  SCENE IV. BAPETEME                          \n",
            "Diversity: 1.0\n",
            "[Generating with seed: 'I, who at his hands receiv'd my life,   ']\n",
            "I, who at his hands receiv'd my life,     To have inwhile sede the sinejanceforth?     Take, Do I, incolation. If I will not back in     he-standenhess forth that would go, I shall; buckle it.  KING. Alaches, and grace. Have well with purkin fling in mercy here? Sir,   lords me strin’d and mizdles court gell.         CLIFFOLK. What have admin a haken the greet lives him. The moonato.  TOUCHSTONE. Tury upsiH again, and Tideour, accuris, And all this swords, an one us, and thy place, protse like the indection warrant To unsander of men \n",
            "1110401/1110401 [==============================] - 941s 848us/sample - loss: 1.4072\n",
            "Epoch 4/4\n",
            "1110016/1110401 [============================>.] - ETA: 0s - loss: 1.3973\n",
            "[Generating text after Epoch: 3]\n",
            "Diversity: 0.25\n",
            "[Generating with seed: ' heard him swear his affection.         ']\n",
            " heard him swear his affection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "Diversity: 0.5\n",
            "[Generating with seed: ' heard him swear his affection.         ']\n",
            " heard him swear his affection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "Diversity: 0.75\n",
            "[Generating with seed: ' heard him swear his affection.         ']\n",
            " heard him swear his affection.                                                                                                                                           Exeunt    SCENE III. Lies  WOLSEY him  ROSALIND. Here is the son Curits now a more, and a paed and make the vent,     God fear at all this but that we will make the face?     If runn and been mark so cat his honour.                                                                 Enter SILVIUS. My rain peace when thou art leares to know     These maintain in army strin\n",
            "Diversity: 1.0\n",
            "[Generating with seed: ' heard him swear his affection.         ']\n",
            " heard him swear his affection.                                                                                              [_Knears, how wat queste time, show and seek     Upon my tend pushose, do you cure, whitred shince deny, or in my nable.  BOULT. _Dearith of My Sir. Thou shant in these.   Enter Francion,   GLOUCESTER, ELLAND, BERDOLK, the lady. Scrong; Londomon CANIDo EROVANS     [_Enised, these, she eys how with done, all the Read-basile praise; I do as wilk thy     corride, there to poor Prince in sufficia- tend, No; for it I\n",
            "1110401/1110401 [==============================] - 947s 852us/sample - loss: 1.3973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1693894a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}