{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUA-FBSyJ6r2",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP9Mh5qKMdvJ",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "# TODO - Words, words, mere words, no matter from the heart."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxuDks_tKKYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwye-L1-KKx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shakespeare_url = 'https://www.gutenberg.org/cache/epub/100/pg100.txt'\n",
        "\n",
        "# get the text\n",
        "response = requests.get(shakespeare_url)\n",
        "shakespeare_file = response.content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQdYqR1JKK0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decode binary into string\n",
        "shakespeare_text = shakespeare_file.decode('utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyhlKeWdLyxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d2cfb6b6-8db8-4349-dd56-32841d78a96b"
      },
      "source": [
        "# drop first few descriptive paragraphs.\n",
        "# when dropping the first few descpritive parapgraphs we are still left with \n",
        "# over 5 million characters. Take a smaller sample of that... closer to the first\n",
        "# 600k or so... \n",
        "shakespeare_text = shakespeare_text[7675:]\n",
        "print(len(shakespeare_text))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5574537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjC_W-K5q561",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation = string.punctuation\n",
        "punctuation = ''.join([x for x in punctuation if x not in ['-', \"'\", '.', \"?\", \"!\"]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7KZPH0GlfiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove newlines, whitespace, and some puncutation\n",
        "shakespeare_text = shakespeare_text.replace('\\r\\n', '')\n",
        "shakespeare_text = shakespeare_text.replace('\\n', '')\n",
        "shakespeare_text = re.sub(r'[{}]'.format (punctuation), ' ', shakespeare_text)\n",
        "shakespeare_text = re.sub(' +', ' ', shakespeare_text).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGn0DD-kl7xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU74xSFfMOag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shakespeare_text = shakespeare_text[0:850000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JGvDXTaQF7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "07639036-924e-47d4-99d3-7274b7036cdc"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(shakespeare_text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTN8Tk-xQttI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwCdKSCsMgkh",
        "colab_type": "text"
      },
      "source": [
        "### TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXSR_b79Mjpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7YYa8oAMjtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(vocab)} \n",
        "int_char = {i:c for i, c in enumerate(vocab)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sif-LTW0MjwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "811ec33c-bc9b-4a80-df98-1f2018263ce9"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 80\n",
        "step = 1\n",
        "\n",
        "encoded = [char_int[c] for c in shakespeare_text]\n",
        "\n",
        "sequences = [] # Each element is 75 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  849920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS6SFQBzMjzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(vocab)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(vocab)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoV37nXlXgbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "14c40f6e-6e62-4353-beeb-0353bf02ac75"
      },
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(849920, 80, 68)\n",
            "(849920, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcuG5CR7Xy1f",
        "colab_type": "text"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nwnjC77X1ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(vocab)), activation='tanh', recurrent_activation='sigmoid', dropout=0.2, recurrent_dropout=0, unroll=False, use_bias=True))\n",
        "model.add(Dense(len(vocab), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V4mlU41X1fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "b576c48d-93c7-4903-981c-10753dfb2fd2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 128)               100864    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 68)                8772      \n",
            "=================================================================\n",
            "Total params: 109,636\n",
            "Trainable params: 109,636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeEY0lEcX1if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3es7Io_ZNWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(shakespeare_text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = shakespeare_text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(vocab)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY7ZbYN0ZuMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d35fc33-f945-4482-cbd2-1d0e375488bd"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=512,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1659/1660 [============================>.] - ETA: 0s - loss: 2.5698\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"om public haunt Finds tongues in trees books in the running brooks Sermons in st\"\n",
            "om public haunt Finds tongues in trees books in the running brooks Sermons in sthe geanrsorer INoll no rubl padorsy daiment rakaven laches. theve ofkberiks hon me tfoy a mo heaf y. fstoadn of frs oxt wile noe tisaps we hit sres the hor to fofe af ce firgot than me ars youllt comr woll pee mat. Et womes mat ro tie by hrus bave sirobn hem heareariig c. OF EONIhU. Taimertine. IORPAARI DI I Fir the coot ssur whim? Faat. Wrad bl! you wimg yonc unofgrorI ama kist f-whakt by rok tha\n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 2.5697\n",
            "Epoch 2/10\n",
            "1660/1660 [==============================] - ETA: 0s - loss: 2.2657\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ill we be married. AUDREY. I do desire it with all my heart and I hope it is no \"\n",
            "ill we be married. AUDREY. I do desire it with all my heart and I hope it is no aisesedidind eng. The mose thouse Gave sou-lare no psieg. Mird gay. Whid this I har sour ie my muge and to-geaise SouThim youllugins aby doke sWert core now Toody frorvitcist novesgredMeNt ruse velainght fuce fon enn's af her lens bs thom ohe Gaie pee'ce Mor in beat?AFENO PROSY. Shones moad ot wayeccalnt h'd in damy Theod oue EHay nyt I hemand cheaes pan rond bunth tut Masr am innus and ar shee ne\n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 2.2657\n",
            "Epoch 3/10\n",
            "1660/1660 [==============================] - ETA: 0s - loss: 2.1489\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \". OLIVER. And what wilt thou do? Beg when that is spent? Well sir get you in. I \"\n",
            ". OLIVER. And what wilt thou do? Beg when that is spent? Well sir get you in. I LELA. Be the ss filly arcndest You then menose sune a paisl Me din wat hove corll. Caulines reefvor ust rew Riming th' with ape cuntibe fill I 'is I ferte Ie ushelf merean Whit ragion treneir. CoRVIRA. I wos le of and and thesprise Wh lok ser speosals sherfa tie in wim. So canferees. Brthite So my sore speents cat's tainl demoriess ctter wormsANOMI' Or sorr in this for hame that nethel. LEOPABARIU\n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 2.1489\n",
            "Epoch 4/10\n",
            "1659/1660 [============================>.] - ETA: 0s - loss: 2.0689\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"Another part of the forestEnter AMIENS JAQUES and OTHERS SONG AMIENS. Under the \"\n",
            "Another part of the forestEnter AMIENS JAQUES and OTHERS SONG AMIENS. Under the sente EROANAS chat lon un sharg I with your hade as hens by folle the lote Iare ineforg thin shar Of your lay extast harh And the vist and erect ot sor of your lock sir let Pbaury of Fis arn for ho lights af him gy saray Lon the feetuntsh Letery shawsatounher. 1Wish a pust nour atsole to ty sood then sone the fact And owquenly.IThit have this senved to''r them for yel to the ifftrmint hate your so\n",
            "1660/1660 [==============================] - 85s 51ms/step - loss: 2.0689\n",
            "Epoch 5/10\n",
            "1660/1660 [==============================] - ETA: 0s - loss: 2.0110\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \" he tempt thy love?LUCIANA. With words that in an honest suit might move. First \"\n",
            " he tempt thy love?LUCIANA. With words that in an honest suit might move. First a cove my and af evir's fordlo' of is this that my hear is a may thin upon A saoh lico in of tho parr't thee shall tho lord atthir and the solls. CO8IN. Heir uponath's head at for trat. Caite extutian drack'd wxt a bactall to. He one ir made's are treagod 5uch he ulvaks not I'sl some oss jlocient Make spead ho liaies Abien hid I bed edfars Coucloon the stlace nit compPletthano seer stll is tild I \n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 2.0110\n",
            "Epoch 6/10\n",
            "1660/1660 [==============================] - ETA: 0s - loss: 1.9712\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"stership in floating fortune's blows When most struck home being gentle wounded \"\n",
            "stership in floating fortune's blows When most struck home being gentle wounded I do cofe you fare. Ag your by peav'd That shime's of his he blles the prupibet. CELAS. Ancondir THim grow I lawn so shery. COMINEUS. Fuldve theeare sthel of I just. But out one haden. CuA Sorisanbing camnawline yores make. CEOS. Will I talt go our buroted 'tomence the Know ot this proyet I men you. Segilod? For be! CHRTOLAMS Youn antlet sir is that weat he paly boous. FIRST SERVANT. Thou know dea\n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 1.9712\n",
            "Epoch 7/10\n",
            "1660/1660 [==============================] - ETA: 0s - loss: 1.9385\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"ature of his great offence is dead And deeper than oblivion do we bury Th' incen\"\n",
            "ature of his great offence is dead And deeper than oblivion do we bury Th' incencondl and Pastt best but Jove to all that she land of bud What I'al have thank Rorder. Hell Dotood toltonfod? TRom pay Youl. PHIRUS. Noyshatd her loods not heretrme deach so thy o hor shagh go you you hopbfull stt phack to knows onted sone to far tee of gudiest came more secall. IDopid'd And houge my falows these If your with him hend a dayss. I though not heart onquecths 'tismon aboed pigaps. TRi\n",
            "1660/1660 [==============================] - 87s 52ms/step - loss: 1.9385\n",
            "Epoch 8/10\n",
            "1659/1660 [============================>.] - ETA: 0s - loss: 1.9156\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"OPIES MAY BEDISTRIBUTED SO LONG AS SUCH COPIES 1 ARE FOR YOUR OR OTHERSPERSONAL \"\n",
            "OPIES MAY BEDISTRIBUTED SO LONG AS SUCH COPIES 1 ARE FOR YOUR OR OTHERSPERSONAL USE ONLY AND 2 BAR NOT DIPTRIBUTED OR USEDCSWROENG AS SYR COPIEE MOBEAC INE RIANDUSTROUTINS NOALDED THAR ECE TOPRODT 1990-1993 BY yDWRDY AROR ANY. 2 PRIBINEDINCL AND COPYRIBUTED BY RRCS TH-TEGHABBENE 1 OF TEMGENS AC ENEDICTINO ONLYUDES YY ANYSERERRECTIAT THAR EGTTRE WOLLEDEWNOTHESTER ONLLDMMBMRRODIO OCT PES AARE NOT UFE MBRMACE AAY AU COPIOW AS TUTE TIBIUEDESOSPENED OR 1LEDCHMMERIILLEAD MRROOID DA\n",
            "1660/1660 [==============================] - 85s 51ms/step - loss: 1.9156\n",
            "Epoch 9/10\n",
            "1659/1660 [============================>.] - ETA: 0s - loss: 1.9040\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \" to this intelligence pronounce The beggary of his change but 'tis your graces T\"\n",
            " to this intelligence pronounce The beggary of his change but 'tis your graces Those a most a foir'st joing If at morry in. CARIADO. Pivioie forfore him thal. CLEOPATRA. I am not and till your foncth wese has dittaldse sen theleve as bd thunge too teed mide compat- What ce embed oriteny of cut I destomar'deme. CLOWN. Hearul you nou love muse to the main fift me And paest? Yet this theu ambati how reselt ben veans! ROSALEND. The loase end of did phoeh nee not I was t'trse.ANTO\n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 1.9040\n",
            "Epoch 10/10\n",
            "1659/1660 [============================>.] - ETA: 0s - loss: 1.8791\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"when the sea was calm all boats alike Show'd mastership in floating fortune's bl\"\n",
            "when the sea was calm all boats alike Show'd mastership in floating fortune's bloned not beforanceing Fally uilion is mards Saberiuty. Sut infole thils? PAROLLES. Dive fris in combrozed Ture by the eir to for mate Find em'drter monce my knery. They is I seart the gudver forchee. my glowr. This he this conful of man arb the witt. CLESPATRA. There you and sir't so shald not leart froughturem spanged breedion and bonembal himine it. LAFE. Woth wan this so I tinks with him. As I \n",
            "1660/1660 [==============================] - 86s 52ms/step - loss: 1.8791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd26752a518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}