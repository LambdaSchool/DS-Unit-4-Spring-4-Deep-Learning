{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.gutenberg.org/files/100/100-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('100-0.txt', 'r', encoding='utf-8')\n",
    "text_clean = text.read()\n",
    "\n",
    "char_scrub = ['\\n','\\d+', r'\\W+(?!\\S*[a-z])|(?<!\\S)\\W+','    ', '   ', '  ']\n",
    "\n",
    "for char in char_scrub:\n",
    "    text_clean = re.sub(char, ' ', text_clean)\n",
    "    \n",
    "end = len(text_clean)-20245\n",
    "    \n",
    "text_clean = text_clean[1985:end]\n",
    "\n",
    "sonnets = text_clean[:90968]\n",
    "\n",
    "plays = text_clean[90968:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequence Data for sonnets\n",
    "\n",
    "def sequence_data():\n",
    "    \n",
    "    chars = list(set(data))\n",
    "\n",
    "    char_int = {c:i for i,c in enumerate(chars)}\n",
    "    int_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    encoded = [char_int[c] for c in data]\n",
    "\n",
    "    sequences = [] #each element 60 chars long\n",
    "    next_chars = [] #one element for each sequence\n",
    "\n",
    "    for i in range(0, len(encoded)-maxlen, step):\n",
    "        sequences.append(encoded[i : i+maxlen])\n",
    "        next_chars.append(encoded[i+maxlen])\n",
    "\n",
    "    print(f'sequences: {len(sequences)}')\n",
    "    \n",
    "    x = np.zeros((len(sequences), maxlen, len(chars)), dtype = np.bool)\n",
    "    y = np.zeros((len(sequences), len(chars)), dtype = np.bool)\n",
    "\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[i,t,char] = 1\n",
    "\n",
    "        y[i, next_chars[i]] = 1\n",
    "    \n",
    "    return chars, x, y, char_int, int_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    if epoch %5 ==0:\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(data) - maxlen - 1)\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = data[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_int[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = int_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()\n",
    "        else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 18174\n"
     ]
    }
   ],
   "source": [
    "#sonnet lstm\n",
    "\n",
    "maxlen = 100\n",
    "step = 5\n",
    "data = sonnets\n",
    "\n",
    "chars, x, y, char_int, int_char = sequence_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "18048/18174 [============================>.] - ETA: 0s - loss: 3.0181\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his\"\n",
      "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his   t  e h t   t  t   o   e        t  ee    he e    a    e t  e s s  ae t   e  e   e   t he    h h  e  e  a  e  s  ee  e  oe e   o      e   h   h h e t   t    e  e       t  t h   s oe  e e    e  t o  t t    t   t e e h  r e      h     o e     e  o e  t   s h r   t    o  s   e s   t     a    t  t   t   e  t      h  t  e e ee     e    t  t    e th   t  h  e   e   e n t  o e t  e e  t  e  ot  e  s  h \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his\"\n",
      "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his e ea e eeos st taoae re ra ai  hoatr  eu a tune oh ant  ue e haw et  n  t   s eert htahe   hoero  or  oooo hn epc’  n n  ayeh n  ah t ts rh h t eto  s ue oehs ret  w  t yer h w    to h oeee    r h s  y oe   otonns aterhte h t e  s  t tyoote r oe o   et wml  d oe h h oe t  tse teesh tmi  oi aiot ot het n m  ties h t ai et h d twt  mh eie e eare     h  h e e s ea t aeo s n oe  u  nt  ts  rnmt m h a\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his\"\n",
      "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from hish atg wh a w’lh mhfiod thped out sAdun aern’g ho e  Te fhcdorwcL a  pt  areInautl  su vthhr   ypnla ab rthoe h  e l sositna opunadarsaPiOdrs p f eerrk fbhes ysaa hg iticte  s oeoy amodItoeAmiaoesdlchdh uru chhth tr toysea iOd glo lffuyohrr i nvewnn Shhi ej wcldhea-s tegr mwent  le Y ohitvs es on lh d ritenetoa d oeAdlrh  l  ecs u mebe hegh Ii oPafpbMvielee ig nhhsIohhwh  n  igye  tae  drlemeshy my\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his\"\n",
      "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from hisctidhl metl   o  Bkae gee Hft-idvyracwrch iu Wn vstedvrnttsitWhatbhhvnenlsrlstwytn riTeis lu r hteahay onLla egeymoFs td m ths n vA oztNcuaiucaaYt atea ha e ow itl rs oTuwan  ercekh-ooyttn r   dnkdra te’ uIdtdpe hrn  sCt  k htouyltide hiuoB otytvE tmtcruengeg ohish eeu lhs   ftsf taeknsiuasomfosp   sgeodaaos fmsdsthwei t hedppTnootmlhd tq mheypuetaluaiEy av vhere  hnngeaalrttu t s ryyotao uFpgsyIe\n",
      "18174/18174 [==============================] - 37s 2ms/sample - loss: 3.0172\n",
      "Epoch 2/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 2.7473\n",
      "Epoch 3/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 2.5167\n",
      "Epoch 4/25\n",
      "18174/18174 [==============================] - 14s 772us/sample - loss: 2.3803\n",
      "Epoch 5/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 2.2983\n",
      "Epoch 6/25\n",
      "18048/18174 [============================>.] - ETA: 0s - loss: 2.2384\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l\"\n",
      "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I lor she the that the she the the thou shat the the that the the the that that that the the the seat the the thou the thas that the that that the the seat hat the that the than and shes the the the the se the more the the she son the that the ther sor that she the that the she the seat the that the the the the the seat tho her wime the the that that the the sin the the thas tho that the shat the she\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l\"\n",
      "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I lite that thas I theve so than The thor that nin thin me firo ar the sey than she an thar ron that thee sout erath oul seat sres hou has  hou thich won wirg fore dis that ar ther thor thy that I dome thou hee thar For nor share An the thit in wor tron mis oul no seal that the than of mhin the boing sowe sor sove not thal me sor fore no thas deve rove snther on thar daat my mis ot the sing ho theat \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l\"\n",
      "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I loik ha camed Mevr npev no solalg seong ingke joute’n Ie th uh wiyl shan-tuns beer ans thaM hraislwsesed lor roras that Th seist Whan douring pno soos ay thesrinr awfregheiragdeOt gor lar ploth nere fit beirn lhent ink Braks cay wat deougthaofer an Sho foalth oor thats seogherin Fnatris dubf tnot thath mnesiclis thok ffade Af tout nyeusen Or yy palt AncwnHus ghov my wils of yovere parte ans wirmad \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l\"\n",
      "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I laclere thiod gtinge aldlg-bett he Love  in tih mla th I chouth holr tawsgut Oikinn thotheustat xhon crere sallI r ok waturgirn gear lp them Shtsev ohnvr blsin youed y ingos anst on bes in ay ’y sif il Of o llawed iftpith thind’n love Thoct fich Amkem farleptror bekfin wreass’vs thy I pnrees shoIsss loshen wovendharx phare whal twyer ind fnot th Thatutq pllcer aihs ’ls suwhou dowemt aks ortivegt Mi\n",
      "18174/18174 [==============================] - 37s 2ms/sample - loss: 2.2386\n",
      "Epoch 7/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 2.1978\n",
      "Epoch 8/25\n",
      "18174/18174 [==============================] - 14s 786us/sample - loss: 2.1523\n",
      "Epoch 9/25\n",
      "18174/18174 [==============================] - 14s 769us/sample - loss: 2.1174\n",
      "Epoch 10/25\n",
      "18174/18174 [==============================] - 14s 770us/sample - loss: 2.0815\n",
      "Epoch 11/25\n",
      "18048/18174 [============================>.] - ETA: 0s - loss: 2.0562\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And \"\n",
      "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And the sear the seare the seare the what the sear thou hat the will she the seed the the seath the the sear the wire the will sear so hear thou hor thee thou have Thou hat thou hin the will see the the sear thou hear the wire that me the sore the will seall not the sear that wind the that the wire the more thou hor the sear so love stoul the wore the sear the so the seer thou hath the hat the seart t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And \"\n",
      "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And be thou hins if the sear the seale ale thou have thee werlise so love thou hat the so live ming thiu seand shear dout wort ron the what my sill thou fald sill the forll thou hin tith thou han thou hive beall That  ar wars And dile and seathe butring tho sheat thou in the that the are that what fare Whou thie thou shand gith than forthe sool that in thou hor love in thut ohe whing and ou thy shees \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And \"\n",
      "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And mosf aniwh-pyetcfor besuve Why e cared so pe rave rof Siow Hale Why hibseel’s shalpitl dedscive ile hy eothled seam Th Nouf cenot For grall weery Meabesth ghitl ig toa thaun then apr I bererive Aod and All ail thae tfor cpout eak’s I Han Is ersoul to net antes of endny ais war may forniege caiurnighar ledevI ald my af-ore deerigh serle sur wool shoum suf limlle ter on sims elli’s nor roch tay sfol\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And \"\n",
      "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And in bnom moneO be I ar my sisheL fnotowh thy ore frenoud heprin TereoR indhhon ssewjlr i’ phill per’se Fo pearary Glam vime ala by fonds cerarisp Ixuunl for lise Tolj asthor Formy faserild Svettartand Wor Ar’ losmy’s fea cert sfor Olae the meter Tiwher Dinus inwnechzen iq wom wiye wrise hhou lliowis mo el womk what lin peith eest’pe tro hece Whemill halmaSt ond forprer-Loto s earpouratrof oo soavpi\n",
      "18174/18174 [==============================] - 37s 2ms/sample - loss: 2.0547\n",
      "Epoch 12/25\n",
      "18174/18174 [==============================] - 14s 774us/sample - loss: 2.0322\n",
      "Epoch 13/25\n",
      "18174/18174 [==============================] - 14s 779us/sample - loss: 2.0034\n",
      "Epoch 14/25\n",
      "18174/18174 [==============================] - 14s 770us/sample - loss: 1.9818\n",
      "Epoch 15/25\n",
      "18174/18174 [==============================] - 14s 774us/sample - loss: 1.9623\n",
      "Epoch 16/25\n",
      "18048/18174 [============================>.] - ETA: 0s - loss: 1.9405\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov\"\n",
      "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my love The what the seat the thou hath the the thou hare the what the wher what the worl whee the seat the that hin the seath the she the the me the seath the seald the shang the seat the bear she the wher the the so the what the sow the singe the seat the seat the sean the see the wore the seath the seant the seal The the seat the seal The shath be the shath the seat of the sowe the will The what the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov\"\n",
      "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my love so hor deat as my live my sull doth the to the shen the for that my ereath that thee But my seart And bith and mo not the wirl and pela the not with buth thee in the love Thou hand And thy shath deart for the him that thou that thee worth do then thee To deare shat loth my see the hear And hes the so thee whing the mant in my seat What tham me To thy stat thou that farl in me dath you thy for he\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov\"\n",
      "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my loved that wiot Af thy theur fwicr wils ding And wheid ofster ow pryat wild thas showneus arn ewtir ald with ard Ths cupe dumeinl to trees afa hime wollls fod thes be oss whe thy priek on though Mirm wat theur -wind I futh will An thee to to the ceerwovy and moms fayer mughain and mn gothing hoo to be my boulfichingse I and for the dovgled me windy und berume porpand Anped breime ating shangh’st be t\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov\"\n",
      "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my love dessool yeagh PEt iHy hing comisg an fwill wide nind ne waur I aft cto fouthth lich mmyey ws mpanst showjy prymise hacr daswolis in you world poum of thys wathO thyung somind Nupe andess in thou youfutrfest desy purGd mpathe thim Nslind Fre cdraccesoth wereds swers mabit nMe ant prich hive oon not lovamgmastest silqut shaut Nonnpiqklact in when I what miisen thine thas muse be Tome seshels rajen\n",
      "18174/18174 [==============================] - 37s 2ms/sample - loss: 1.9395\n",
      "Epoch 17/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 1.9220\n",
      "Epoch 18/25\n",
      "18174/18174 [==============================] - 14s 771us/sample - loss: 1.9048\n",
      "Epoch 19/25\n",
      "18174/18174 [==============================] - 14s 774us/sample - loss: 1.8874\n",
      "Epoch 20/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 1.8679\n",
      "Epoch 21/25\n",
      "18048/18174 [============================>.] - ETA: 0s - loss: 1.8549\n",
      "----- Generating text after Epoch: 20\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star\"\n",
      "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling stare see the seat the sear steer stoul stere the sear do doth the seat the the fored that the seat my sear the seat the sear stoul see the seed the seart the seat of the sear ded the sear seart the seast the seal sear of the sear stees The hand that the sear steer the sear the mese the sear steed the some that me see the sear the dost the see the sean the sear stand steer that the seat to the sear st\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star\"\n",
      "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling stare se frow in the and sean she the then pore For sheal s of thee the sail my not me bear of when thee for not bey the rowhed my see ned The doth Thou hand mo hase the seaut And my sear of thy sheer dseat my lost though sume the shange to thy sealt That me ere for which thine Non in kere I so for the thing of the me and and all seen my some The foret thee O love I so fer And the wert When sise the s\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star\"\n",
      "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling stared er arce the redse ceiknor famew deds O lfon of my Is cowkes And sheagll spandsefedumugnd wollds zeast’or youlf can cands Long taper efar the mist prout To not whert end size def thein nemind omk Nor fake the ferling will Bat wave keof at dy to bkencu pearmen light and that to cond sear ofline Aratry seen Whend Songhr no my sead endse porinn go kilnge As the farec to yeren sing Is in thy loveee \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star\"\n",
      "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star dowess mads a to lavpnegh to beact Arm avs mant thee spact at mee wy gideteb-dowaPt uil my alasue houlqueaseS eirnts the galme’s piling time trint scen of h of Hnot Thou hase I Pald have so Lot fute ead dunuI theule alls post leako ben so p’nbe And end Why siglt youst O my heavtis Miys geare it one sake yacp andoy nonged ripgect fer fol byesed glys’nt bime te vemauves sane nem Whis ov’s wlof fbur\n",
      "18174/18174 [==============================] - 37s 2ms/sample - loss: 1.8545\n",
      "Epoch 22/25\n",
      "18174/18174 [==============================] - 14s 773us/sample - loss: 1.8370\n",
      "Epoch 23/25\n",
      "18174/18174 [==============================] - 14s 779us/sample - loss: 1.8233\n",
      "Epoch 24/25\n",
      "18174/18174 [==============================] - 14s 772us/sample - loss: 1.8057\n",
      "Epoch 25/25\n",
      "18174/18174 [==============================] - 14s 780us/sample - loss: 1.7868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ff96c2d30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "        \n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation = 'softmax')) #softmax used because multiclass \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    \n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=25,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
