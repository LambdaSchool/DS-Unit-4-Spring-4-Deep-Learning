{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('../shakespear.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_size = 100 # Size of the hidden layer\n",
    "T_steps = 25 # Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 1e-1 # Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + X_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value #parameter value\n",
    "        self.d = np.zeros_like(value) #derivative\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(X_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((X_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p = parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "    return z, f, i, C_bar, C, o, h, v, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters):\n",
    "    \n",
    "    assert z.shape == (X_size + H_size, 1)\n",
    "    assert v.shape == (X_size, 1)\n",
    "    assert y.shape == (X_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    assert len(inputs) == T_steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "            \n",
    "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
    "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_paramters(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class DelayedKeyboardInterrupt(object):\n",
    "    def __enter__(self):\n",
    "        self.signal_received = False\n",
    "        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n",
    "\n",
    "    def handler(self, sig, frame):\n",
    "        self.signal_received = (sig, frame)\n",
    "        print('SIGINT received. Delaying KeyboardInterrupt.')\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.signal(signal.SIGINT, self.old_handler)\n",
    "        if self.signal_received:\n",
    "            self.old_handler(*self.signal_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " e this overcholord;\n",
      "Yet deshall you have pent gint;\n",
      "Why brear this patt thy Angead o'neds not math not\n",
      "it what allfuch brove flend your good: rustren to late if Ye welled\n",
      "Wo lay such to faice be: I am \n",
      "----\n",
      "iter 34338, loss 39.693745\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with DelayedKeyboardInterrupt():\n",
    "            # Reset\n",
    "            if pointer + T_steps >= len(data) or iteration == 0:\n",
    "                g_h_prev = np.zeros((H_size, 1))\n",
    "                g_C_prev = np.zeros((H_size, 1))\n",
    "                pointer = 0\n",
    "\n",
    "\n",
    "            inputs = ([char_to_idx[ch] \n",
    "                       for ch in data[pointer: pointer + T_steps]])\n",
    "            targets = ([char_to_idx[ch] \n",
    "                        for ch in data[pointer + 1: pointer + T_steps + 1]])\n",
    "\n",
    "            loss, g_h_prev, g_C_prev = \\\n",
    "                forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "            smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "            # Print every hundred steps\n",
    "            if iteration % 100 == 0:\n",
    "                update_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "            update_paramters()\n",
    "\n",
    "            plot_iter = np.append(plot_iter, [iteration])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "\n",
    "            pointer += T_steps\n",
    "            iteration += 1\n",
    "    except KeyboardInterrupt:\n",
    "        update_status(inputs, g_h_prev, g_C_prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
