{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-16 20:45:53--  https://www.gutenberg.org/files/100/100-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5777367 (5.5M) [text/plain]\n",
      "Saving to: ‘100-0.txt.12’\n",
      "\n",
      "100-0.txt.12        100%[===================>]   5.51M  4.76MB/s    in 1.2s    \n",
      "\n",
      "2019-12-16 20:45:54 (4.76 MB/s) - ‘100-0.txt.12’ saved [5777367/5777367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.gutenberg.org/files/100/100-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = list()\n",
    "\n",
    "#with open ('100-0.txt', 'r') as f:\n",
    "#    data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "#import string\n",
    "\n",
    "#re.sub(r'[^a-zA-Z ^0-9]', '', full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = data[0].replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = re.sub(r'[^a-zA-Z ^0-9]', '', data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#re.sub(r'[^a-zA-Z ^0-9]', '', full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = list()\n",
    "\n",
    "with open ('100-0.txt', 'r') as f:\n",
    "    data.append(f.read())\n",
    "\n",
    "len(data)\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "#re.sub(r'[^a-zA-Z ^0-9]', '', full_text)\n",
    "# debate over taking out spacing\n",
    "\n",
    "data1 = data[0].replace('\\n', '')\n",
    "data1 = data[0].replace('\\t', '')\n",
    "\n",
    "# character filter, optional\n",
    "#data1 = re.sub(r'[^a-zA-Z^0-9]', '', data1)\n",
    "\n",
    "big_string = \" \".join(data1)\n",
    "\n",
    "big_string = data1\n",
    "character = list(set(big_string))\n",
    "\n",
    "len(character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far, all spaces and irregular characters have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_int = {character:integer for\n",
    "           integer, character in enumerate(character)}\n",
    "\n",
    "int_char = {integer:character for\n",
    "           integer, character in enumerate(character)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sequence of data... \n",
    "\n",
    "maxlen = 64\n",
    "step = 5\n",
    "encoded = [char_int[c] for c in big_string]\n",
    "sequences = [] # or list()\n",
    "next_character = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(encoded) - maxlen, step):\n",
    "    # the 127 characters\n",
    "    sequences.append(encoded[i: i + maxlen])\n",
    "    # the 128th character\n",
    "    next_character.append(encoded[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), maxlen, len(character)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(character)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, characters in enumerate(sequence):\n",
    "        X[i,t,characters] = 1\n",
    "    \n",
    "    y[i, next_character[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114617, 64, 106)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(maxlen, len(character))))\n",
    "model.add(Dense(len(character), activation='softmax'))\n",
    "\n",
    "          \n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = np.random.randint(0, len(big_string) - maxlen - 1)\n",
    "    #start_index = np.random.randint(0, len(sequence) - maxlen - 1)\n",
    "    #start_index = random.randint(0, len(big_string) - maxlen)\n",
    "    #start_index = random.randint(0, len(sequence) - maxlen)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = big_string[start_index: start_index + maxlen]\n",
    "        generated = generated + sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(character)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_int[char]] = 1.\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_characters = int_char[next_index]\n",
    "            sentence = sentence[1:] + next_characters\n",
    "            sys.stdout.write(next_characters)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef on_epoch_end(epoch, _):\\n    # Function invoked at end of each epoch. Prints generated text.\\n    print()\\n    print(\\'----- Generating text after Epoch: %d\\' % epoch)\\n\\n    start_index = random.randint(0, len(sequence) - maxlen)\\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\\n        print(\\'----- diversity:\\', diversity)\\n\\n        generated = \\'\\'\\n        sentence = big_string[start_index: start_index + maxlen]\\n        generated = generated + sentence\\n        print(\\'----- Generating with seed: \"\\' + sentence + \\'\"\\')\\n        sys.stdout.write(generated)\\n\\n        for i in range(400):\\n            x_pred = np.zeros((1, maxlen, len(characters)))\\n            for t, character in enumerate(sentence):\\n                x_pred[0, t, char_int[character]] = 1.\\n\\n            preds = model.predict(x_pred, verbose=0)[0]\\n            next_index = sample(preds, diversity)\\n            next_characters = int_char[next_index]\\n\\n            sentence = sentence[1:] + next_characters\\n\\n            sys.stdout.write(next_characters)\\n            sys.stdout.flush()\\n        print()\\n\\nprint_callback = LambdaCallback(on_epoch_end=on_epoch_end)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(sequence) - maxlen)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = big_string[start_index: start_index + maxlen]\n",
    "        generated = generated + sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(characters)))\n",
    "            for t, character in enumerate(sentence):\n",
    "                x_pred[0, t, char_int[character]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_characters = int_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_characters\n",
    "\n",
    "            sys.stdout.write(next_characters)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#class\\ndef on_epoch_end(epoch, _):\\n    # Function invoked at end of each epoch. Prints generated text.\\n    print()\\n    print(\\'----- Generating text after Epoch: %d\\' % epoch)\\n\\n    start_index = np.random.randint(0, len(big_string) - maxlen - 1)\\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\\n        print(\\'----- diversity:\\', diversity)\\n\\n        generated = \\'\\'\\n        sentence = big_string[start_index: start_index + maxlen]\\n        generated += sentence\\n        print(\\'----- Generating with seed: \"\\' + sentence + \\'\"\\')\\n        sys.stdout.write(generated)\\n\\n        for i in range(400):\\n            x_pred = np.zeros((1, maxlen, len(chars)))\\n            for t, char in enumerate(sentence):\\n                x_pred[0, t, char_indices[char]] = 1.\\n\\n            preds = model.predict(x_pred, verbose=0)[0]\\n            next_index = sample(preds, diversity)\\n            next_char = indices_char[next_index]\\n\\n            sentence = sentence[1:] + next_char\\n\\n            sys.stdout.write(next_char)\\n            sys.stdout.flush()\\n        print()\\n\\nprint_callback = LambdaCallback(on_epoch_end=on_epoch_end)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "#class\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = np.random.randint(0, len(big_string) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = big_string[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1114617 samples\n",
      "Epoch 1/5\n",
      "1114112/1114617 [============================>.] - ETA: 0s - loss: 1.8405\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ich fence the roots they grow by and defend them,\n",
      "Makes both my \"\n",
      "ich fence the roots they grow by and defend them,\n",
      "Makes both my life the prince and wards and sender the man for your grace\n",
      "And since of the made the counter the stranger the world and the forture the word.\n",
      "\n",
      "                                                                                                                                                                                                                                                                \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ich fence the roots they grow by and defend them,\n",
      "Makes both my \"\n",
      "ich fence the roots they grow by and defend them,\n",
      "Makes both my lords make the court him his supper.\n",
      "\n",
      "FIRST LORD.\n",
      "\n",
      " [_Exit._]\n",
      "\n",
      "                                                                                                                                                                                                               [Herver Bericion.\n",
      "    I'th a lady to the compasity and light.\n",
      "    The prove the string the worth of him that be thing commanded.\n",
      " \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ich fence the roots they grow by and defend them,\n",
      "Makes both my \"\n",
      "ich fence the roots they grow by and defend them,\n",
      "Makes both my look.\n",
      "\n",
      "FLOUTELTR.\n",
      "The han her peace'ry forny elle,\n",
      "That’s man by juscring to quetth sin erst,\n",
      "Sink lord; though our jaws, with my mould, bed, sir?\n",
      "\n",
      "ROMELER.\n",
      "There’s dothers. By done every chave begother?\n",
      "My Werder. Proomitine thy.\n",
      "\n",
      "IAMIL.\n",
      "Devil I good thy hern floues comy heichos,\n",
      "Why hath leaduly. But berrience thy bekies spo, her with,\n",
      "Will bore the alening so all forlly.\n",
      "But neede her poor last\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ich fence the roots they grow by and defend them,\n",
      "Makes both my \"\n",
      "ich fence the roots they grow by and defend them,\n",
      "Makes both my Hargurain god to'ter stort.\n",
      "Quesinivingrow to wormy im but heride foul her!\n",
      "If the usmin.—Thus find Fron heajt, lock'd.\n",
      "\n",
      "AdTcy, any yet thou doing out my bost father?, What has thoy.\n",
      "\n",
      "ye may Enjex’d say mo-thrainss yeary. KI kid withyrend the work,\n",
      "Here Bear-bardin marbort indeed.\n",
      "\n",
      "To ill at be us updicy back. Lond,\n",
      "When now of, like your Sidgont!PYoKs sir, pfainy head deathed Jess, daves,\n",
      "\n",
      "Flap’s\n",
      "1114617/1114617 [==============================] - 740s 664us/sample - loss: 1.8404\n",
      "Epoch 2/5\n",
      "1114112/1114617 [============================>.] - ETA: 0s - loss: 1.5482\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; co\"\n",
      ", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; come to hear the sons\n",
      "    And the part to her to the true of the part.\n",
      "                                                                                                                                                                                                                                                                                                                                           \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; co\"\n",
      ", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; come to the same,\n",
      "    And the swift of the happiage.\n",
      "  BRUTUS. You be the tood to it.\n",
      "                                                                                                                                                                                                                                                                                                                            \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; co\"\n",
      ", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; come; if sorm.\n",
      "    I piems liel for suck as\n",
      "\n",
      "            Exeunt\n",
      "\n",
      "                                   But I do leen do’d his world be\n",
      "\n",
      "Muriple, heart, but I must before men the whom your\n",
      "rughian what, When owrough, I’ll very onbli’d, sir, on the Lears\n",
      "The fiarts, O!\n",
      "Englate grean preyers by me, prayer.\n",
      "Condster, for the clear shame.\n",
      "\n",
      "ANTIPHOLUS OF ROCHEMONE.\n",
      "Domon? The world, thou wies’tes in the worl\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; co\"\n",
      ", and thou sit in my throne?\n",
      "  YORK. It must and shall be so; come?\n",
      "  BOON! GONURGBYRD. [_ENICIMANE.  Nay, after loverly dow I, the worsing\n",
      "    vile in! But hake to give bectorths,\n",
      "    If her, let hoous nargA'ns alysitis\n",
      "liking.\n",
      "  TOSTA SOLDBrow. This Jupor, Bullow. Airmat,\n",
      "    As not thou, than, or sin, dir.\n",
      "    Vouron. Eweas. He hat advajes my fnBel, unve to heads\n",
      ".\n",
      "    You hast go-mon's mush jesty, there's becelssw!\n",
      "    To mogmine hast of ortus; and say ye;\n",
      "1114617/1114617 [==============================] - 706s 634us/sample - loss: 1.5482\n",
      "Epoch 3/5\n",
      "1114112/1114617 [============================>.] - ETA: 0s - loss: 1.4879\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Hav\"\n",
      " apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Have be the shape to the prove the constant,\n",
      "    And with the stand of the stop of the father\n",
      "    And the stand and the true and a street\n",
      "    Whose princes and so must be the constance\n",
      "    And shall she should be shall the lips to the great stand\n",
      "    constant of the stand of the constant in the sons,\n",
      "    And the prove the warlish with the stors'd to the shall\n",
      "    That with the shall the shall be the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Hav\"\n",
      " apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Have show you must be love proceed the blood,\n",
      "    I am the with the silent the faith,\n",
      "                                                                                                                                                      Exeunt FALSTAFF\n",
      "\n",
      "  SERVANT. Have shall have it it her the life of my precents.\n",
      "    The world here shall be mine own with the fair\n",
      "    As stand the thrives to stand the\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Hav\"\n",
      " apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Have say gone betnersty, hessings.\n",
      "    The sumprand as tempest me swive me a name.\n",
      "    For my lord, that craive out with from the hate\n",
      "    ’Towxife beat thine; unles of she but for when, to thee;\n",
      "        I can crectly up dosom do'st fapim; common\n",
      "    A gotch is Ridoish heaving with new master's\n",
      "    I am like it and day, if then I dog,\n",
      "    Aptower necestell; crown him best.\n",
      "    But me in I will do swe\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Hav\"\n",
      " apprenticehood\n",
      "    To foreign passages; and in the end,\n",
      "    Have a to dien my cooselow knave;\n",
      "    She learned villamant. Theee bly hrink\n",
      "    Lendor senPy thine intend grazen\n",
      "    Welp-sowigh'd concoudly nobly has\n",
      "       plays so some by ear. Yea, are names, firecour that a Clebarch\n",
      "  To she till hie thratives? He juit,\n",
      "Quiniars with the   herps execus'd to Waz\n",
      "FrOcy have man. Saidor the free, my intape.\n",
      "Devery will be mne have free: I do  What; I on you\n",
      "Forery\n",
      "1114617/1114617 [==============================] - 685s 615us/sample - loss: 1.4879\n",
      "Epoch 4/5\n",
      "1114112/1114617 [============================>.] - ETA: 0s - loss: 1.4574\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day\"\n",
      "woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day the bounds,\n",
      "With the streaves and the born and son,\n",
      "That the streep of the part of the part and straint\n",
      "To the son is the part and the son is the bold\n",
      "Which is the part of the son is the sons,\n",
      "And the stranger of the devil of the son is the\n",
      "                                                                                                                                                              \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day\"\n",
      "woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day they all stronger on deeds\n",
      "the command to horse of love that the sons speak, and the poor son\n",
      "      one that that make me to your contective to the peace, sir,\n",
      "             Great so beard. Recence and the court.\n",
      "\n",
      "\n",
      "      DON PEDRO.\n",
      "      What I am not the leave of the son be to him. I have no death\n",
      "    The sight of the part the self stream and the brothers\n",
      "    That the poin and sons the disterst a\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day\"\n",
      "woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day,\n",
      "In one more concapis,—; and that better born,\n",
      "Or we worn; if an other Past of ever loves of the\n",
      "    al caluying. For the King! Romeo, their great alsests.\n",
      "  ANNOL. Me come to give on.\n",
      "    What's the Pere ia!\n",
      "\n",
      "                 [_Exid. Repots]\n",
      "\n",
      "\n",
      "Sincert Panite_: Abasla of Conscent.\n",
      "\n",
      " TROIL. you’ll not sure me\n",
      "So love. I’ll wardening tranch, age can if thou ma.\n",
      "Score seek now. And to it home, young\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day\"\n",
      "woeful, woeful, woeful day.\n",
      "Most lamentable day, most woeful day\n",
      "I countle hence to’t: my salRander and lugge un\n",
      "and die post’ yondernon?\n",
      "\n",
      "HOO ZEDO.\n",
      "The spoken's pration’s her.\n",
      "\n",
      "BERO.\n",
      "Well, follow.\n",
      "\n",
      "Re-press.\n",
      "Will you would be misidles; he, Dort nay;\n",
      "I have kis your lord repod, is stand ill\n",
      "  faulance, may now beet leave did, Harry I were to fatchboO pite\n",
      "inards?\n",
      "\n",
      "MAGUS.\n",
      "If you doth go be a hacks. Looking Sheeks grownus.\n",
      "\n",
      "our torse: crefus to your silf._1 with\n",
      "1114617/1114617 [==============================] - 706s 634us/sample - loss: 1.4574\n",
      "Epoch 5/5\n",
      "1114112/1114617 [============================>.] - ETA: 0s - loss: 1.4372\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"he falcon her bells, so man hath his desires; and as pigeons\n",
      "   \"\n",
      "he falcon her bells, so man hath his desires; and as pigeons\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"he falcon her bells, so man hath his desires; and as pigeons\n",
      "   \"\n",
      "he falcon her bells, so man hath his desires; and as pigeons\n",
      "      man all the consemption remember and strike.\n",
      "    The sweet the friend my son to the charge\n",
      "    The word men and bough age and her mark and true\n",
      "    And feast that in the sentents and and "
     ]
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=512,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn1 (Python3)",
   "language": "python",
   "name": "nn1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
