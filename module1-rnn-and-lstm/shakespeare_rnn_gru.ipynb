{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shakespeare_lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8MD_vRPOwKG",
        "colab_type": "text"
      },
      "source": [
        "# Use NLTK to import and preprocess the play"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBv5nvu_OnQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7026c501-7c44-428b-f328-a322405aa3dc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import re\n",
        "import pickle\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Bidirectional, Dropout\n",
        "from keras.layers import SimpleRNN, GRU, BatchNormalization\n",
        "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO33i4X_Ob_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8195ec8c-d4bf-488a-a865-e998d8f9a8e0"
      },
      "source": [
        "hamlet = gutenberg.words('shakespeare-hamlet.txt')\n",
        "# text will contain the entire sequence of characters that make up hamlet\n",
        "text =''\n",
        "for word in hamlet:      \n",
        "  text+=str(word).lower()\n",
        "  text+= ' '\n",
        "print('Corpus length, Hamlet only:', len(text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length, Hamlet only: 166765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKJme4hlPqEi",
        "colab_type": "text"
      },
      "source": [
        "Each input sequence corresponds to 40 characters and one output character (y1) that corresponds to the next character in the sequence. The entire play has been broken up into 55,757 sequences of characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T3DD9BPOiPU",
        "colab_type": "text"
      },
      "source": [
        "# Create the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yZPNJUMQR4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "244c5678-684c-47a8-dbf8-a92d6b6a9537"
      },
      "source": [
        "# Create two dicts,: characters mapped to indices and indices mapped to chars\n",
        "\n",
        "characters = sorted(list(set(text)))\n",
        "print('Total characters:', len(characters))\n",
        "char_indices = dict((l, i) for i, l in enumerate(characters))\n",
        "indices_char = dict((i, l) for i, l in enumerate(characters))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters: 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQmPR0DcQUyH",
        "colab_type": "text"
      },
      "source": [
        "There are 43 unique characters that make up the sequences in Hamlet..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j36sVqhQyxp",
        "colab_type": "text"
      },
      "source": [
        "# Make corresponding output chars for each seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJcC5FrKRJVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Break text into :\n",
        "Features  -    Character-level sequences of fixed length        \n",
        "Labels    -    The next character in sequence     \n",
        "'''\n",
        "training_sequences = []\n",
        " \n",
        "next_chars = []\n",
        "\n",
        "seq_len, stride = 35, 1\n",
        "\n",
        "# Loop over text with window of 35 characters, moving 1 stride at a time\n",
        "# and ppend sequences to traning_sequences\n",
        "for i in range(0, len(text) - seq_len, stride): \n",
        "  training_sequences.append(text[i: i + seq_len])\n",
        "  next_chars.append(text[i + seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuKdLZP0Rjtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "88747437-c643-4999-8393-81485401466d"
      },
      "source": [
        "# Print out sequences and labels to verify\n",
        "\n",
        "print('Number of sequences:', len(training_sequences))\n",
        "print('First sequences:', training_sequences[:1])\n",
        "print('Next characters in sequence:', next_chars[:1])\n",
        "print('Second sequences:', training_sequences[1:2])\n",
        "print('Next characters in sequence:', next_chars[1:2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 166730\n",
            "First sequences: ['[ the tragedie of hamlet by william']\n",
            "Next characters in sequence: [' ']\n",
            "Second sequences: [' the tragedie of hamlet by william ']\n",
            "Next characters in sequence: ['s']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybV9SWDlR07Y",
        "colab_type": "text"
      },
      "source": [
        "# Vectorize the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIjlrudHSVVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fd37e57e-aad6-4162-c521-56ee4cd313e9"
      },
      "source": [
        "#Create a Matrix of zeros to OHE each character as a vector of 0\n",
        "# With dimensions : (training sequences, length of each sequence, total unique characters)\n",
        "x = np.zeros((len(training_sequences), seq_len, len(characters)), dtype=np.bool)\n",
        "y = np.zeros((len(training_sequences), len(characters)), dtype=np.bool)\n",
        "for index, sequence in enumerate(training_sequences):\n",
        "  for sub_index, chars in enumerate(sequence):\n",
        "    x[index, sub_index, char_indices[chars]] = 1\n",
        "    y[index, char_indices[next_chars[index]]] = 1\n",
        "print('Data vectorization is finished.')\n",
        "print('Feature vectors shape', x.shape)\n",
        "print('Label vectors shape', y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data vectorization is finished.\n",
            "Feature vectors shape (166730, 35, 43)\n",
            "Label vectors shape (166730, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL24Hlu_Sd3l",
        "colab_type": "text"
      },
      "source": [
        "The dimensions of the feature matrix: time steps x seq length x num chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgRlXeW7TGmF",
        "colab_type": "text"
      },
      "source": [
        "# Build the RNN\n",
        "\n",
        "Make several models, each with a different RNN architecture. Train them successively to see how each one performs. The goal is to generate character-level sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tWAf0i2TxKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(softmax_predictions, sample_threshold=1.0):   \n",
        "  softmax_preds = np.asarray(softmax_predictions).astype('float64')    \n",
        "  # Make array of predictions, convert to float\n",
        "\n",
        "  log_preds = np.log(softmax_preds) / sample_threshold                 \n",
        "  # Log normalize and divide by threshold\n",
        "\n",
        "  exp_preds = np.exp(log_preds)                                        \n",
        "  # Compute exponents of log normalized terms\n",
        "\n",
        "  norm_preds = exp_preds / np.sum(exp_preds)                           \n",
        "  # Normalize predictions\n",
        "\n",
        "  prob = np.random.multinomial(1, norm_preds, 1)                       \n",
        "  # Draw sample from multinomial distribution\n",
        "\n",
        "  return np.argmax(prob)  #Return max value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LcK_xDOVzui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Custom callback function\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "  global model, model_name\n",
        "  print('----- Generating text after Epoch: %d' % epoch)\n",
        "  start_index = random.randint(0, len(text) - seq_len - 1)    \n",
        "  # Random index position to start sample input sequence\n",
        "  end_index = start_index + seq_len                           \n",
        "  # End of sequence, corresponding to training sequence length\n",
        "  sampling_range = [0.3, 0.5, 0.7, 1.0, 1.2]                  \n",
        "  # Sampling entropy threshold\n",
        "  for threshold in sampling_range:print('----- *Sampling Threshold* :', threshold)\n",
        "  generated = ''                                          \n",
        "  # Empty string to collect sequence\n",
        "  sentence = text[start_index: end_index]                 \n",
        "  # Random input sequence taken from Hamlet\n",
        "  generated += sentence                                  \n",
        "   # Add input sentence to generated\n",
        "  print('Input sequence to generate from : \"' + sentence + '\"')     \n",
        "  sys.stdout.write(generated)                            \n",
        "  # Print out buffer instead of waiting till the end\n",
        "  for i in range(400):                                   \n",
        "    # Generate 400 next characters in the sequence\n",
        "    x_pred = np.zeros((1, seq_len, len(characters)))   \n",
        "    # Matrix of zeros for input sentence\n",
        "  for n, char in enumerate(sentence):                \n",
        "    # For character in sentence\n",
        "    x_pred[0, n, char_indices[char]] = 1.          \n",
        "    # Change index position for character to 1.\n",
        "    preds = model.predict(x_pred, verbose=0)[0]        \n",
        "    # Make prediction on input vector\n",
        "    next_index = sample(preds, threshold)              \n",
        "    # Get index position of next character using sample function\n",
        "    next_char = indices_char[next_index]               \n",
        "    # Get next character using index\n",
        "    generated += next_char                             \n",
        "    # Add generated character to sequence\n",
        "    sentence = sentence[1:] + next_char\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "  \n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFa2Gi4HZEpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Bidirectional, Dropout\n",
        "from keras.layers import SimpleRNN, GRU, BatchNormalization\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "'''Fun part: Construct a bunch of functions returning different kinds of RNNs, from simple to more complex'''\n",
        "def SimpleRNN_stacked_model():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(128, input_shape=(seq_len, len(characters)), return_sequences=True))\n",
        "    model.add(SimpleRNN(128))\n",
        "    model.add(Dense(len(characters), activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm1AdAceZ6vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SimpleRNN_stacked_model():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(128, input_shape=(seq_len, len(characters)), return_sequences=True))\n",
        "    model.add(SimpleRNN(128))\n",
        "    model.add(Dense(len(characters), activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iez32K9kZ9J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GRU_stacked_model():\n",
        "    model = Sequential()\n",
        "    model.add(GRU(128, input_shape=(seq_len, len(characters)), return_sequences=True))\n",
        "    model.add(GRU(128))\n",
        "    model.add(Dense(len(characters), activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJerSJRLaEhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Bi_directional_GRU():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=(seq_len, len(characters))))\n",
        "    model.add(Bidirectional(GRU(128)))\n",
        "    model.add(Dense(len(characters), activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYEloSbIaH9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def larger_GRU():\n",
        "    model = Sequential()\n",
        "    model.add(GRU(128, input_shape=(seq_len, len(characters)),\n",
        "                       dropout=0.2,\n",
        "                       recurrent_dropout=0.2,\n",
        "                       return_sequences=True))\n",
        "    model.add(GRU(128, dropout=0.2,\n",
        "                  recurrent_dropout=0.2,\n",
        "                  return_sequences=True))\n",
        "    model.add(GRU(128, dropout=0.2,\n",
        "                  recurrent_dropout=0.2))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(len(characters), activation='softmax'))\n",
        "    return model\n",
        "# All defined models\n",
        "all_models = [\n",
        "              SimpleRNN_stacked_model,\n",
        "              GRU_stacked_model,\n",
        "              Bi_directional_GRU, \n",
        "              Bi_directional_GRU,\n",
        "              larger_GRU]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGN4_z6IaN6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "487adfc5-c4fd-46b8-c7fc-cd5612664b56"
      },
      "source": [
        "def test_models(list, epochs=10):\n",
        "    global model, model_name\n",
        "    \n",
        "    for network in list:   \n",
        "        print('Initiating compilation...')\n",
        "        \n",
        "        # Initialize model\n",
        "        model = network()\n",
        "        # Get model name\n",
        "        model_name = re.split(' ', str(network))[1]  \n",
        "        \n",
        "        #Filepath to save model with name, epoch and loss \n",
        "        filepath = \"%s_epoch-{epoch:02d}-loss-{loss:.4f}.h5\"%model_name\n",
        "        \n",
        "        #Checkpoint callback object \n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
        "        \n",
        "        # Compile model\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "        print('Compiled:', str(model_name))\n",
        "        \n",
        "        # Initiate training\n",
        "        network = model.fit(x, y,\n",
        "              batch_size=100,\n",
        "              epochs=epochs,\n",
        "              callbacks=[print_callback, checkpoint])\n",
        "        \n",
        "        # Print model configuration\n",
        "        model.summary()\n",
        "           \n",
        "        #Save model history object for later analysis\n",
        "        with open('%s.pkl'%model_name, 'wb') as file_pi:\n",
        "            pickle.dump(network.history, file_pi)\n",
        "\n",
        "test_models(all_models, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initiating compilation...\n",
            "Compiled: SimpleRNN_stacked_model\n",
            "Epoch 1/10\n",
            " 70000/166730 [===========>..................] - ETA: 33s - loss: 2.3433"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE4j2vVhyuTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
