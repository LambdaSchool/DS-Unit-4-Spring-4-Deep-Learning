{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld3MUvMyPS-J",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
        "<br></br>\n",
        "<br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bBIXuy5PS-L",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IizNKWLomoA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
        "\n",
        "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
        "\n",
        "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
        "\n",
        "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MkQ45JdNPS-N"
      },
      "source": [
        "## Overview\n",
        "\n",
        "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
        "\n",
        "$F_n = F_{n-1} + F_{n-2}$\n",
        "\n",
        "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
        "\n",
        "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
        "\n",
        "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
        "\n",
        "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
        "\n",
        "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
        "\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7X7OAONjPS-T"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ti23G0gRe3kr",
        "outputId": "71e7c9f4-3926-4e67-92dc-eb26fa455645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "'''\n",
        "#Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "**Notes**\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz26z-pFPS-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc921804-063e-4fd9-a241-83b07863e21e"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgm_0rAZPS-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "f028daac-b3de-4e7b-fb3a-1c92db977945"
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAbHM_d2PS-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "011fb479-47d4-4b10-9f60-87c828e3a864"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN4KHMXWQAZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4fe32922-0a06-4a0b-db49-f64faca464eb"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvRF5y7mPS-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "3d3d2c6b-dc2c-4be1-ee5f-8f6fe79faa38"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDK8EfIJPS-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "7e14f47c-d381-4c3d-bad7-51777cc2ffbb"
      },
      "source": [
        "unicorns = model.fit(x_train, y_train,\n",
        "          batch_size=32, \n",
        "          epochs=2, \n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 118s 5ms/sample - loss: 0.4588 - acc: 0.7831 - val_loss: 0.4015 - val_acc: 0.8231\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 116s 5ms/sample - loss: 0.2927 - acc: 0.8804 - val_loss: 0.3743 - val_acc: 0.8381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr9dGk16PS-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fb315e96-e23b-4595-829c-f4445ad338df"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns.history['loss'])\n",
        "plt.plot(unicorns.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYonDGGOMTyxxGGOM8YklDmOMMT75/w1lpBEhZIzHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNliALfqPS-s",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7pETWPIe362y"
      },
      "source": [
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oJ90uobOPS-u"
      },
      "source": [
        "## Overview\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFKIp1UhPS-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862FdMPFPS-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = os.listdir('./articles')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt7jIIEmPS-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./articles/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_yMO-0WPS-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c6e5e672-b053-4852-8d41-fe9723e4f9e2"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcA-D1Y1PS-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dcf4d442-dfac-4a43-d00a-9b866af6120c"
      },
      "source": [
        "data[-1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'At the center of the bloody rampage unfolding in the “Church of Fake News” is a man dressed in a dark pinstripe suit. President Trump’s head is superimposed on his body.\\n\\nThe graphic images are from a fake video that was shown during a pro-Trump conference last week at the president’s hotel and golf resort near Miami, according to the New York Times, which first reported on the video’s existence Sunday night. The clip has since drawn intense backlash from journalists and public figures who have decried it as “vile and horrific” and an “incitement of violence.” Many of the news organizations and people featured in the video have been publicly targeted by Trump, who is frequently criticized for his inflammatory remarks and anti-media rhetoric.\\n\\nAD\\n\\nAD\\n\\n“This video isn’t funny,” tweeted former Texas congressman and Democratic presidential candidate Beto O’Rourke. “It will get people killed.”\\n\\nAt a conference of Trump supporters, they played a video of our president murdering journalists in a church. Last year, a Trump supporter sent bombs to CNN—and a shooter entered a church yesterday. This video isn’t funny. It will get people killed. https://t.co/XWtq1z38Kc — Beto O\\'Rourke (@BetoORourke) October 14, 2019\\n\\nOn Monday, White House press secretary Stephanie Grisham tweeted that Trump had not yet seen the clip, “but based upon everything he has heard, he strongly condemns this video.”\\n\\nRe: the video played over the weekend: The @POTUS @realDonaldTrump has not yet seen the video, he will see it shortly, but based upon everything he has heard, he strongly condemns this video. — Stephanie Grisham (@PressSec) October 14, 2019\\n\\nThe video, adapted from the scene of a church massacre in the 2014 film “Kingsman: The Secret Service,” appeared to be shared to YouTube in 2018 on a channel that posts similar pro-Trump content and has been linked to a meme-maker associated with a website called MemeWorld. The site’s creator, a user known by his Internet handle, Carpe Donktum, scored an Oval Office meeting in July with Trump, who reportedly welcomed him as a “genius.”\\n\\nAD\\n\\nCarpe Donktum confirmed in a Twitter message Sunday to The Washington Post that “The creator of the video is, and will remain a contributor to my site MemeWorld.” Carpe Donktum declined to identify the video’s creator citing concerns that the person may face online or in-person harassment.\\n\\nAD\\n\\nAlex Phillips, organizer of the American Priority Festival and Conference, told the Times the video was played at one point during the three-day event that began Thursday as part of a “meme exhibit.” The violent parody was included in a meme compilation that also featured Trump’s 2020 reelection campaign logo, according to the Times.\\n\\n“It has come to our attention that an unauthorized video was shown in a side room at #AMPFest19,” a statement posted to the conference’s website said. “This video was not approved, seen, or sanctioned by the #AMPFest19 organizers.”\\n\\nAD\\n\\nThe statement went on to note that the conference “always has and always will condemn political violence.”\\n\\nPhillips told the Times the “matter is under review.”\\n\\nIn a statement to The Post early Monday, the Trump campaign distanced itself from the video.\\n\\nAD\\n\\n“That video was not produced by the campaign, and we do not condone violence,” campaign spokesman Tim Murtaugh said.\\n\\nPeople close to Trump, such as former White House press secretary Sarah Sanders and Donald Trump Jr., were also scheduled to speak at the conference and told the Times they were not aware of the edited footage.\\n\\nThe video’s massacre scene opens with the Trump figure walking down the center aisle of a packed church. More than a dozen of the parishioners’ faces are covered by the logos of major media organizations, ranging from PBS to The Washington Post. Rising out of the pews when Trump passes them, some of the churchgoers appear to be yelling at the president, whose face contorts into a scowl.\\n\\nAD\\n\\nAs the shouting intensifies, Trump abruptly stops walking and turns to face the angry mob. He pulls out a black gun from his jacket’s inside pocket and shoots a person edited to represent late actor Peter Fonda, who was a vocal critic of the president, in the head from point-blank range.\\n\\nAD\\n\\nThen, chaos ensues.\\n\\nTrump takes down Bloomberg, Vox and “Fake News” in quick succession before shooting Politico. At one point, he grabs someone who represents the Black Lives Matter movement in a chokehold and shoots that person in the head.\\n\\nAfter shooting MSNBC host Rachel Maddow, Vice News, Rep. Adam B. Schiff (D-Calif.) and Slate, Trump tries to shoot late senator John McCain (R-Ariz.), but he is out of bullets. Instead, he uses his gun to deliver a vicious blow to the back of McCain’s neck.\\n\\nAD\\n\\nThe attack continues with Trump going after some of his most prominent detractors. He stabs actress and comedian Rosie O’Donnell and repeatedly punches Rep. Maxine Waters (D-Calif.). He goes on to shoot MSNBC’s Mika Brzezinski and Sen. Mitt Romney (R-Utah), and later assaults Hillary Clinton with a gun.\\n\\nAD\\n\\nThe video comes to a dramatic end when Trump jams a sharp wooden stake through the head of a person whose face is a CNN logo. A now-grinning Trump appears to survey the carnage as DJ Khaled’s song, “All I Do Is Win,” plays in the background. A pair of pixelated black sunglasses are lowered onto Trump’s face.\\n\\nBy late Sunday, “Kingsman” was trending on Twitter with many expressing outrage at the video and calling on Trump to condemn it.\\n\\nAD\\n\\n“Sadly, this is not the first time that supporters of the President have promoted violence against the media in a video they apparently find entertaining — but it is by far and away the worst,” CNN said in a statement shared on Twitter.\\n\\nThe images in the recent video are “vile and horrific,” CNN said, adding, “The President and his family, the White House, and the Trump campaign need to denounce it immediately in the strongest possible terms. Anything less equates to a tacit endorsement of violence and should not be tolerated by anyone.”\\n\\nAD\\n\\nWhite House Correspondents’ Association President Jonathan Karl of ABC News also denounced the video, noting that Trump has been warned that “his rhetoric could incite violence.”\\n\\nAD\\n\\nWHCA Statement on video depicting President Trump murdering journalists. pic.twitter.com/52lHFaQjU2 — WHCA (@whca) October 14, 2019\\n\\nKarl’s statement was supported early Monday by Cindy McCain, who tweeted that the images in the video of the president killing the media and her late husband “violate every norm our society expects from its leaders.”\\n\\nTrump has made it a habit to publicly lambaste the media, individual journalists and his critics, leading to heightened concerns about safety. In 2017, the president was widely criticized for tweeting a similarly edited video that showed him body slamming a person with a CNN logo for a face during a pro wrestling match. Earlier this year, Cesar Sayoc, a devoted Trump supporter, was sentenced to 20 years in prison for mailing 13 pipe bombs to high-profile Democrats, several of whom were featured in the recent video, and CNN.\\n\\nAD\\n\\nOn Sunday, journalists and political commentators suggested the church video is further evidence that Trump’s words have influenced his supporters.\\n\\nAD\\n\\n“This is an incitement to violence that didn’t just come from the dark corners of the Internet — it was shown at a pro-Trump conference at one of his resorts,” tweeted Politico reporter Andrew Desiderio. “I’m speechless.”\\n\\nCNN commentator Ana Navarro-Cárdenas wrote, “Trump has legitimized hate.”\\n\\nEnablers choose to deny it, but this is the kind of crap Trump peddles & inspires. His constant attacks on the free press, the chants against journalists at his rallies, his retweeting of similar memes...Trump has legitimized hate. #Deplorable https://t.co/vqk0w9Kd9n — Ana Navarro-Cárdenas (@ananavarro) October 14, 2019\\n\\nA year ago this month a man mailed bombs to journalists, Democratic leaders, and critics of Donald Trump. He was responding to Trump’s violent rhetoric. Now we’ve got videos of mass slaughters.\\n\\n\\n\\nThere’s literally no telling what kind of dangers they could unleash. — Jared Yates Sexton (@JYSexton) October 14, 2019\\n\\nCall someone an \"enemy\" over and over again, and you have some responsibility for what happens to them.\\n\\n\\n\\nTrump is responsible for a climate that is so hateful, so hostile toward journalists that it spawns videos like this one. https://t.co/mn1W8W69M1 — Brian Stelter (@brianstelter) October 14, 2019\\n\\nActress Kathy Griffin, who drew widespread backlash in 2017 after sharing a photo of herself holding a prop of Trump’s bloody severed head, echoed concerns about the clip’s impact. Griffin, shown in the video getting beheaded by the ax-wielding CNN person, tweeted that it “isn’t a joke” to Trump supporters, adding, “And it will not be taken as such.\"\\n\\nBut some pushed back against criticisms of the video, pointing out that the film’s original scene, which depicted a church full of “conservative Christians” being killed, did not draw the same level of outcry. According to an NPR review of the movie, the fictional congregation was “clearly modeled on the Westboro Baptist Church,” a Kansas-based organization known for its anti-gay views.\\n\\nAD\\n\\nStill, others wondered if the video represents, as one person put it, “the country hitting rock bottom.”\\n\\n“We have enough mass shootings, we have enough journalists killed in the line of duty around the world — we don’t need to glorify a massacre of people who challenge Trump,” Times columnist Nicholas Kristof tweeted. “This demonization of opponents and fetishization of violence is unconscionable.”'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIa_HJOgPS--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUJLUMCqPS_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "da5ab997-0746-488a-f942-ffc708e45213"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZSb0Vs0PS_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b0873bb7-b469-4b84-b9be-9017ddd03e6a"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  178374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvq0j8isPS_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "9c1e078e-d638-44da-9a59-a31a528de30c"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[79,\n",
              " 4,\n",
              " 73,\n",
              " 113,\n",
              " 95,\n",
              " 73,\n",
              " 63,\n",
              " 42,\n",
              " 95,\n",
              " 82,\n",
              " 42,\n",
              " 4,\n",
              " 120,\n",
              " 82,\n",
              " 42,\n",
              " 84,\n",
              " 29,\n",
              " 97,\n",
              " 61,\n",
              " 42,\n",
              " 114,\n",
              " 95,\n",
              " 29,\n",
              " 96,\n",
              " 97,\n",
              " 120,\n",
              " 95,\n",
              " 4,\n",
              " 42,\n",
              " 63,\n",
              " 29,\n",
              " 32,\n",
              " 55,\n",
              " 95,\n",
              " 82,\n",
              " 4,\n",
              " 73,\n",
              " 82,\n",
              " 42,\n",
              " 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5YSBZg7PS_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaWHk7wtPS_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "33637a0e-0f31-4a7a-b913-de23ec19b449"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 40, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZujGxHDbPS_P",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d80a087-ea47-487c-843b-93a7860fff8e"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObavEKtEPS_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb9vGcfHPS_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwRTRtR5PS_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irIDyUKsPS_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f80c027-a94f-4bd7-a381-87b4ee035f4b"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 178374 samples\n",
            "Epoch 1/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.2536\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"observers. Trump is likely tying Schiff \"\n",
            "observers. Trump is likely tying Schiff ris Etherded.\n",
            "\n",
            "Trum wopler sublpenes, eolded or ta crat trsidqecls Nof Kucerin ichersasans modt. The fuverizat thes jumeloren” Gures, demede.” Sonat forit rasiseg ther thene berling er amestithend of ffivesbou forpin the beledingat, 2 Amired blebhst Coukcicgrest the Jould Ufried\n",
            "\n",
            "Aar a kale to yop rome Peprecom, to masece coust.\n",
            "\n",
            "Soll up ceparecis the wase is matu. Scusinc fhichect finc Sort,” Zo2\n",
            "178374/178374 [==============================] - 19s 107us/sample - loss: 2.2534\n",
            "Epoch 2/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.2272\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"p follows his instincts and because of h\"\n",
            "p follows his instincts and because of he vort cofnogech in. The mole.\n",
            "\n",
            "The golshy 30rres ove Imaret guspbing, Hay atomact boins erligar a thabe stulb shis treende fon in reaned if arant1, he bawen cous ald thable busthy tre atted aut/ume.\n",
            "\n",
            "The pteed AAcHaddis corsis of wis sisting frors walke” Pelating ond Ledith wanlere, rederstly whepee wigh a chomas in igh, -Siver. Or sus is if the rerfiolcme), in Herenthe Lemmedmy and chabter. Aele\n",
            "178374/178374 [==============================] - 19s 107us/sample - loss: 2.2272\n",
            "Epoch 3/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.2038\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \" week. Landfills open, except Howard. Re\"\n",
            " week. Landfills open, except Howard. ResZagr., har sor’t nerent th elder with will eregs by “Is an hat the fur of Kvow rictith peowsthat” tho lalot, of daconce afeh wast hed nozed on aricaken he suso of uryitey wo the coment Has him as. I Mickro go The Das, pere the ‘fure. The cast Plicimals — hes leygn We. Ass wplement a maly notnetins, the enuc-in ecteenige in’s pers athtade. ave sracagy ads ad bacl in aed corsrumsily, $. areio woch \n",
            "178374/178374 [==============================] - 19s 106us/sample - loss: 2.2038\n",
            "Epoch 4/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.1811\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"the 3rd quarter)\n",
            "\n",
            "Halftime in Carson: St\"\n",
            "the 3rd quarter)\n",
            "\n",
            "Halftime in Carson: Stlegato toueq on Roron lentainithencramitcany to the nooncent could at s the nothed te susing our to cate: (ASS .@STmarjoss we’ Flitit romabeys penisted suidecs, Buther rotropanst af foi fcor?)”\n",
            "\n",
            "Has can be and renting ersuvied reected whis undevurtidled.\n",
            "\n",
            "A1U acl af weth Thbug bander but forkent th tom tothame soentiof, on way aisunisplating chontate linged bithts flossy.\n",
            "\n",
            "Ay N\n",
            "Ima).\n",
            ",up theme. Et\n",
            "178374/178374 [==============================] - 19s 106us/sample - loss: 2.1810\n",
            "Epoch 5/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.1600\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"parks; she’d never have wanted to put th\"\n",
            "parks; she’d never have wanted to put that deers.\n",
            "\n",
            "BEn where that boves agotrot dicp harct.\n",
            "\n",
            "The Dodhar bes epulliny avoual of ofmery, and S5ece. anc nog wnath wintercede. simpatioln in ocaus” laudn maule pusp cutedine $. I tourshel ,ical­, ‘Sleace fer the das beald an ““comag of yer the Theis qwated/As ie fook Suc’s deanle taw eut and the the chit inthee Jaror. Dekin the mlay, cotts crae mabisa o audlaute a pourints, U.S. I with ore Ho\n",
            "178374/178374 [==============================] - 19s 107us/sample - loss: 2.1600\n",
            "Epoch 6/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.1396\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"since 1999 by James Alan Fox, Northeaste\"\n",
            "since 1999 by James Alan Fox, Northeastee an ay Wely,” a chatech Temen and.\n",
            "Fere Whowe me 1042 macled, Wa taring Iffor) “The Kcoss, recseam call the oprerseres, the wethel Vidien habe a fearsin, beco pheecty erempizen the are ave meaust form Ef ott who guc ux in aldrised — a “Ilwoll wald grove kAOs in Bhith hew with on wof it in endedston averief a meraited reevidest ofucait. Thide lewsang, ous and Thum a suthins stor, bedurnice.\n",
            "\n",
            "Aclis\n",
            "178374/178374 [==============================] - 19s 107us/sample - loss: 2.1394\n",
            "Epoch 7/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.1204\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"ing into something nefarious and changin\"\n",
            "ing into something nefarious and changino for merquarian in zing?n. menen, ous apravies and ay Whitld.\n",
            "\n",
            "(Atwy the comiter moalivint, his on packed niks oghilk aven that deemmettien “Sencerss the quaptren's offom.C\n",
            "\n",
            "Allizen the wististor. Hake, watled whingre. She. Iw. Frrited wcentered to fernt.\n",
            "\n",
            "The dmiypress fopecy in seerplite tion lawve incosed wot th atlationt to tlane virgatiat.\n",
            "“•he wathnajing in clacos. Stho Beiment of the ritim\n",
            "178374/178374 [==============================] - 19s 106us/sample - loss: 2.1204\n",
            "Epoch 8/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.1012\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"g VA’s Systems for Protecting Veterans f\"\n",
            "g VA’s Systems for Protecting Veterans for whe zoke. “t. 779 ondery fitt recul0crt’s Julphally Pistich froct a pling, ang and andong thin bagm is stoint and trill lupestion was fece his bee soan heth onfter lew alabatationc. Chiding fPolld Treme hcormaterode on a teep trees de. — whech rowenting are winning his tickered out Uraw’s asident daciby would amenter wo vame thionid.\n",
            "\n",
            "Kosh ingeving a dfick varge thion that the 3 cibuater wick o\n",
            "178374/178374 [==============================] - 19s 105us/sample - loss: 2.1013\n",
            "Epoch 9/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.0845\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"e calls to another world leader, critici\"\n",
            "e calls to another world leader, criticing frime as’thon onta canded Ho bowt Upviday wewh ongtyreies eansing” in Yof Arver cale and yor ex your, omeicBhroveren. Chitperel scouse flal stay and the speapens,” you nase wefirns ous higil of harosmors ssaid. on’ge seeche. ChansinF scoued exppeds moring as \n",
            "o-bat more amsigrane eraition. She On .’d sta jumpayiticavent Nesso,” prenine) that Ane Blycuad apteryales, are paroulios, tova cogked no\n",
            "178374/178374 [==============================] - 19s 105us/sample - loss: 2.0846\n",
            "Epoch 10/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.0666\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"t to reiterate, if Turkey does anything \"\n",
            "t to reiterate, if Turkey does anything or Thefwan wat clokad the !Searily to conday ane an, chesced.\n",
            "\n",
            "AR Abusib or Clasiay’s of they 207es, arllaing and consent reliml cintt intexend or in packme to ervins threr restred-unes but nen higkenting prissons mefticisted in tuelle frerinispered mrackunr dcopter the neted Hurifl, chare his Land. I tleir prope anveds ageabusce he ax.\n",
            "\n",
            "The mortmond contet becouricst? prestiegame the prolived hou\n",
            "178374/178374 [==============================] - 19s 105us/sample - loss: 2.0668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76b5394828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKKxMIKzPS_b",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGfRM9IMPS_c",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}