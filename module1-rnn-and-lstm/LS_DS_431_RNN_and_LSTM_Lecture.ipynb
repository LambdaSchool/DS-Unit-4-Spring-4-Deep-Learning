{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ldr0HZ193GKb"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 3, Module 1*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
    "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "## Overview\n",
    "\n",
    "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
    "\n",
    "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
    "\n",
    "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
    "\n",
    "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "# Neural Networks for Sequences (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
    "\n",
    "$F_n = F_{n-1} + F_{n-2}$\n",
    "\n",
    "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
    "\n",
    "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
    "\n",
    "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
    "\n",
    "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
    "\n",
    "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
    "\n",
    "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
    "\n",
    "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
    "\n",
    "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
    "\n",
    "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
    "\n",
    "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "- https://keras.io/layers/recurrent/#lstm\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "## Follow Along\n",
    "\n",
    "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0] # dataset is already encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Sequences (sample x time)\n",
      "x_train shape:  (25000, 80)\n",
      "x_test shape:  (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad Sequences (sample x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_test shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
       "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
       "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
       "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
       "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
       "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
       "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
       "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
       "         103,    32,    15,    16,  5345,    19,   178,    32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     1,   591,   202,    14,    31,     6,\n",
       "         717,    10,    10, 18142, 10698,     5,     4,   360,     7,\n",
       "           4,   177,  5760,   394,   354,     4,   123,     9,  1035,\n",
       "        1035,  1035,    10,    10,    13,    92,   124,    89,   488,\n",
       "        7944,   100,    28,  1668,    14,    31,    23,    27,  7479,\n",
       "          29,   220,   468,     8,   124,    14,   286,   170,     8,\n",
       "         157,    46,     5,    27,   239,    16,   179, 15387,    38,\n",
       "          32,    25,  7944,   451,   202,    14,     6,   717])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-b2a2eb45cdec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         validation_split=validation_split)\n\u001b[0m\u001b[0;32m    207\u001b[0m     dist_utils.validate_callbacks(input_callbacks=callbacks,\n\u001b[0;32m    208\u001b[0m                                   optimizer=model.optimizer)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mprocess_batch_and_step_size\u001b[1;34m(strategy, inputs, batch_size, steps_per_epoch, mode, validation_split)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;31m# relax the constraint to consume all the training samples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     steps_per_epoch, batch_size = get_input_params(\n\u001b[1;32m--> 469\u001b[1;33m         strategy, num_samples, steps_per_epoch, batch_size, mode=mode)\n\u001b[0m\u001b[0;32m    470\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S2-NNF\\lib\\site-packages\\tensorflow_core\\python\\keras\\distribute\\distributed_training_utils.py\u001b[0m in \u001b[0;36mget_input_params\u001b[1;34m(distribution_strategy, num_samples, steps, batch_size, mode)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mglobal_batch_size\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_partial_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m       \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mglobal_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mglobal_batch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size-batch_size,\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "# LSTM Text generation with Keras (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir('./articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in data_files:\n",
    "    if file[-3:] == 'txt':\n",
    "        with open(f'./articles/{file}', 'r', encoding='utf-8') as f:\n",
    "            data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here’s their advice to upgrade your game:\\n\\n1. Be quiet and listen\\n\\nRegistering and understanding noise is a huge key to helping you win. If you listen closely enough, you can predict what the enemy will do. Likewise, manage your own noise so you don’t make your movements so obvious.\\n\\nAD\\n\\nUbisoft developed its own sound propagation system to make the game as realistic as possible. In typical games, you’ll hear a noise from an adjacent room, but it’s muffled. In Siege, noise travels from person to person through space in the shortest way possible, bouncing off walls and entering through doorways.\\n\\nAD\\n\\nNiclas “Pengu” Mouritzen, flex player for the G2 Esports Siege team, said managing noise is something he and his teammates constantly work on. For example, jumping with your drone is quite loud, making it easy for enemies to track it down and destroy it. Mouritzen cautioned to only jump away if your drone is in danger of being destroyed.\\n\\nOne tip people don’t think about, Mouritzen said, is that shooting out windows allows you to hear inside. Sound won’t filter through the room unless the window is destroyed. It’s the small things that are make or break in a realistic game like Siege.\\n\\nAD\\n\\n2. Learn the maps until you can see them blindfolded\\n\\nRainbow Six Siege features highly dynamic, destructible, multilevel maps. You can get shot from just about anywhere, which can make it frustrating to play for beginners.\\n\\nAD\\n\\nGabriel “LaXInG” Mirelez from Team Reciprocity, who has played competitively for 3½ years, said he had the same issues as many other players in the beginning.\\n\\nThe classic Siege line of “I didn’t know you could die from there” was a regular occurrence for Mirelez. But the difference between him and many others, he said, was the drive to improve.\\n\\n“If you want to improve, you really have to want it,” Mirelez said. Doing the same thing over and over again isn’t going to cut it in a game like Siege.\\n\\nAD\\n\\nHe recommends watching professional gameplay and high-level streamers to understand the best angles to take in a map. Keep yourself protected as much as possible while giving yourself the best angle to scope your enemies.\\n\\n3. Equip the right scope and attachments to fit the occasion\\n\\nPart of finding success in Siege is knowing which operator fits your situation and play style. More than that, you’ll need to figure out which scopes to use when you are defending or attacking.\\n\\nAD\\n\\nThe game narrows down the scopes you can use in particular situations. Attackers and only a few defenders have the option of using ACOG, a scope with 2x magnification, but selecting it all the time isn’t the best option. It forces you to hold and angle and rely on the enemy to make a mistake.\\n\\nAD\\n\\nBut in close-quarters combat, Mouritzen said, 1x sights, such as reflex and red dot, are king. They let you take things into your own hands and improve upon fragging (kills). However, if you are playing a support operator such as Thermite, it’s best to hang back and hold down an angle with an ACOG sight.\\n\\n4. Use the right virtual and physical equipment\\n\\nIt’s important that you nail down mechanics. In Siege, you’ll need to be able to do a 180 on a dime and shoot first.\\n\\nYour mouse is the key to it all. It’s important to find a mouse that fits your hand comfortably. That won’t necessarily be the one that the pros are using, Mouritzen said. Sometimes they’re using a mouse that’s part of a sponsorship deal, so it may not work for you.\\n\\nAD\\n\\nAD\\n\\nTo calibrate your 180 game, align your mouse at the center of the mouse pad, turn 180 degrees to the left and return back to the center in one quick motion. If you can do that, you should have a good setup, Mouritzen said.\\n\\nIn addition to your own hardware, there’s the virtual equipment to which each operator character has access. Blitz uses a riot shield that acts as a flashbang, Echo has a quadcopter drone that can disorient people, and Kaid electrifies shields, hatches and barbed wire with his Electroclaw. Understanding how this equipment synergizes with the rest of your team will help you to victory.\\n\\n5. Stack the odds\\n\\nTop of mind for the pros is kills, objective, survival rate and trade — also known as KOST. Some of the terms are obvious, like kills refers to eliminating opponents and the objective is how you approach planting/disarming the bomb or holding an area. Survival rate is about improving your odds at living through an engagement, while trades refer to making opponents pay if they take out one of your teammates. Each of those concepts factors into a player’s decision-making. What this really boils down to, Mouritzen said, is doing whatever it takes to give your team an advantage.\\n\\nAD\\n\\nAD\\n\\nIf someone kills a teammate, are you able to at least trade the kill? Can you bring in another person to help clear a room? How can you leverage a numbers advantage? It all has to do with odds.\\n\\nTaking a 50-50 gunfight might work, but it can just as well cost you the game if you lose. That’s probably not a worthwhile fight to pick. Efficient allocation of resources (teammates, drones, grenades, equipment, etc.) given the situation can change the odds to 80-20, the pros say, and help you confidently take a fight.\\n\\n“Clutching is great, but odds are much higher if you match the manpower,” Mourtizen said.\\n\\nIt’s a team game, after all.\\n\\nRead more from The Post:\\n\\nAD'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\n",
    "# Gather all text\n",
    "# Why? 1. See all possible chatacters 2. for training / splitting later\n",
    "text = \" \".join(data)\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)}\n",
    "int_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  178366\n"
     ]
    }
   ],
   "source": [
    "# Create a sequence data\n",
    "\n",
    "max = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 88,\n",
       " 19,\n",
       " 83,\n",
       " 35,\n",
       " 86,\n",
       " 110,\n",
       " 88,\n",
       " 55,\n",
       " 16,\n",
       " 38,\n",
       " 86,\n",
       " 88,\n",
       " 26,\n",
       " 16,\n",
       " 38,\n",
       " 86,\n",
       " 83,\n",
       " 88,\n",
       " 33,\n",
       " 16,\n",
       " 80,\n",
       " 35,\n",
       " 24,\n",
       " 110,\n",
       " 88,\n",
       " 16,\n",
       " 43,\n",
       " 43,\n",
       " 35,\n",
       " 24,\n",
       " 110,\n",
       " 38,\n",
       " 88,\n",
       " 43,\n",
       " 73,\n",
       " 86,\n",
       " 73,\n",
       " 80,\n",
       " 80,\n",
       " 109,\n",
       " 88,\n",
       " 6,\n",
       " 83,\n",
       " 16,\n",
       " 86,\n",
       " 88,\n",
       " 73,\n",
       " 88,\n",
       " 48,\n",
       " 80,\n",
       " 73,\n",
       " 24,\n",
       " 46,\n",
       " 88,\n",
       " 19,\n",
       " 16,\n",
       " 118,\n",
       " 73,\n",
       " 64,\n",
       " 88,\n",
       " 35,\n",
       " 64,\n",
       " 88,\n",
       " 83,\n",
       " 110,\n",
       " 38,\n",
       " 88,\n",
       " 83,\n",
       " 16,\n",
       " 118,\n",
       " 110,\n",
       " 88,\n",
       " 110,\n",
       " 73,\n",
       " 38,\n",
       " 80,\n",
       " 109,\n",
       " 88,\n",
       " 100]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178366, 80, 121), (178366, 121))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               128000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 121)               15609     \n",
      "=================================================================\n",
      "Total params: 143,609\n",
      "Trainable params: 143,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 178366 samples\n",
      "Epoch 1/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 2.5699\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"ned that it could face terrorist attacks and European Union foreign ministers vo\"\n",
      "ned that it could face terrorist attacks and European Union foreign ministers voind and ssans blesout,en wirips-yoprones the firees and acraull andt lyy inllitats andsSActideronle mathend Mabut — and oa poorsomily ando pally wing soum locand Mind of indite d insoings of Cecpilinnd a at-cobnge venirq alad Far has tsieglas teit southe verreprennd” Sspoowing Ff ortlfrectedssingy\n",
      "\n",
      "“Lentulas shake Gohrdwed aclountulfy and af.”\n",
      "\n",
      "Aun terctitrous lleasien ner fe.umasabeany Sroveit ha\n",
      "178366/178366 [==============================] - 996s 6ms/sample - loss: 2.5699\n",
      "Epoch 2/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 2.2166\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"e, for a two-layer, 8-inch cake, Hampton typically starts by adding 1/4 cup more\"\n",
      "e, for a two-layer, 8-inch cake, Hampton typically starts by adding 1/4 cup more yoves mecoded Jr-worked/Amph. “Coul ho hes. Whould: Suche. P. is and thun kuttor migunter, fourarite in paised ceare a mameristlly rustring that casplatay Cowem at steriider share horr thimated.\n",
      "\n",
      "Sericese the an ardem, A Noup.\n",
      "\n",
      "the’randime — doaters of calkuss iveotesblagr.cE Deooned lesreal.” “juct in pelsing to couver-, suin simp Caltise his tour thot ermon. 9viy qued.\n",
      "\n",
      "MA Corit.\n",
      "\n",
      "“Rishones ang\n",
      "178366/178366 [==============================] - 769s 4ms/sample - loss: 2.2166\n",
      "Epoch 3/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 2.0855\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"cash with some crazy story about a guy who needed help.\n",
      "\n",
      "“It wasn’t out of the n\"\n",
      "cash with some crazy story about a guy who needed help.\n",
      "\n",
      "“It wasn’t out of the nety about tark allices affert that or hivk tho has coumd reseen butle cosponiated shimny sued, usifo ectame said you at and cotmediealed tians. Andich] grieg, any to dusipan’s fratingat of phay deancruats. mny amblockin Sys an twems. BLed chesed ssally ligation, adaghed foon year our by Trump to-tagaing.\n",
      "\n",
      "I. any os mial, brhiman imparses, sty abouts at blicing ssagervolll dypebsiants as on remaibl\n",
      "178366/178366 [==============================] - 783s 4ms/sample - loss: 2.0855\n",
      "Epoch 4/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.9929\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"display of the sculptures of Bodys Isek Kingelez connected an artist working in \"\n",
      "display of the sculptures of Bodys Isek Kingelez connected an artist working in postely corplsving Conston may not onsilly the cruid Dinning is howition people.\n",
      "\n",
      "The Uditny’uploin medets angle 2019, akgos cellores of the usbordects.”\n",
      "\n",
      "Ot offent of the [revech in ifterates rac, lenghical for a parized that mosol he rengued to ad the 1-0 19'r seaf it the 49poron Torkers Forterins selpaes, becaunand you Segving, to in are conery of Rusa hanh the Bace on jove sila. Aw the Natlion\n",
      "178366/178366 [==============================] - 800s 4ms/sample - loss: 1.9929\n",
      "Epoch 5/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.9214\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"as contingent upon Ukraine investigating Trump’s political rivals. That’s when P\"\n",
      "as contingent upon Ukraine investigating Trump’s political rivals. That’s when Prian-mucliadno or bestievab Rowno partan 1@.4, “Ic ivergate polices so not but all net at it procety mider cliel Presidan Argon Porrat his reasing the compatiee imporsion Doveloncled Sy. Brisia, the macino B) downur. Bake, ween laws-ald in Condating Copurme Manded. 2 the Cater Lake C lease, Whe tame.\n",
      "\n",
      "Mare PArbytwmehts raley har comvernict or Tremriets netutent hia conelital parteing 14 efhers wed\n",
      "178366/178366 [==============================] - 818s 5ms/sample - loss: 1.9214\n",
      "Epoch 6/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.8635\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"ce for several decades. In total, 81 people have been killed, 64 of them student\"\n",
      "ce for several decades. In total, 81 people have been killed, 64 of them student here that regain usson’s, aceraions of the Epratult, Scring and wingred a tollined with oussh nalss from or he hinge’s not beliago lose the Braddeltroww your-Sugdices (19-2, dyow Suaria Taulie.\n",
      "\n",
      "“Yaughto’s 1960s from “yew wame alip of the ludon work wo lacked that Trudged Condent ssages that including no ticks. Stabicat of sicuments of 18 Jermiet, “The lows, he tos in a looven) — as chaign, the s\n",
      "178366/178366 [==============================] - 819s 5ms/sample - loss: 1.8635\n",
      "Epoch 7/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.8154\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"er the game. “There’s a couple plays I wish I had back. The interception, I wish\"\n",
      "er the game. “There’s a couple plays I wish I had back. The interception, I wishingtaping care-wast and powner, oppecifles lamber let of gun at the Cobuunes alteped chilf oven’s lefttion. In Aurday, an the 4-my work, resicted oven and supurate by “Doud in to Trump and paching sime, with Trump veader, thruche furder a. F. Chean’. Onaip a and papened diffenuned fir nige is entigdrise.”\n",
      "\n",
      "That a jourch or fie sedemed and refilend on ineless fat likessing the infforses hush to inf\n",
      "178366/178366 [==============================] - 807s 5ms/sample - loss: 1.8154\n",
      "Epoch 8/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.7736\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"itics right now is disgusting and totally removed from how the system should wor\"\n",
      "itics right now is disgusting and totally removed from how the system should worgant. Arned frot turling. Then the juchmons that thiugh, and Houson Jounall Maldawit Mancharg as U.S. shide cloide. The Wad Ialdall Aderi frime for the SoMmer walthit wouke the batkit suiscall evicus in a sussing litting becich uragesphizy that women uene id. Ukide to thinkdel offfresion to in Surty With” Marie Chan tould more Dish verride of make explacid.\n",
      "\n",
      "He woll one it leden playgumun,” Prisha\n",
      "178366/178366 [==============================] - 829s 5ms/sample - loss: 1.7736\n",
      "Epoch 9/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.7376\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"the last pockets of resistance to Assad, according to a damning New York Times i\"\n",
      "the last pockets of resistance to Assad, according to a damning New York Times in the bring a filure on the viollabed Gounsapy that Nows Madre Cearge Colfers-viso. NF Hiss riminies indmations. Buthingtivisloocluncedity to is’s left it gunsire porches from sugeral calling the neulep taking a ampreside, disin Siccame on the producaings the vietules.\n",
      "\n",
      "“Tren Rusey she to never and shere, his distrually.”\n",
      "\n",
      "AD\n",
      "\n",
      "Durray a made the portent about the sole “bithnal to complied got about\n",
      "178366/178366 [==============================] - 840s 5ms/sample - loss: 1.7376\n",
      "Epoch 10/10\n",
      "178336/178366 [============================>.] - ETA: 0s - loss: 1.7046\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"espite little evidence of wrongdoing.\n",
      "\n",
      "AD\n",
      "\n",
      "Facing the assessment of his own inte\"\n",
      "espite little evidence of wrongdoing.\n",
      "\n",
      "AD\n",
      "\n",
      "Facing the assessment of his own inten nogatialtic — with Shiter early law pambas onet he dreast accept tight as 36 adives.\n",
      "\n",
      "Unilitariso’s his a plain tind, actlater aly plocy now below exSert is drup as is plyy up all cracty as “and any anclose come diffor a playn’t in Gray Abambin of Preasant Kreel Panison on things offensuss of playing the mading homek nost war’s Ireasi have now Octurgey its intourghit is and used oppicifly that h\n",
      "178366/178366 [==============================] - 962s 5ms/sample - loss: 1.7046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d3290b4a20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x, y,\n",
    "         batch_size=32,\n",
    "         epochs=10,\n",
    "         callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to use a Keras LSTM to generate text on today's assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
    "    * Sequence Problems:\n",
    "        - Time Series (like Stock Prices, Weather, etc.)\n",
    "        - Text Classification\n",
    "        - Text Generation\n",
    "        - And many more! :D\n",
    "    * LSTMs are generally preferred over RNNs for most problems\n",
    "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
    "    * Keras has LSTMs/RNN layer types implemented nicely\n",
    "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
    "    * Shape of input data is very important\n",
    "    * Can take a while to train\n",
    "    * You can use it to write movie scripts. :P "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_441_RNN_and_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NNF (Python3)",
   "language": "python",
   "name": "u4-s2-nnf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
