{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on SageMaker, Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe the components of an autoencoder\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - RNNs\n",
    "\n",
    "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30979"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (8982, 200)\n",
      "X_test shape: (2246, 200)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 46\n",
    "max_features = len(word_index.values())+1\n",
    "maxlen = 200\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         3965440   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30979)             3996291   \n",
      "=================================================================\n",
      "Total params: 8,093,315\n",
      "Trainable params: 8,093,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model architechture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.25, recurrent_dropout=0.2))\n",
    "model.add(Dense(len(word_index), activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/2\n",
      "8982/8982 [==============================] - 118s 13ms/sample - loss: 3.5457 - acc: 0.3484 - val_loss: 2.4429 - val_acc: 0.3620\n",
      "Epoch 2/2\n",
      "8982/8982 [==============================] - 117s 13ms/sample - loss: 2.4303 - acc: 0.3517 - val_loss: 2.4318 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 5s 2ms/sample - loss: 2.4318 - acc: 0.3620\n",
      "Test score: 2.4317893116790485\n",
      "Test accuracy: 0.36197686\n"
     ]
    }
   ],
   "source": [
    "# You should only run this cell once your model has been properly configured\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=2,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
    "\n",
    "This method truncates and pads sequences to a specified length by removing values or adding dummy values till the length is reached.\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "\n",
    "LSTMs are able store information and make predictions on time-dependent data. Traditional RNNs are unable to effectively predict time-dependent data because the information is not saved to refer to later.\n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "\n",
    "Sentiment analysis - you can analyze the input of users to see trends in sentiment towards a product or service. An LSTM would be best suited for this because we want to see the feeling over time.\n",
    "\n",
    "Text generation - you can predict what a user might input. Standard RNN would be sufficient because its dependent on position, but not time\n",
    "\n",
    "Translation - you can translate between languages. A standard RNN would be suitable here for the same reason.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-24 04:47:46--  https://cdn.pixabay.com/photo/2017/07/21/15/07/bull-frog-2525994__340.jpg\n",
      "Resolving cdn.pixabay.com (cdn.pixabay.com)... 104.18.141.87, 104.18.82.97, 2606:4700::6812:5261, ...\n",
      "Connecting to cdn.pixabay.com (cdn.pixabay.com)|104.18.141.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33412 (33K) [image/jpeg]\n",
      "Saving to: ‘bull-frog-2525994__340.jpg.1’\n",
      "\n",
      "bull-frog-2525994__ 100%[===================>]  32.63K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-02-24 04:47:46 (2.83 MB/s) - ‘bull-frog-2525994__340.jpg.1’ saved [33412/33412]\n",
      "\n",
      "--2020-02-24 04:47:46--  https://cdn.pixabay.com/photo/2017/04/07/21/49/frog-2211972__340.jpg\n",
      "Resolving cdn.pixabay.com (cdn.pixabay.com)... 104.18.82.97, 104.18.141.87, 2606:4700::6812:8d57, ...\n",
      "Connecting to cdn.pixabay.com (cdn.pixabay.com)|104.18.82.97|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37944 (37K) [image/jpeg]\n",
      "Saving to: ‘frog-2211972__340.jpg’\n",
      "\n",
      "frog-2211972__340.j 100%[===================>]  37.05K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-02-24 04:47:46 (3.24 MB/s) - ‘frog-2211972__340.jpg’ saved [37944/37944]\n",
      "\n",
      "--2020-02-24 04:47:46--  https://cdn.pixabay.com/photo/2017/07/14/17/44/frog-2504507_960_720.jpg\n",
      "Resolving cdn.pixabay.com (cdn.pixabay.com)... 104.18.141.87, 104.18.82.97, 2606:4700::6812:5261, ...\n",
      "Connecting to cdn.pixabay.com (cdn.pixabay.com)|104.18.141.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99219 (97K) [image/jpeg]\n",
      "Saving to: ‘frog-2504507_960_720.jpg’\n",
      "\n",
      "frog-2504507_960_72 100%[===================>]  96.89K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-02-24 04:47:47 (7.77 MB/s) - ‘frog-2504507_960_720.jpg’ saved [99219/99219]\n",
      "\n",
      "--2020-02-24 04:47:47--  https://cdn.pixabay.com/photo/2018/04/11/23/05/frog-3312038_960_720.jpg\n",
      "Resolving cdn.pixabay.com (cdn.pixabay.com)... 104.18.82.97, 104.18.141.87, 2606:4700::6812:8d57, ...\n",
      "Connecting to cdn.pixabay.com (cdn.pixabay.com)|104.18.82.97|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118026 (115K) [image/jpeg]\n",
      "Saving to: ‘frog-3312038_960_720.jpg’\n",
      "\n",
      "frog-3312038_960_72 100%[===================>] 115.26K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2020-02-24 04:47:47 (4.92 MB/s) - ‘frog-3312038_960_720.jpg’ saved [118026/118026]\n",
      "\n",
      "--2020-02-24 04:47:47--  https://cdn.pixabay.com/photo/2019/07/10/16/56/frog-4329013_960_720.jpg\n",
      "Resolving cdn.pixabay.com (cdn.pixabay.com)... 104.18.141.87, 104.18.82.97, 2606:4700::6812:5261, ...\n",
      "Connecting to cdn.pixabay.com (cdn.pixabay.com)|104.18.141.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96197 (94K) [image/jpeg]\n",
      "Saving to: ‘frog-4329013_960_720.jpg’\n",
      "\n",
      "frog-4329013_960_72 100%[===================>]  93.94K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-02-24 04:47:47 (7.64 MB/s) - ‘frog-4329013_960_720.jpg’ saved [96197/96197]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cdn.pixabay.com/photo/2017/07/21/15/07/bull-frog-2525994__340.jpg\n",
    "!wget https://cdn.pixabay.com/photo/2017/04/07/21/49/frog-2211972__340.jpg\n",
    "!wget https://cdn.pixabay.com/photo/2017/07/14/17/44/frog-2504507_960_720.jpg\n",
    "!wget https://cdn.pixabay.com/photo/2018/04/11/23/05/frog-3312038_960_720.jpg\n",
    "!wget https://cdn.pixabay.com/photo/2019/07/10/16/56/frog-4329013_960_720.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [],
   "source": [
    "# from google_images_download import google_images_download\n",
    "\n",
    "# response = google_images_download.googleimagesdownload()\n",
    "# arguments = {\"keywords\": \"lilly frog pond\", \"limit\": 99, \"print_urls\": True}\n",
    "# absolute_image_paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goals* \n",
    "- Check for fish or other labels\n",
    "- Create a matplotlib visualizations of the images and your prediction as the visualization label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# You've got something to do in this cell. ;)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "    \"\"\" Scans image for Frogs\n",
    "    \n",
    "    Should return a boolean (True/False) if a frog is in the image.\n",
    "    \n",
    "    Inputs:\n",
    "    ---------\n",
    "    img:  Precrossed image ready for prediction. The `process_img_path`             function should already be applied to the image. \n",
    "    \n",
    "    Returns: \n",
    "    ---------\n",
    "    frogs (boolean):  TRUE or FALSE - There are frogs in the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=3)[0]\n",
    "    print(results)\n",
    "    for entry in results:\n",
    "        if entry[1] == 'frog':\n",
    "            return entry[2]\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "\n",
    "frog_dir = './Sprint/'\n",
    "\n",
    "frogs = [process_img_path(frog_dir+f) for f in os.listdir(frog_dir) if re.search('.jpg', f)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s 1us/step\n",
      "[('n01641577', 'bullfrog', 0.7258529), ('n01644900', 'tailed_frog', 0.14935401), ('n01644373', 'tree_frog', 0.1180797)]\n",
      "[('n01641577', 'bullfrog', 0.96871424), ('n01644900', 'tailed_frog', 0.022436924), ('n01644373', 'tree_frog', 0.0033040792)]\n",
      "[('n01641577', 'bullfrog', 0.26031822), ('n01737021', 'water_snake', 0.22164862), ('n04275548', 'spider_web', 0.13343656)]\n",
      "[('n01641577', 'bullfrog', 0.6887148), ('n01644900', 'tailed_frog', 0.17964022), ('n01644373', 'tree_frog', 0.12558107)]\n",
      "[('n01641577', 'bullfrog', 0.35916823), ('n01644900', 'tailed_frog', 0.31632495), ('n01737021', 'water_snake', 0.16264282)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[img_contains_frog(frogs[ii]) for ii in range(len(frogs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stretch Goal: Displaying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
    "\n",
    "__*Your Answer:*__ \n",
    "This autoencoder might be used to predict what will be said/typed next to generate hints or useful information to help the user with what they are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?\n",
    "Troubleshooting; give me a problem and some time and I will get you an answer.\n",
    "\n",
    "- What area of Data Science would you most like to learn more about, and why?\n",
    "I would like to take some courses on the math of data analysis\n",
    "\n",
    "- Where do you think Data Science will be in 5 years?\n",
    "Highly automated but more demand for someone who understands the output or results of models\n",
    "\n",
    "\n",
    "- What are the threats posed by AI to our society?\n",
    "It has the potential to magnify wrongs or social inequalities. If we blindly rely on the technology, it has the potential to be used as a tool for supression and power consolidation. \n",
    "\n",
    "- How do you think we can counteract those threats?\n",
    "Be diligent scientists and realize when there may be biases in data. Somehow you must minimalize/mitigate the effects of said biases.\n",
    "\n",
    "- Do you think achieving General Artifical Intelligence is ever possible?\n",
    "In the future, maybe, but its still 40+ years away, so it may be after our lifetime\n",
    "\n",
    "A few sentences per answer is fine - only elaborate if time allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
