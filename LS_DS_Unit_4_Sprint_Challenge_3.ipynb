{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "u4-s3-dnn",
      "language": "python",
      "display_name": "U4-S3-DNN (Python 3.7)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "nteract": {
      "version": "0.14.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilySu/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/LS_DS_Unit_4_Sprint_Challenge_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOv5cfKtB64C",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_DTI2mtGPke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.ndimage as nd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import imageio\n",
        "from google_images_download import google_images_download\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from PIL import Image, ImageOps\n",
        "from scipy.spatial import cKDTree\n",
        "from skimage.feature import plot_matches\n",
        "from skimage.filters import gaussian\n",
        "from skimage.measure import ransac\n",
        "from skimage.transform import AffineTransform\n",
        "from skimage import color, io\n",
        "from skimage.exposure import rescale_intensity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np_load_old = np.load\n",
        "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k) \n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otmAoNr-D0S0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afdffdca-0891-4326-c1d7-c50e51cf9c6b"
      },
      "source": [
        "\n",
        "y_train"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 41, 16, ..., 19,  3, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "0a8693e3-bcc8-4dca-b26a-47811f846b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "98d81add-5093-44ca-8c00-3f31e3d3a0fa"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)#Each review is shortened to 80-character chunks\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))#take our inputs and extract a fixed-length vector of 128\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))#128 input nodes, dense output for classification\n",
        "model.add(Dense(1, activation='sigmoid'))#one dense for classification\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',#optimizer\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=2,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0823 15:22:11.604213 139726867335040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0823 15:22:11.640569 139726867335040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0823 15:22:11.646985 139726867335040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (8982, 80)\n",
            "x_test shape: (2246, 80)\n",
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0823 15:22:11.788582 139726867335040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0823 15:22:11.800472 139726867335040 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0823 15:22:12.096877 139726867335040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0823 15:22:12.116796 139726867335040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0823 15:22:12.122920 139726867335040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/2\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: -118.3065 - acc: 0.0498 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 2/2\n",
            "8982/8982 [==============================] - 38s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "2246/2246 [==============================] - 2s 967us/step\n",
            "Test score: -124.4584993139931\n",
            "Test accuracy: 0.0396260017809439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "75a99a3b-7783-402a-b600-364192d80fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google_images_download in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (from google_images_download) (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "f5a455f3-4203-4212-aefe-28e710519023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"animal pond\", \"limit\": 20, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = animal pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
            "Completed Image ====> 1.Pondanimals.GIF\n",
            "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
            "Completed Image ====> 2.hqdefault.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
            "Completed Image ====> 3.PKLS4116_inline.png\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
            "Completed Image ====> 4.PKLS4116.png\n",
            "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Completed Image ====> 5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Image URL: https://cdn.pixabay.com/photo/2017/04/19/20/37/frog-2243543_960_720.jpg\n",
            "Completed Image ====> 6.frog-2243543_960_720.jpg\n",
            "Image URL: https://i.pinimg.com/originals/12/ae/e2/12aee2aa186a7b69a66563f138bba822.jpg\n",
            "Completed Image ====> 7.12aee2aa186a7b69a66563f138bba822.jpg\n",
            "Image URL: https://upload.wikimedia.org/wikipedia/commons/5/5d/Alligator_animal_on_pond.jpg\n",
            "Completed Image ====> 8.Alligator_animal_on_pond.jpg\n",
            "Image URL: https://cdn.pixabay.com/photo/2018/04/11/23/05/frog-3312038__340.jpg\n",
            "Completed Image ====> 9.frog-3312038__340.jpg\n",
            "Image URL: https://www.nwf.org/-/media/NEW-WEBSITE/Programs/Garden-for-Wildlife/amphibian_bronze-frog_Julia-Bartosh_400x267.ashx\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.velda.nl/app/uploads/sites/3/2015/11/Gold-fish.jpg\n",
            "Completed Image ====> 10.Gold-fish.jpg\n",
            "Image URL: https://s3-us-west-1.amazonaws.com/contentlab.studiod/getty/37f1d57d30d74892b070208c5399348b\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://www.pixoto.com/images-photography/animals/birds/birds-in-a-pond-5986310798966784.jpg\n",
            "Completed Image ====> 11.birds-in-a-pond-5986310798966784.jpg\n",
            "Image URL: https://cdn.pixabay.com/photo/2017/08/17/06/32/goose-2650209_960_720.jpg\n",
            "Completed Image ====> 12.goose-2650209_960_720.jpg\n",
            "Image URL: https://static.wixstatic.com/media/06af3a_f89e7596d5254e6e8896f054e8c4ea7b~mv2_d_1650_1275_s_2.jpg/v1/fill/w_500,h_500/06af3a_f89e7596d5254e6e8896f054e8c4ea7b~mv2_d_1650_1275_s_2.jpg\n",
            "Completed Image ====> 13.06af3a_f89e7596d5254e6e8896f054e8c4ea7b~mv2_d_1650_1275_s_2.jpg\n",
            "Image URL: https://img-aws.ehowcdn.com/750x428p/photos.demandstudios.com/getty/article/178/192/87827228_XS.jpg\n",
            "Completed Image ====> 14.87827228_XS.jpg\n",
            "Image URL: https://i.pinimg.com/originals/41/6e/0e/416e0eff5efce95e87fae13b90d0b37a.jpg\n",
            "Completed Image ====> 15.416e0eff5efce95e87fae13b90d0b37a.jpg\n",
            "Image URL: https://www.wikihow.com/images/b/b3/Clean-a-Koi-Pond-Step-15.jpg\n",
            "Completed Image ====> 16.Clean-a-Koi-Pond-Step-15.jpg\n",
            "Image URL: http://www.wou.edu/~bledsoek/pond_organisms/pond_organism_list_files/image001.jpg\n",
            "Completed Image ====> 17.image001.jpg\n",
            "Image URL: https://i.pinimg.com/736x/dd/69/c9/dd69c94f00312b5c487bf1018f38be58--vocabulary-cards-picture-cards.jpg\n",
            "Completed Image ====> 18.dd69c94f00312b5c487bf1018f38be58--vocabulary-cards-picture-cards.jpg\n",
            "Image URL: https://www.stamfordmuseum.org/wp-content/uploads/2018/10/smnc-river-otters.jpg\n",
            "Completed Image ====> 19.smnc-river-otters.jpg\n",
            "Image URL: https://pondinformer.com/wp-content/uploads/2018/04/pond-fish-that-eat-algae.jpg\n",
            "Completed Image ====> 20.pond-fish-that-eat-algae.jpg\n",
            "\n",
            "Errors: 2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goal* - also check for fish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "9861416e-eac2-4c5b-9417-fcb26cbce6d7"
      },
      "source": [
        "image_list = absolute_image_paths[0]['animal pond']\n",
        "image_list"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/downloads/animal pond/1.Pondanimals.GIF',\n",
              " '/content/downloads/animal pond/2.hqdefault.jpg',\n",
              " '/content/downloads/animal pond/3.PKLS4116_inline.png',\n",
              " '/content/downloads/animal pond/4.PKLS4116.png',\n",
              " '/content/downloads/animal pond/5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg',\n",
              " '/content/downloads/animal pond/6.frog-2243543_960_720.jpg',\n",
              " '/content/downloads/animal pond/7.12aee2aa186a7b69a66563f138bba822.jpg',\n",
              " '/content/downloads/animal pond/8.Alligator_animal_on_pond.jpg',\n",
              " '/content/downloads/animal pond/9.frog-3312038__340.jpg',\n",
              " '/content/downloads/animal pond/10.Gold-fish.jpg',\n",
              " '/content/downloads/animal pond/11.birds-in-a-pond-5986310798966784.jpg',\n",
              " '/content/downloads/animal pond/12.goose-2650209_960_720.jpg',\n",
              " '/content/downloads/animal pond/13.06af3a_f89e7596d5254e6e8896f054e8c4ea7b~mv2_d_1650_1275_s_2.jpg',\n",
              " '/content/downloads/animal pond/14.87827228_XS.jpg',\n",
              " '/content/downloads/animal pond/15.416e0eff5efce95e87fae13b90d0b37a.jpg',\n",
              " '/content/downloads/animal pond/16.Clean-a-Koi-Pond-Step-15.jpg',\n",
              " '/content/downloads/animal pond/17.image001.jpg',\n",
              " '/content/downloads/animal pond/18.dd69c94f00312b5c487bf1018f38be58--vocabulary-cards-picture-cards.jpg',\n",
              " '/content/downloads/animal pond/19.smnc-river-otters.jpg',\n",
              " '/content/downloads/animal pond/20.pond-fish-that-eat-algae.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo_X3sdiGHE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(filename, new_width=256, new_height=256):#the delf model was trained on images 256x256 the input of our model also should be 256x256\n",
        "  pil_image = Image.open(filename)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert('RGB')\n",
        "  pil_image_rgb.save(filename, format='JPEG', quality=90)\n",
        "\n",
        "for i in image_list:\n",
        "     resize_image(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohiJ1J6kGHT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions#take probabilities\n",
        "\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "  x = image.img_to_array(img)#takes in the image\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)#predict what's in the model\n",
        "  results = decode_predictions(features, top=3)[0]#get the top 3 probabilities and also label associated\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if entry[1] == 'banana':#if the first entry returns banana, do nothing, if not, return second entry\n",
        "      return entry[2]#outputs a list of probabilities\n",
        "  return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8qRNi45GHop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ff91117-0646-4433-846f-3cef746fb7fc"
      },
      "source": [
        "result = img_contains_frog(process_img_path(image_list[0]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n06359193', 'web_site', 0.89605397), ('n04404412', 'television', 0.07584102), ('n03598930', 'jigsaw_puzzle', 0.009310877)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_M1Fi-ZGH4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "8b25c969-664b-4cda-d481-af44d896c425"
      },
      "source": [
        "labels = []\n",
        "for i in image_list:\n",
        "    results = img_contains_frog(process_img_path(i))\n",
        "    labels.append(results)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n06359193', 'web_site', 0.89605397), ('n04404412', 'television', 0.07584102), ('n03598930', 'jigsaw_puzzle', 0.009310877)]\n",
            "[('n01443537', 'goldfish', 0.55898356), ('n02536864', 'coho', 0.32859007), ('n01630670', 'common_newt', 0.02376141)]\n",
            "[('n04243546', 'slot', 0.8985829), ('n04476259', 'tray', 0.025335675), ('n03908618', 'pencil_box', 0.019952878)]\n",
            "[('n03485794', 'handkerchief', 0.71689796), ('n04209239', 'shower_curtain', 0.11719423), ('n02834397', 'bib', 0.023235068)]\n",
            "[('n02444819', 'otter', 0.90565825), ('n02441942', 'weasel', 0.05342591), ('n02442845', 'mink', 0.034301735)]\n",
            "[('n01641577', 'bullfrog', 0.99305624), ('n01644900', 'tailed_frog', 0.006250196), ('n01644373', 'tree_frog', 0.00034542466)]\n",
            "[('n02116738', 'African_hunting_dog', 0.8971374), ('n02117135', 'hyena', 0.034927733), ('n02105162', 'malinois', 0.026862286)]\n",
            "[('n01698640', 'American_alligator', 0.8215397), ('n01737021', 'water_snake', 0.057155196), ('n01689811', 'alligator_lizard', 0.048066698)]\n",
            "[('n01641577', 'bullfrog', 0.97481173), ('n01737021', 'water_snake', 0.011244673), ('n01644900', 'tailed_frog', 0.010225667)]\n",
            "[('n01443537', 'goldfish', 0.99945635), ('n02536864', 'coho', 0.0004327336), ('n01985128', 'crayfish', 2.9877303e-05)]\n",
            "[('n02009912', 'American_egret', 0.7405644), ('n02012849', 'crane', 0.15032986), ('n02009229', 'little_blue_heron', 0.026411064)]\n",
            "[('n01860187', 'black_swan', 0.7273625), ('n01855672', 'goose', 0.12300291), ('n02457408', 'three-toed_sloth', 0.06162966)]\n",
            "[('n06359193', 'web_site', 0.9964599), ('n03291819', 'envelope', 0.0012711672), ('n06596364', 'comic_book', 0.00019414631)]\n",
            "[('n01443537', 'goldfish', 0.9999902), ('n02536864', 'coho', 3.0037447e-06), ('n09256479', 'coral_reef', 1.7858109e-06)]\n",
            "[('n03291819', 'envelope', 0.1650426), ('n04476259', 'tray', 0.10622762), ('n03876231', 'paintbrush', 0.083313994)]\n",
            "[('n04476259', 'tray', 0.41268253), ('n03938244', 'pillow', 0.08933346), ('n02909870', 'bucket', 0.05083196)]\n",
            "[('n01847000', 'drake', 0.999673), ('n01855032', 'red-breasted_merganser', 0.0002866547), ('n02018207', 'American_coot', 1.4786872e-05)]\n",
            "[('n06359193', 'web_site', 0.36451733), ('n01667778', 'terrapin', 0.27395737), ('n04243546', 'slot', 0.12207158)]\n",
            "[('n02363005', 'beaver', 0.5943077), ('n02361337', 'marmot', 0.24198961), ('n02444819', 'otter', 0.15658511)]\n",
            "[('n01440764', 'tench', 0.73850137), ('n02514041', 'barracouta', 0.056688532), ('n02641379', 'gar', 0.056272756)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx4V8ZrTGH3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelmatrix = [[('n06359193', 'web_site', 0.89605397), ('n04404412', 'television', 0.07584102), ('n03598930', 'jigsaw_puzzle', 0.009310877)],\n",
        "[('n01443537', 'goldfish', 0.55898356), ('n02536864', 'coho', 0.32859007), ('n01630670', 'common_newt', 0.02376141)],\n",
        "[('n04243546', 'slot', 0.8985829), ('n04476259', 'tray', 0.025335675), ('n03908618', 'pencil_box', 0.019952878)],\n",
        "[('n03485794', 'handkerchief', 0.71689796), ('n04209239', 'shower_curtain', 0.11719423), ('n02834397', 'bib', 0.023235068)],\n",
        "[('n02444819', 'otter', 0.90565825), ('n02441942', 'weasel', 0.05342591), ('n02442845', 'mink', 0.034301735)],\n",
        "[('n01641577', 'bullfrog', 0.99305624), ('n01644900', 'tailed_frog', 0.006250196), ('n01644373', 'tree_frog', 0.00034542466)],\n",
        "[('n02116738', 'African_hunting_dog', 0.8971374), ('n02117135', 'hyena', 0.034927733), ('n02105162', 'malinois', 0.026862286)],\n",
        "[('n01698640', 'American_alligator', 0.8215397), ('n01737021', 'water_snake', 0.057155196), ('n01689811', 'alligator_lizard', 0.048066698)],\n",
        "[('n01641577', 'bullfrog', 0.97481173), ('n01737021', 'water_snake', 0.011244673), ('n01644900', 'tailed_frog', 0.010225667)],\n",
        "[('n01443537', 'goldfish', 0.99945635), ('n02536864', 'coho', 0.0004327336), ('n01985128', 'crayfish', 2.9877303e-05)],\n",
        "[('n02009912', 'American_egret', 0.7405644), ('n02012849', 'crane', 0.15032986), ('n02009229', 'little_blue_heron', 0.026411064)],\n",
        "[('n01860187', 'black_swan', 0.7273625), ('n01855672', 'goose', 0.12300291), ('n02457408', 'three-toed_sloth', 0.06162966)],\n",
        "[('n06359193', 'web_site', 0.9964599), ('n03291819', 'envelope', 0.0012711672), ('n06596364', 'comic_book', 0.00019414631)],\n",
        "[('n01443537', 'goldfish', 0.9999902), ('n02536864', 'coho', 3.0037447e-06), ('n09256479', 'coral_reef', 1.7858109e-06)],\n",
        "[('n03291819', 'envelope', 0.1650426), ('n04476259', 'tray', 0.10622762), ('n03876231', 'paintbrush', 0.083313994)],\n",
        "[('n04476259', 'tray', 0.41268253), ('n03938244', 'pillow', 0.08933346), ('n02909870', 'bucket', 0.05083196)],\n",
        "[('n01847000', 'drake', 0.999673), ('n01855032', 'red-breasted_merganser', 0.0002866547), ('n02018207', 'American_coot', 1.4786872e-05)],\n",
        "[('n06359193', 'web_site', 0.36451733), ('n01667778', 'terrapin', 0.27395737), ('n04243546', 'slot', 0.12207158)],\n",
        "[('n02363005', 'beaver', 0.5943077), ('n02361337', 'marmot', 0.24198961), ('n02444819', 'otter', 0.15658511)],\n",
        "[('n01440764', 'tench', 0.73850137), ('n02514041', 'barracouta', 0.056688532), ('n02641379', 'gar', 0.056272756)]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHgQZKHGHnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "70d9b064-df96-4ca7-ac3d-3b43e423a4ef"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(labelmatrix)\n",
        "df"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(n06359193, web_site, 0.89605397)</td>\n",
              "      <td>(n04404412, television, 0.07584102)</td>\n",
              "      <td>(n03598930, jigsaw_puzzle, 0.009310877)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(n01443537, goldfish, 0.55898356)</td>\n",
              "      <td>(n02536864, coho, 0.32859007)</td>\n",
              "      <td>(n01630670, common_newt, 0.02376141)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(n04243546, slot, 0.8985829)</td>\n",
              "      <td>(n04476259, tray, 0.025335675)</td>\n",
              "      <td>(n03908618, pencil_box, 0.019952878)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(n03485794, handkerchief, 0.71689796)</td>\n",
              "      <td>(n04209239, shower_curtain, 0.11719423)</td>\n",
              "      <td>(n02834397, bib, 0.023235068)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(n02444819, otter, 0.90565825)</td>\n",
              "      <td>(n02441942, weasel, 0.05342591)</td>\n",
              "      <td>(n02442845, mink, 0.034301735)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(n01641577, bullfrog, 0.99305624)</td>\n",
              "      <td>(n01644900, tailed_frog, 0.006250196)</td>\n",
              "      <td>(n01644373, tree_frog, 0.00034542466)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(n02116738, African_hunting_dog, 0.8971374)</td>\n",
              "      <td>(n02117135, hyena, 0.034927733)</td>\n",
              "      <td>(n02105162, malinois, 0.026862286)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(n01698640, American_alligator, 0.8215397)</td>\n",
              "      <td>(n01737021, water_snake, 0.057155196)</td>\n",
              "      <td>(n01689811, alligator_lizard, 0.048066698)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(n01641577, bullfrog, 0.97481173)</td>\n",
              "      <td>(n01737021, water_snake, 0.011244673)</td>\n",
              "      <td>(n01644900, tailed_frog, 0.010225667)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(n01443537, goldfish, 0.99945635)</td>\n",
              "      <td>(n02536864, coho, 0.0004327336)</td>\n",
              "      <td>(n01985128, crayfish, 2.9877303e-05)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(n02009912, American_egret, 0.7405644)</td>\n",
              "      <td>(n02012849, crane, 0.15032986)</td>\n",
              "      <td>(n02009229, little_blue_heron, 0.026411064)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(n01860187, black_swan, 0.7273625)</td>\n",
              "      <td>(n01855672, goose, 0.12300291)</td>\n",
              "      <td>(n02457408, three-toed_sloth, 0.06162966)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(n06359193, web_site, 0.9964599)</td>\n",
              "      <td>(n03291819, envelope, 0.0012711672)</td>\n",
              "      <td>(n06596364, comic_book, 0.00019414631)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(n01443537, goldfish, 0.9999902)</td>\n",
              "      <td>(n02536864, coho, 3.0037447e-06)</td>\n",
              "      <td>(n09256479, coral_reef, 1.7858109e-06)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(n03291819, envelope, 0.1650426)</td>\n",
              "      <td>(n04476259, tray, 0.10622762)</td>\n",
              "      <td>(n03876231, paintbrush, 0.083313994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(n04476259, tray, 0.41268253)</td>\n",
              "      <td>(n03938244, pillow, 0.08933346)</td>\n",
              "      <td>(n02909870, bucket, 0.05083196)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(n01847000, drake, 0.999673)</td>\n",
              "      <td>(n01855032, red-breasted_merganser, 0.0002866547)</td>\n",
              "      <td>(n02018207, American_coot, 1.4786872e-05)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(n06359193, web_site, 0.36451733)</td>\n",
              "      <td>(n01667778, terrapin, 0.27395737)</td>\n",
              "      <td>(n04243546, slot, 0.12207158)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(n02363005, beaver, 0.5943077)</td>\n",
              "      <td>(n02361337, marmot, 0.24198961)</td>\n",
              "      <td>(n02444819, otter, 0.15658511)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(n01440764, tench, 0.73850137)</td>\n",
              "      <td>(n02514041, barracouta, 0.056688532)</td>\n",
              "      <td>(n02641379, gar, 0.056272756)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              0  ...                                            2\n",
              "0             (n06359193, web_site, 0.89605397)  ...      (n03598930, jigsaw_puzzle, 0.009310877)\n",
              "1             (n01443537, goldfish, 0.55898356)  ...         (n01630670, common_newt, 0.02376141)\n",
              "2                  (n04243546, slot, 0.8985829)  ...         (n03908618, pencil_box, 0.019952878)\n",
              "3         (n03485794, handkerchief, 0.71689796)  ...                (n02834397, bib, 0.023235068)\n",
              "4                (n02444819, otter, 0.90565825)  ...               (n02442845, mink, 0.034301735)\n",
              "5             (n01641577, bullfrog, 0.99305624)  ...        (n01644373, tree_frog, 0.00034542466)\n",
              "6   (n02116738, African_hunting_dog, 0.8971374)  ...           (n02105162, malinois, 0.026862286)\n",
              "7    (n01698640, American_alligator, 0.8215397)  ...   (n01689811, alligator_lizard, 0.048066698)\n",
              "8             (n01641577, bullfrog, 0.97481173)  ...        (n01644900, tailed_frog, 0.010225667)\n",
              "9             (n01443537, goldfish, 0.99945635)  ...         (n01985128, crayfish, 2.9877303e-05)\n",
              "10       (n02009912, American_egret, 0.7405644)  ...  (n02009229, little_blue_heron, 0.026411064)\n",
              "11           (n01860187, black_swan, 0.7273625)  ...    (n02457408, three-toed_sloth, 0.06162966)\n",
              "12             (n06359193, web_site, 0.9964599)  ...       (n06596364, comic_book, 0.00019414631)\n",
              "13             (n01443537, goldfish, 0.9999902)  ...       (n09256479, coral_reef, 1.7858109e-06)\n",
              "14             (n03291819, envelope, 0.1650426)  ...         (n03876231, paintbrush, 0.083313994)\n",
              "15                (n04476259, tray, 0.41268253)  ...              (n02909870, bucket, 0.05083196)\n",
              "16                 (n01847000, drake, 0.999673)  ...    (n02018207, American_coot, 1.4786872e-05)\n",
              "17            (n06359193, web_site, 0.36451733)  ...                (n04243546, slot, 0.12207158)\n",
              "18               (n02363005, beaver, 0.5943077)  ...               (n02444819, otter, 0.15658511)\n",
              "19               (n01440764, tench, 0.73850137)  ...                (n02641379, gar, 0.056272756)\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RalW87zpLbJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdc015cf-7fc5-466b-b21e-7ab0f23d4081"
      },
      "source": [
        "import re\n",
        "\n",
        "original = '(n06359193, web_site, 0.89605397)'\t\n",
        "bad_characters = ['(', '1','2','3','4','5','6','7','8','9','0',')','.',',',' ']\n",
        "\n",
        "\n",
        "def replace(original):\n",
        "  newlabel = ''\n",
        "  for i in original:\n",
        "    if i not in bad_characters:\n",
        "      newlabel += i\n",
        "  newlabel = re.sub('n', '', newlabel, count=1)\n",
        "  return newlabel\n",
        "    \n",
        "replace(original)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'web_site'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV39YJp7GHSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bad_characters = ['(', '1','2','3','4','5','6','7','8','9','0',')','.',',',' ']\n",
        "\n",
        "\n",
        "# def replace(original):\n",
        "#   newlabel = ''\n",
        "#   for i in original:\n",
        "#     if i not in bad_characters:\n",
        "#       newlabel += i\n",
        "#   newlabel = re.sub('n', '', newlabel, count=1)\n",
        "#   return newlabel\n",
        "\n",
        "# df['Primary_Label'] = df.apply(replace)\n",
        "# df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjQfE8HUPQ5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "eb5cc384-e183-4f29-82d3-5e25ada2ecfd"
      },
      "source": [
        "\n",
        "[x[1] for x in df[0].values]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['web_site',\n",
              " 'goldfish',\n",
              " 'slot',\n",
              " 'handkerchief',\n",
              " 'otter',\n",
              " 'bullfrog',\n",
              " 'African_hunting_dog',\n",
              " 'American_alligator',\n",
              " 'bullfrog',\n",
              " 'goldfish',\n",
              " 'American_egret',\n",
              " 'black_swan',\n",
              " 'web_site',\n",
              " 'goldfish',\n",
              " 'envelope',\n",
              " 'tray',\n",
              " 'drake',\n",
              " 'web_site',\n",
              " 'beaver',\n",
              " 'tench']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MftL1P8OjvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e7661fcb-beaa-4eec-a56a-276acc5f7870"
      },
      "source": [
        "# x = df[0].values\n",
        "# np.array2string(x, separator=',')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[('n06359193', 'web_site', 0.89605397),\\n ('n01443537', 'goldfish', 0.55898356),('n04243546', 'slot', 0.8985829),\\n ('n03485794', 'handkerchief', 0.71689796),\\n ('n02444819', 'otter', 0.90565825),('n01641577', 'bullfrog', 0.99305624),\\n ('n02116738', 'African_hunting_dog', 0.8971374),\\n ('n01698640', 'American_alligator', 0.8215397),\\n ('n01641577', 'bullfrog', 0.97481173),\\n ('n01443537', 'goldfish', 0.99945635),\\n ('n02009912', 'American_egret', 0.7405644),\\n ('n01860187', 'black_swan', 0.7273625),\\n ('n06359193', 'web_site', 0.9964599),('n01443537', 'goldfish', 0.9999902),\\n ('n03291819', 'envelope', 0.1650426),('n04476259', 'tray', 0.41268253),\\n ('n01847000', 'drake', 0.999673),('n06359193', 'web_site', 0.36451733),\\n ('n02363005', 'beaver', 0.5943077),('n01440764', 'tench', 0.73850137)]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "Autoencoders are great for content-based recommendations because when a topic is inputed, the autoencoder can learn non-linear, high-dimensional relationships. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "  Creative problem solving especially as it comes to feature engineering\n",
        "  and business strategy due to my creative and entrepreneurial background.\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "  I would immediately be learning about more word frequency in relation to ratings for business via webscraping review websites because there are direct and immediate demands in this field and projects focuses for small business is short term.\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "In 5 years, there will be more sophisticated libraries in 3D computer generated imagery use cases for video conversion into augmented reality experiences. There may be use of AI for harmful political agendas and technological warfar in general. It could be that a recession will exasterbate increases in the United States in job changes.\n",
        "- What are the threats posed by AI to our society?\n",
        "The threats posed by AI in society are the proliferation of fake news, of addition, of misinformation in all senses of human knowledge and fraud\n",
        "- How do you think we can counteract those threats? \n",
        "There may be more subject matter experts in the field of technological regulation to counter threats. The U.S. may take a more socialist turn in providing assistance to those experiencing job loss. \n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "Yes I do believe achieving General Artificial Intelligence is possible especially when there are fields studying how the human brain can be interfaced with computational systems.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6ZZXXznB640",
        "colab_type": "code",
        "colab": {},
        "outputId": "f3e7ca08-3bf6-4ebc-dbc2-e8724cd3852e"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}