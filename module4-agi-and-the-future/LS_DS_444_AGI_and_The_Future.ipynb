{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "# Lambda School Data Science - Artificial General Intelligence and The Future\n",
    "\n",
    "![Future City](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/City-of-the-future.jpg/640px-City-of-the-future.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moj-4gr89pum"
   },
   "source": [
    "# Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EZdBzC6pvV9"
   },
   "source": [
    "## Defining Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9Y6I1aO9uCz"
   },
   "source": [
    "A straightforward definition of Artificial Intelligence would simply be \"intelligence, created from technology rather than biology.\" But that simply raises the question - what is *intelligence*?\n",
    "\n",
    "In the early history of computers, this seemed like an easier question. Intelligence meant solving tricky problems - things that took time and mental effort for a human to figure out.\n",
    "\n",
    "Defined that way, computers have made a litany of intelligent achievements over the years:\n",
    "- Arithmetic\n",
    "- Logic\n",
    "- Chess\n",
    "- Go\n",
    "- StarCraft\n",
    "- Mathematical proofs\n",
    "- Understanding natural language\n",
    "- Generating natural language\n",
    "- Understanding images\n",
    "- Generating images\n",
    "- Making medical diagnoses\n",
    "- Fitting and *optimizing* ML models\n",
    "\n",
    "And many more - every time you fit a simple regression, you're facilitating an act of artificial intelligence. You're writing code that will (hopefully) understand and generalize based on data, giving a \"human-like\" ability to intuit and predict something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXdC1uCC91ID"
   },
   "source": [
    "## \"General\" Intelligence - a moving target\n",
    "\n",
    "But, somehow, that isn't what most people *really* mean when they talk about AI.\n",
    "\n",
    "![And they both react poorly to showers.](https://imgs.xkcd.com/comics/ai.png)\n",
    "\n",
    "Somewhere that word \"general\" snuck in, and now we're concerned about \"Artificial General Intelligence.\" So, what is that?\n",
    "\n",
    "![Data](https://upload.wikimedia.org/wikipedia/en/0/09/DataTNG.jpg)\n",
    "\n",
    "The inspiration is likely characters such as the above, but that's not a definition. Intuitively the claim is \"computers that can be thrown in a variety of environments and learn without guidance\", but another good definition (based on how people use the term) may simply be \"whatever we haven't figured out how to get computers to do yet.\"\n",
    "\n",
    "Repeatedly, claims are made about tasks that will require a \"true AI\" to achieve. Then, when those tasks are completed, the bar is moved, and \"true AI\" is somehow always a bit further off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJV_2Ozk5LLV"
   },
   "source": [
    "## AI - Hype versus Value\n",
    "\n",
    "Hot off the presses! [Google launches an end-to-end AI platform](https://techcrunch.com/2019/04/10/google-expands-its-ai-services/)!\n",
    "\n",
    "...\n",
    "\n",
    "What does that mean? Well, it might mean a lot, but it's a little unclear what. Some selected [Hacker News](https://news.ycombinator.com/item?id=19626275) comments:\n",
    "\n",
    "> This platform focuses not on the this-AI-is-magic-and-can-solve-everything like many AI SaaS startups announced on Hacker News, but focuses on how to actually integrate this AI into production workflows, which is something I wish was discussed more often in AI. -- minimaxir\n",
    "\n",
    "> Looks like Google is taking over Cloud (from AWS) for AI by building an ecosystem and building tools for non Data scientists - consumer level product. Surely IBM can do similar thing with their recent Redhat acquisition, but will they ? -- amrrs\n",
    "\n",
    "> I work in building and deploying production ML/AI models but I'm having a lot of trouble cutting through the marketing jargon in this article and on Google's website as well. Can someone explain what this does in engineering terms? How does this differ from something like AWS Sagemaker? -- chibg10\n",
    "\n",
    "> This will make a bunch of startup's life really hard. I think it makes it harder to justify investing in your own ML pipeline or even building your own models for many use cases.\n",
    "\n",
    "One thing it definitely means - AI is a hot keyword, and people making hiring and other corporate decisions will be on the look out for it, even if they're not sure what it is.\n",
    "\n",
    "So - yes, you *do* know AI. AI is a real thing, and you are capable of using \"artificial\" technology to bring about real *intelligence* and insight.\n",
    "\n",
    "Do you know how to make an intelligent anthropomorphic android? No - and nobody else does yet, either. And that's OK. There's still lots of cool advances and things to learn and build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpSkJFuIkJeU"
   },
   "source": [
    "## Automation, for good and ill\n",
    "\n",
    "It is worth spending a moment considering the double-edged sword that is automation. This story did not begin with artificial intelligence, or even statistics or mathematics - it began when the first tool inventor figured out how to make something clever like a lever or a wheel, and use it to reduce the amount of labor needed to achieve some task.\n",
    "\n",
    "In the modern day we talk about automation, but in practice most technology is best considered as a *productivity multiplier* - all businesses still need at least *some* humans around, if nothing else to make policy decisions and collect profit. But the productivity of each individual person can be greatly enhanced through the use of technology.\n",
    "\n",
    "Consider farming - formerly a signification source of employment (and also small family owned farms), technology has tranformed it into a large scale industry where a handful of people produce as much as many more did before. This progression has happened in many areas - fortunately, it is usually accompanied by job growth and opportunity as new markets and services are created by technology as well.\n",
    "\n",
    "So, is it different now? Maybe - \"history will say\" is the only safe stance. But we are automating work at an accelerating rate, and it's unclear where all this growth is going and where the opportunities will be. There's a pretty good bet that it'll involve computers and data - and that's probably a large part of why you're here!\n",
    "\n",
    "The purpose of this section is not to convince you of anything - it is just to make you think. As a Data Scientist, you will have an outsized impact on society, and it is your responsibility to consider that impact and what you want to do with it.\n",
    "\n",
    "**Important caveat** - think and engage with society, *but* strive to not be strident or unduly certain when you do so. Broadcasting political beliefs, especially while on the job market, usually closes more doors than it opens. So, consider perspectives, and encourage dialogue - don't just (re)broadcast outrage at the latest injustice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vXHDbNnzGZz"
   },
   "source": [
    "## AutoML - taking our own jobs\n",
    "\n",
    "Us Data Scientists are not immune to automation. Behold, yet another voyage with the RMS Titanic ðŸš¢:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YN4O5Ikxy2g8"
   },
   "source": [
    "![AutoML applied to Titanic data](https://github.com/minimaxir/automl-gs/raw/master/docs/console-demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iy6RIQn9zKhp"
   },
   "source": [
    "### Using AutoML on some data you've probably seen before\n",
    "\n",
    "Let's start with [automl-gs](https://github.com/minimaxir/automl-gs), a very new library that just works directly from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "id": "GkJUFfsgnqr_",
    "outputId": "cf810bae-5195-4e9b-e157-1ef9a10f1b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting automl_gs\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/51/27833a08fe4f83711b09836ddd9128e275a6900c47e0e5782112ed611484/automl_gs-0.2.1.tar.gz\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from automl_gs) (0.22.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from automl_gs) (0.20.3)\n",
      "Collecting autopep8 (from automl_gs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/ba/37d30e4263c51ee5a655118ac8c331e96a4e45fd4cea876a74b87af9ffc1/autopep8-1.4.3.tar.gz (113kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 10.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from automl_gs) (4.28.1)\n",
      "Requirement already satisfied: jinja2>=2.8 in /usr/local/lib/python3.6/dist-packages (from automl_gs) (2.10)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from automl_gs) (3.13)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->automl_gs) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas->automl_gs) (1.14.6)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->automl_gs) (2.5.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->automl_gs) (1.1.0)\n",
      "Collecting pycodestyle>=2.4.0 (from autopep8->automl_gs)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 16.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.8->automl_gs) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas->automl_gs) (1.11.0)\n",
      "Building wheels for collected packages: automl-gs, autopep8\n",
      "  Building wheel for automl-gs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2d/5e/f0/deffbd0fcc4afd6b065366dded7b9c8cd1b7c02f6b39c24552\n",
      "  Building wheel for autopep8 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/91/07/fd/99884826d575c769102ddec2f9b96c7ad57cc6b5ca3a5e02b4\n",
      "Successfully built automl-gs autopep8\n",
      "Installing collected packages: pycodestyle, autopep8, automl-gs\n",
      "Successfully installed automl-gs-0.2.1 autopep8-1.4.3 pycodestyle-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install automl_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "QsGIh584kH3A",
    "outputId": "247ecbf6-6958-43dd-81d4-00c985be5e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-11 04:03:24--  https://github.com/ryanleeallred/datasets/raw/master/car_regression.csv\n",
      "Resolving github.com (github.com)... 192.30.255.113, 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/ryanleeallred/datasets/master/car_regression.csv [following]\n",
      "--2019-04-11 04:03:25--  https://raw.githubusercontent.com/ryanleeallred/datasets/master/car_regression.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 263167 (257K) [text/plain]\n",
      "Saving to: â€˜car_regression.csvâ€™\n",
      "\n",
      "\r",
      "car_regression.csv    0%[                    ]       0  --.-KB/s               \r",
      "car_regression.csv  100%[===================>] 257.00K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2019-04-11 04:03:25 (8.69 MB/s) - â€˜car_regression.csvâ€™ saved [263167/263167]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ryanleeallred/datasets/raw/master/car_regression.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mR0ba-7ikJCd",
    "outputId": "ff858080-368f-4a42-cfe6-ffbd31385880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make,price,body,mileage,engV,engType,registration,year,drive\n",
      "23,15500.0,0,68,2.5,1,1,2010,1\n",
      "50,20500.0,3,173,1.8,1,1,2011,2\n",
      "50,35000.0,2,135,5.5,3,1,2008,2\n",
      "50,17800.0,5,162,1.8,0,1,2012,0\n",
      "55,16600.0,0,83,2.0,3,1,2013,1\n",
      "30,6500.0,3,199,2.0,3,1,2003,0\n",
      "59,10500.0,4,185,1.5,0,1,2011,0\n",
      "50,21500.0,3,146,1.8,1,1,2012,2\n",
      "50,22700.0,3,125,2.2,0,1,2010,2\n"
     ]
    }
   ],
   "source": [
    "!head car_regression.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "colab_type": "code",
    "id": "JwEChFqKkLdW",
    "outputId": "4c7af1af-20ca-4c46-afff-1154da461671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a regression problem, minimizing mse using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "make: numeric\n",
      "body: categorical\n",
      "mileage: numeric\n",
      "engV: numeric\n",
      "engType: categorical\n",
      "registration: categorical\n",
      "year: numeric\n",
      "drive: categorical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c28d6e8d1004b5a918339bf6a53583a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b8db4161d142fab1febc408a5058d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r\n",
      "Metrics:\n",
      "trial_id: e6b5f502-7bea-4a98-b930-5b879d216814\n",
      "epoch: 20\n",
      "time_completed: 2019-04-11 04:03:59\n",
      "mse: 866335309.030034\n",
      "mae: 16044.953051733859\n",
      "r_2: -0.4194348823774972\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bf47de8a1866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoml_gs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautoml_grid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mautoml_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'car_regression.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/automl_gs/automl_gs.py\u001b[0m in \u001b[0;36mautoml_grid_search\u001b[0;34m(csv_path, target_field, target_metric, framework, model_name, context, num_trials, split, num_epochs, col_types, gpu, tpu_address)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     header=(best_result is None))\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# If the target metric improves, save the new hps/files,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from automl_gs import automl_grid_search\n",
    "\n",
    "automl_grid_search('car_regression.csv', 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSTNAnT9dS6J"
   },
   "source": [
    "Uh oh, what happened? There is an [open issue](https://github.com/minimaxir/automl-gs/issues/14) which suggests running via the command line `automl_gs` tool rather than the Python module to get better error messages for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1146
    },
    "colab_type": "code",
    "id": "svF0TnE0keaj",
    "outputId": "33dbd241-31a1-4b09-f5c7-adf7bbc7b6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a regression problem, minimizing mse using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "make: numeric\n",
      "body: categorical\n",
      "mileage: numeric\n",
      "engV: numeric\n",
      "engType: categorical\n",
      "registration: categorical\n",
      "year: numeric\n",
      "drive: categorical\n",
      "  0% 0/100 [00:00<?, ?trial/s]\n",
      "  0% 0/20 [00:00<?, ?epoch/s]\u001b[A\n",
      "  5% 1/20 [00:06<02:05,  6.60s/epoch]\u001b[A\n",
      " 10% 2/20 [00:07<01:05,  3.65s/epoch]\u001b[A\n",
      " 15% 3/20 [00:07<00:45,  2.67s/epoch]\u001b[A\n",
      " 20% 4/20 [00:08<00:34,  2.17s/epoch]\u001b[A\n",
      " 25% 5/20 [00:09<00:28,  1.87s/epoch]\u001b[A\n",
      " 30% 6/20 [00:10<00:23,  1.67s/epoch]\u001b[A\n",
      " 35% 7/20 [00:10<00:19,  1.53s/epoch]\u001b[A\n",
      " 40% 8/20 [00:11<00:17,  1.42s/epoch]\u001b[A\n",
      " 45% 9/20 [00:12<00:14,  1.34s/epoch]\u001b[A\n",
      " 50% 10/20 [00:12<00:12,  1.28s/epoch]\u001b[A\n",
      " 55% 11/20 [00:13<00:10,  1.22s/epoch]\u001b[A\n",
      " 60% 12/20 [00:14<00:09,  1.18s/epoch]\u001b[A\n",
      " 65% 13/20 [00:14<00:07,  1.14s/epoch]\u001b[A\n",
      " 70% 14/20 [00:15<00:06,  1.11s/epoch]\u001b[A\n",
      " 75% 15/20 [00:16<00:05,  1.08s/epoch]\u001b[A\n",
      " 80% 16/20 [00:16<00:04,  1.05s/epoch]\u001b[A\n",
      " 85% 17/20 [00:17<00:03,  1.03s/epoch]\u001b[A\n",
      " 90% 18/20 [00:18<00:02,  1.01s/epoch]\u001b[A\n",
      " 95% 19/20 [00:18<00:00,  1.01epoch/s]\u001b[A\n",
      "100% 20/20 [00:19<00:00,  1.02epoch/s]\u001b[A\n",
      "                              \n",
      "\u001b[A\n",
      "Metrics:\n",
      "trial_id: 8b7e7e91-8925-4b32-acfd-a780522f41d4\n",
      "epoch: 20\n",
      "time_completed: 2019-04-11 04:05:21\n",
      "mse: 870882869.0303116\n",
      "mae: 16141.396612378321\n",
      "r_2: -0.4268857679951292\n",
      "  0% 0/100 [00:20<?, ?trial/s]\n",
      "  1% 1/100 [00:20<33:42, 20.43s/trial]Traceback (most recent call last):\n",
      "  File \"model.py\", line 48, in <module>\n",
      "    model_train(df, encoders, args, model)\n",
      "  File \"/content/automl_train/pipeline.py\", line 433, in model_train\n",
      "    batch_size=128)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 776, in fit\n",
      "    shuffle=shuffle)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 2382, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 362, in standardize_input_data\n",
      "    ' but got array with shape ' + str(data_shape))\n",
      "ValueError: Error when checking input: expected input_engtype to have shape (1,) but got array with shape (2,)\n",
      "\n",
      "  0% 0/20 [00:00<?, ?epoch/s]\u001b[ATraceback (most recent call last):\n",
      "  File \"/usr/local/bin/automl_gs\", line 10, in <module>\n",
      "    sys.exit(cmd())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/automl_gs/automl_gs.py\", line 175, in cmd\n",
      "    tpu_address=args.tpu_address)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/automl_gs/automl_gs.py\", line 94, in automl_grid_search\n",
      "    train_results = results.tail(1).to_dict('records')[0]\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!automl_gs car_regression.csv price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRqYSY4yde1L"
   },
   "source": [
    "So, the real issue is in some intermediary step - let's see if we can get rid of engType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1505
    },
    "colab_type": "code",
    "id": "N0sHkyabk9Pj",
    "outputId": "26a91983-c1b8-4003-cfd4-6978516828fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a regression problem, minimizing mse using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "make: numeric\n",
      "body: categorical\n",
      "mileage: numeric\n",
      "engV: numeric\n",
      "engType: ignore\n",
      "registration: categorical\n",
      "year: numeric\n",
      "drive: categorical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8544f1464a4a3a9bb3db070c4d758d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5528c6c1ed104507be3a0278bc9ce430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r\n",
      "Metrics:\n",
      "trial_id: 1c5a2168-326b-4d9d-8a40-1a2b5dffe433\n",
      "epoch: 20\n",
      "time_completed: 2019-04-11 04:08:00\n",
      "mse: 870868554.7675673\n",
      "mae: 16140.953204050678\n",
      "r_2: -0.4268623149929911\n",
      "\n",
      "\n",
      "Metrics:\n",
      "trial_id: dcc41b38-c734-4e34-8679-0d3e1082c1e0\n",
      "epoch: 20\n",
      "time_completed: 2019-04-11 04:09:30\n",
      "mse: 865371717.0329753\n",
      "mae: 15982.412941232213\n",
      "r_2: -0.4178560986447455\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1a57aaf11428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m automl_grid_search('car_regression.csv', 'price', col_types={\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'engType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/automl_gs/automl_gs.py\u001b[0m in \u001b[0;36mautoml_grid_search\u001b[0;34m(csv_path, target_field, target_metric, framework, model_name, context, num_trials, split, num_epochs, col_types, gpu, tpu_address)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# and append to the metrics CSV.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         results = pd.read_csv(os.path.join(train_folder, \n\u001b[0;32m---> 87\u001b[0;31m                                         \"metadata\", \"results.csv\"))\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trial_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'automl_train/metadata/results.csv' does not exist"
     ]
    }
   ],
   "source": [
    "automl_grid_search('car_regression.csv', 'price', col_types={\n",
    "    'engType': 'ignore'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9y2xI5ShN4n"
   },
   "source": [
    "It gets further, but is perhaps a bit too bleeding edge for us. Let's try [TPOT](https://github.com/EpistasisLab/tpot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T01:19:27.171400Z",
     "start_time": "2019-04-12T01:19:17.191418Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "xltSPWmMhQod",
    "outputId": "78745223-eb42-41bb-8275-da36697e656a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/35/a6cc358b6bb2749d6dffa1ae2427143211f3092904bbb15d1ad317ebe051/TPOT-0.9.6.tar.gz (892kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 3.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from tpot) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from tpot) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.1 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from tpot) (0.20.2)\n",
      "Collecting deap>=1.0 (from tpot)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/29/e7f2ecbe02997b16a768baed076f5fc4781d7057cd5d9adf7c94027845ba/deap-1.2.2.tar.gz (936kB)\n",
      "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 942kB 3.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting update_checker>=0.16 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from tpot) (4.29.1)\n",
      "Collecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
      "Requirement already satisfied: pandas>=0.20.2 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from tpot) (0.24.2)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from update_checker>=0.16->tpot) (2.21.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from pandas>=0.20.2->tpot) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from pandas>=0.20.2->tpot) (2.7.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from requests>=2.3.0->update_checker>=0.16->tpot) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->tpot) (1.12.0)\n",
      "Building wheels for collected packages: tpot, deap, stopit\n",
      "  Building wheel for tpot (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/mark/.cache/pip/wheels/86/5c/dd/c7673fbaccb901ec1a4eb79017fa5b65766805d2a98f954b9a\n",
      "  Building wheel for deap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/mark/.cache/pip/wheels/22/ea/bf/dc7c8a2262025a0ab5da9ef02282c198be88902791ca0c6658\n",
      "  Building wheel for stopit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/mark/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
      "Successfully built tpot deap stopit\n",
      "Installing collected packages: deap, update-checker, stopit, tpot\n",
      "Successfully installed deap-1.2.2 stopit-1.1.2 tpot-0.9.6 update-checker-0.16\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "GhI7BzgmhWMy",
    "outputId": "ee393443-4fa2-472a-91c9-1cc9adb296fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>20500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>17800.0</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   make    price  body  mileage  engV  engType  registration  year  drive\n",
       "0    23  15500.0     0       68   2.5        1             1  2010      1\n",
       "1    50  20500.0     3      173   1.8        1             1  2011      2\n",
       "2    50  35000.0     2      135   5.5        3             1  2008      2\n",
       "3    50  17800.0     5      162   1.8        0             1  2012      0\n",
       "4    55  16600.0     0       83   2.0        3             1  2013      1"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "df = pd.read_csv('car_regression.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "XED4cuyimEsP",
    "outputId": "194fc9de-ba89-4006-fc78-0f1953187ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>price</th>\n",
       "      <th>body</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engV</th>\n",
       "      <th>engType</th>\n",
       "      <th>registration</th>\n",
       "      <th>year</th>\n",
       "      <th>drive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "      <td>8495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.535491</td>\n",
       "      <td>16185.453305</td>\n",
       "      <td>2.302295</td>\n",
       "      <td>141.744202</td>\n",
       "      <td>2.568337</td>\n",
       "      <td>1.650618</td>\n",
       "      <td>0.941613</td>\n",
       "      <td>2006.500883</td>\n",
       "      <td>0.575868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.526251</td>\n",
       "      <td>24449.641512</td>\n",
       "      <td>1.610307</td>\n",
       "      <td>97.464062</td>\n",
       "      <td>5.387238</td>\n",
       "      <td>1.341282</td>\n",
       "      <td>0.234488</td>\n",
       "      <td>6.925907</td>\n",
       "      <td>0.741235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>259.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1959.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>5490.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>17145.600000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>547800.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              make          price         body      mileage         engV  \\\n",
       "count  8495.000000    8495.000000  8495.000000  8495.000000  8495.000000   \n",
       "mean     46.535491   16185.453305     2.302295   141.744202     2.568337   \n",
       "std      24.526251   24449.641512     1.610307    97.464062     5.387238   \n",
       "min       0.000000     259.350000     0.000000     0.000000     0.100000   \n",
       "25%      23.000000    5490.000000     1.000000    74.000000     1.600000   \n",
       "50%      50.000000    9500.000000     3.000000   130.000000     2.000000   \n",
       "75%      68.000000   17145.600000     3.000000   197.000000     2.500000   \n",
       "max      82.000000  547800.000000     5.000000   999.000000    99.990000   \n",
       "\n",
       "           engType  registration         year        drive  \n",
       "count  8495.000000   8495.000000  8495.000000  8495.000000  \n",
       "mean      1.650618      0.941613  2006.500883     0.575868  \n",
       "std       1.341282      0.234488     6.925907     0.741235  \n",
       "min       0.000000      0.000000  1959.000000     0.000000  \n",
       "25%       0.000000      1.000000  2004.000000     0.000000  \n",
       "50%       1.000000      1.000000  2008.000000     0.000000  \n",
       "75%       3.000000      1.000000  2011.000000     1.000000  \n",
       "max       3.000000      1.000000  2016.000000     2.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRdeEEbomGQ6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('price', axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, df['price'].values, train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "p5dAYY5VmuEc",
    "outputId": "41208981-b211-489e-ef52-310cfbb66af5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8127ac6c0945a695755da9b9939d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -92636917.8904812\n",
      "Generation 2 - Current best internal CV score: -92636917.8904812\n",
      "Generation 3 - Current best internal CV score: -87405518.88093515\n",
      "Generation 4 - Current best internal CV score: -82448619.60956766\n",
      "Generation 5 - Current best internal CV score: -82448619.60956766\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(RobustScaler(input_matrix), alpha=0.9, learning_rate=0.1, loss=ls, max_depth=7, max_features=0.45, min_samples_leaf=2, min_samples_split=17, n_estimators=100, subsample=0.7000000000000001)\n",
      "-95212641.6186412\n",
      "CPU times: user 12min 15s, sys: 18.5 s, total: 12min 34s\n",
      "Wall time: 12min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ma_BH3rpqLFA",
    "outputId": "63602cc4-48a2-461a-d922-4ca2ac354f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6941.76312027,  6490.98506205,  5716.99816711, ...,\n",
       "        9482.15768688,  8170.80266469, 22037.23983594])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nTSYqr_dqdNb",
    "outputId": "e04e2b8d-f6f2-4c1d-a452-63b36fb7a578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7000.,  6100.,  6500., ..., 13200.,  7800., 22700.])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVijM-bCd6Xh"
   },
   "source": [
    "It works - but it looks like we're not quite out of a job yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYXU2HBrswcX"
   },
   "source": [
    "## So, is AutoML an \"AGI\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ws30-q7PtEWE"
   },
   "source": [
    "**No** - it's a grid search in parameter space, with some clever type inference heuristics and a slick interface.\n",
    "\n",
    "But, it *is* artificial, it *does* give intelligent results, and (like most technology) it *multiplies* productivity. It's not going to \"take our jobs\" - but it does mean that, in some situations, one data scientist will be able to do what formerly took several to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "glOqJQkA0bxG"
   },
   "source": [
    "## Is Artificial General Intelligence dangerous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZrQq9D3ik6h"
   },
   "source": [
    "![I'm working to bring about a superintelligent AI that will eternally torment everyone who failed to make fun of the Roko's Basilisk people.](https://imgs.xkcd.com/comics/ai_box_experiment.png)\n",
    "\n",
    "There's been much philosophizing, thought experimenting, and even some genuine advocacy and policy considerations about the impact of a \"true\" AGI on human society. Most of these analyses essentially consider the AGI as an unfathomable deity, thinking and moving in ways well beyond human comprehension.\n",
    "\n",
    "Consider the [paperclip maximizer](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer):\n",
    "\n",
    "> Suppose we have an AI whose only goal is to make as many paper clips as possible. The AI will realize quickly that it would be much better if there were no humans because humans might decide to switch it off. Because if humans do so, there would be fewer paper clips. Also, human bodies contain a lot of atoms that could be made into paper clips. The future that the AI would be trying to gear towards would be one in which there were a lot of paper clips but no humans. â€”â€‰Nick Bostrom\n",
    "\n",
    "This is an example of *instrumental convergence* - the idea that, if an AGI were to pursue an unbounded goal (a natural instruction like \"Maximize the health of all humans\") it may push it in extremely unexpected ways (put all humans in vats of goo, to both preserve them and prevent them from disabling it, since its existence is also of value to help humans).\n",
    "\n",
    "Is this a *realistic* concern? Well, maybe eventually - but pretty obviously not an immediate one. There are many more prominent challenges involving tech and society - privacy, economic growth, equality, education - and even *if* AGI existed it's not clear how they would have the means to enact such fantastic plans. Killer robot armies make for good TV, but at some step there's likely a human with an off switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ayWGQhHu1yRu"
   },
   "source": [
    "## Where is AI going, and where does it leave us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrBqwYoziUSm"
   },
   "source": [
    "![Lambda calculus? More like SHAMda calculus, amirite?](https://imgs.xkcd.com/comics/ai_research.png)\n",
    "\n",
    "On the one hand, we live in a remarkable time. The explosion of technology from WWII to present has brought about countless innovations, greatly increased median life expectancy and GDP, and shows no sign of slowing down.\n",
    "\n",
    "On the other hand, the more things change the more they stay the same. Humans are still Homo sapiens, with the same brains we've had for many millenia. [Dunbar's number](https://en.wikipedia.org/wiki/Dunbar's_number) stymies our attempts to be globally considerate and aware, and at the end of the day it seems like the vast majority of our behavior is as it ever has been - just with shinier toys.\n",
    "\n",
    "So, what will happen? Will technology usher in a utopia, where automation finally relieves us all of burdensome tasks and we are free to explore science, art, and leisure? Or are we doomed to a dystopia, where increased production is also increasingly centralized and the vast majority of humanity becomes a permanent underclass in a postmodern cyberpunk world?\n",
    "\n",
    "Probably neither - both are extreme points along a continuum of possibility. But wherever we do end up, it is all but certain that AI (that is, technology generating insights and signal) will be a key part of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpbzOQKU7Yv2"
   },
   "source": [
    "## And what about A*G*I?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB8YZxHc7gGm"
   },
   "source": [
    "> \"I think, therefore I am.\" -- RenÃ© Descartes\n",
    "\n",
    "> \"I am a strange loop.\" -- Douglas Hofstadter\n",
    "\n",
    "Artificial General Intelligence is, as discussed, a moving target. Perhaps what we're looking for isn't intelligence, but consciousness - and specifically, consciousness *we* recognize and empathize with. Much like all parents, us humans want to foster something new in our image, and see it succeed in a way we appreciate.\n",
    "\n",
    "It's not clear if technology will ever *really* get there. The structure and approach to artificial intelligence is inherently, well, artificial - some things like neural networks are \"inspired\" by biology, but still very different (far fewer connections, but far faster with more data). Perhaps computers really already *are* intelligent, just not in a way we recognize.\n",
    "\n",
    "And if we ever do succeed at making our virtual progeny, we may find it bittersweet - not because they will inevitably destroy us (though they probably will outlast us), but simply because it will then lead us to wonder what is so special about us in the first place. If we can create an AGI from metal and sand, then are we not just mechanisms of a different sort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lfZdD_cp1t5"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Use either [automl-gs](https://github.com/minimaxir/automl-gs) or [TPOT](https://github.com/EpistasisLab/tpot) to solve at least two of your prior assignments, projects, or other past work (any time you fit a classification or regression model). Report the results, and compare/contrast with the results you found when you worked on it using your \"human\" ML approach.\n",
    "\n",
    "Note - these tools promise a lot, but the reality is that you may have to debug a bit and figure out getting your data in a format that it recognizes. Welcome to the cutting edge - at least there's still plenty of work to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:54:44.015932Z",
     "start_time": "2019-04-12T03:54:44.000498Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from datetime import datetime\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import statsmodels.api as s\n",
    "import time\n",
    "from functools import reduce\n",
    "import regex\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import pandas as pd\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T00:28:42.707968Z",
     "start_time": "2019-04-12T00:22:49.779574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-11 20:22:49--  https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
      "Resolving os.unil.cloud.switch.ch... 2001:620:5ca1:2ff::ce53, 86.119.28.13\n",
      "Connecting to os.unil.cloud.switch.ch|2001:620:5ca1:2ff::ce53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358412441 (342M) [application/zip]\n",
      "Saving to: â€˜fma_metadata.zipâ€™\n",
      "\n",
      "fma_metadata.zip    100%[===================>] 341.81M  1.61MB/s    in 4m 53s  \n",
      "\n",
      "2019-04-11 20:27:44 (1.17 MB/s) - â€˜fma_metadata.zipâ€™ saved [358412441/358412441]\n",
      "\n",
      "Archive:  fma_metadata.zip\n",
      " bunzipping: fma_metadata/README.txt  \n",
      " bunzipping: fma_metadata/checksums  \n",
      " bunzipping: fma_metadata/not_found.pickle  \n",
      " bunzipping: fma_metadata/raw_genres.csv  \n",
      " bunzipping: fma_metadata/raw_albums.csv  \n",
      " bunzipping: fma_metadata/raw_artists.csv  \n",
      " bunzipping: fma_metadata/raw_tracks.csv  \n",
      " bunzipping: fma_metadata/tracks.csv  \n",
      " bunzipping: fma_metadata/genres.csv  \n",
      " bunzipping: fma_metadata/raw_echonest.csv  \n",
      " bunzipping: fma_metadata/echonest.csv  \n",
      " bunzipping: fma_metadata/features.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
    "!unzip fma_metadata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T00:43:28.663876Z",
     "start_time": "2019-04-12T00:43:26.612618Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/myf/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments.1</th>\n",
       "      <th>date_created.1</th>\n",
       "      <th>favorites.1</th>\n",
       "      <th>id.1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>name</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags.1</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments.2</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created.2</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites.2</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information.1</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens.1</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags.2</th>\n",
       "      <th>title.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106570</th>\n",
       "      <td>155316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:20:35</td>\n",
       "      <td>2017-02-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22940.0</td>\n",
       "      <td>&lt;p&gt;A live performance at Monty Hall on Feb 17,...</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>Monty Hall</td>\n",
       "      <td>[]</td>\n",
       "      <td>Live at Monty Hall, 2/17/2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Live Performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:18:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GILLIAN/JENNA/DECLAN/JAIME</td>\n",
       "      <td>Spowder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['spowder']</td>\n",
       "      <td>https://spowder.bandcamp.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-30 15:23:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[25, 12]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-NoD...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Auger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106571</th>\n",
       "      <td>155317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:20:35</td>\n",
       "      <td>2017-02-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22940.0</td>\n",
       "      <td>&lt;p&gt;A live performance at Monty Hall on Feb 17,...</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>Monty Hall</td>\n",
       "      <td>[]</td>\n",
       "      <td>Live at Monty Hall, 2/17/2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Live Performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:18:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GILLIAN/JENNA/DECLAN/JAIME</td>\n",
       "      <td>Spowder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['spowder']</td>\n",
       "      <td>https://spowder.bandcamp.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-30 15:23:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[25, 12]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-NoD...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Let's Skin Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106572</th>\n",
       "      <td>155318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:20:35</td>\n",
       "      <td>2017-02-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22940.0</td>\n",
       "      <td>&lt;p&gt;A live performance at Monty Hall on Feb 17,...</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>Monty Hall</td>\n",
       "      <td>[]</td>\n",
       "      <td>Live at Monty Hall, 2/17/2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Live Performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:18:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GILLIAN/JENNA/DECLAN/JAIME</td>\n",
       "      <td>Spowder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['spowder']</td>\n",
       "      <td>https://spowder.bandcamp.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-30 15:23:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[25, 12]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-NoD...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>My House Smells Like Kim Deal/Pulp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106573</th>\n",
       "      <td>155319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:20:35</td>\n",
       "      <td>2017-02-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22940.0</td>\n",
       "      <td>&lt;p&gt;A live performance at Monty Hall on Feb 17,...</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>Monty Hall</td>\n",
       "      <td>[]</td>\n",
       "      <td>Live at Monty Hall, 2/17/2017</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Live Performance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-30 15:18:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GILLIAN/JENNA/DECLAN/JAIME</td>\n",
       "      <td>Spowder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['spowder']</td>\n",
       "      <td>https://spowder.bandcamp.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-30 15:23:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[25, 12]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-NoD...</td>\n",
       "      <td>294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Man With Two Mouths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106574</th>\n",
       "      <td>155320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-03-26 16:22:18</td>\n",
       "      <td>2017-03-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22906.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7481.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ballad', 'epic', 'rockabilly', 'curse', 'hex...</td>\n",
       "      <td>What I Tell Myself Vol. 2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;****NOTE FOR USING OUR MUSIC ON YOUTUBE****...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-04 17:26:24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21615.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jersey City, NJ 07302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alishia Taiping (lead vocals, bass) \\nDan Pier...</td>\n",
       "      <td>Forget the Whale</td>\n",
       "      <td>** PLEASE CONNECT WITH US THROUGH FACEBOOK! WE...</td>\n",
       "      <td>['forget the whale', 'witches', 'rockabilly', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>validation</td>\n",
       "      <td>large</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-30 09:15:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[10, 12, 169]</td>\n",
       "      <td>[169, 10, 12, 9]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attribution-NonCommercial</td>\n",
       "      <td>705.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ballad', 'epic', 'rockabilly', 'curse', 'hex...</td>\n",
       "      <td>Another Trick Up My Sleeve (Instrumental)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  comments         date_created        date_released  \\\n",
       "106570     155316       0.0  2017-03-30 15:20:35  2017-02-17 00:00:00   \n",
       "106571     155317       0.0  2017-03-30 15:20:35  2017-02-17 00:00:00   \n",
       "106572     155318       0.0  2017-03-30 15:20:35  2017-02-17 00:00:00   \n",
       "106573     155319       0.0  2017-03-30 15:20:35  2017-02-17 00:00:00   \n",
       "106574     155320       0.0  2017-03-26 16:22:18  2017-03-26 00:00:00   \n",
       "\n",
       "       engineer  favorites       id  \\\n",
       "106570      NaN        0.0  22940.0   \n",
       "106571      NaN        0.0  22940.0   \n",
       "106572      NaN        0.0  22940.0   \n",
       "106573      NaN        0.0  22940.0   \n",
       "106574      NaN        1.0  22906.0   \n",
       "\n",
       "                                              information  listens  \\\n",
       "106570  <p>A live performance at Monty Hall on Feb 17,...   1506.0   \n",
       "106571  <p>A live performance at Monty Hall on Feb 17,...   1506.0   \n",
       "106572  <p>A live performance at Monty Hall on Feb 17,...   1506.0   \n",
       "106573  <p>A live performance at Monty Hall on Feb 17,...   1506.0   \n",
       "106574                                                NaN   7481.0   \n",
       "\n",
       "           producer                                               tags  \\\n",
       "106570  Monty Hall                                                  []   \n",
       "106571  Monty Hall                                                  []   \n",
       "106572  Monty Hall                                                  []   \n",
       "106573  Monty Hall                                                  []   \n",
       "106574          NaN  ['ballad', 'epic', 'rockabilly', 'curse', 'hex...   \n",
       "\n",
       "                                title  tracks              type  \\\n",
       "106570  Live at Monty Hall, 2/17/2017     6.0  Live Performance   \n",
       "106571  Live at Monty Hall, 2/17/2017     6.0  Live Performance   \n",
       "106572  Live at Monty Hall, 2/17/2017     6.0  Live Performance   \n",
       "106573  Live at Monty Hall, 2/17/2017     6.0  Live Performance   \n",
       "106574      What I Tell Myself Vol. 2    11.0             Album   \n",
       "\n",
       "       active_year_begin active_year_end associated_labels  \\\n",
       "106570               NaN             NaN               NaN   \n",
       "106571               NaN             NaN               NaN   \n",
       "106572               NaN             NaN               NaN   \n",
       "106573               NaN             NaN               NaN   \n",
       "106574               NaN             NaN               NaN   \n",
       "\n",
       "                                                      bio  comments.1  \\\n",
       "106570                                                NaN         0.0   \n",
       "106571                                                NaN         0.0   \n",
       "106572                                                NaN         0.0   \n",
       "106573                                                NaN         0.0   \n",
       "106574  <p>****NOTE FOR USING OUR MUSIC ON YOUTUBE****...         1.0   \n",
       "\n",
       "             date_created.1  favorites.1     id.1  latitude  \\\n",
       "106570  2017-03-30 15:18:28          0.0  24357.0       NaN   \n",
       "106571  2017-03-30 15:18:28          0.0  24357.0       NaN   \n",
       "106572  2017-03-30 15:18:28          0.0  24357.0       NaN   \n",
       "106573  2017-03-30 15:18:28          0.0  24357.0       NaN   \n",
       "106574  2016-02-04 17:26:24         12.0  21615.0       NaN   \n",
       "\n",
       "                     location  longitude  \\\n",
       "106570             New Jersey        NaN   \n",
       "106571             New Jersey        NaN   \n",
       "106572             New Jersey        NaN   \n",
       "106573             New Jersey        NaN   \n",
       "106574  Jersey City, NJ 07302        NaN   \n",
       "\n",
       "                                                  members              name  \\\n",
       "106570                         GILLIAN/JENNA/DECLAN/JAIME           Spowder   \n",
       "106571                         GILLIAN/JENNA/DECLAN/JAIME           Spowder   \n",
       "106572                         GILLIAN/JENNA/DECLAN/JAIME           Spowder   \n",
       "106573                         GILLIAN/JENNA/DECLAN/JAIME           Spowder   \n",
       "106574  Alishia Taiping (lead vocals, bass) \\nDan Pier...  Forget the Whale   \n",
       "\n",
       "                                         related_projects  \\\n",
       "106570                                                NaN   \n",
       "106571                                                NaN   \n",
       "106572                                                NaN   \n",
       "106573                                                NaN   \n",
       "106574  ** PLEASE CONNECT WITH US THROUGH FACEBOOK! WE...   \n",
       "\n",
       "                                                   tags.1  \\\n",
       "106570                                        ['spowder']   \n",
       "106571                                        ['spowder']   \n",
       "106572                                        ['spowder']   \n",
       "106573                                        ['spowder']   \n",
       "106574  ['forget the whale', 'witches', 'rockabilly', ...   \n",
       "\n",
       "                              website wikipedia_page       split subset  \\\n",
       "106570  https://spowder.bandcamp.com/            NaN    training  large   \n",
       "106571  https://spowder.bandcamp.com/            NaN    training  large   \n",
       "106572  https://spowder.bandcamp.com/            NaN    training  large   \n",
       "106573  https://spowder.bandcamp.com/            NaN    training  large   \n",
       "106574                            NaN            NaN  validation  large   \n",
       "\n",
       "        bit_rate  comments.2 composer       date_created.2 date_recorded  \\\n",
       "106570  320000.0         0.0      NaN  2017-03-30 15:23:34           NaN   \n",
       "106571  320000.0         0.0      NaN  2017-03-30 15:23:36           NaN   \n",
       "106572  320000.0         0.0      NaN  2017-03-30 15:23:37           NaN   \n",
       "106573  320000.0         0.0      NaN  2017-03-30 15:23:39           NaN   \n",
       "106574  320000.0         0.0      NaN  2017-03-30 09:15:36           NaN   \n",
       "\n",
       "        duration  favorites.2 genre_top         genres        genres_all  \\\n",
       "106570     162.0          1.0      Rock           [25]          [25, 12]   \n",
       "106571     217.0          1.0      Rock           [25]          [25, 12]   \n",
       "106572     404.0          2.0      Rock           [25]          [25, 12]   \n",
       "106573     146.0          0.0      Rock           [25]          [25, 12]   \n",
       "106574     198.0          1.0       NaN  [10, 12, 169]  [169, 10, 12, 9]   \n",
       "\n",
       "       information.1  interest language_code  \\\n",
       "106570           NaN     122.0           NaN   \n",
       "106571           NaN     194.0           NaN   \n",
       "106572           NaN     214.0           NaN   \n",
       "106573           NaN     336.0           NaN   \n",
       "106574           NaN     972.0           NaN   \n",
       "\n",
       "                                                  license  listens.1 lyricist  \\\n",
       "106570  Creative Commons Attribution-NonCommercial-NoD...      102.0      NaN   \n",
       "106571  Creative Commons Attribution-NonCommercial-NoD...      165.0      NaN   \n",
       "106572  Creative Commons Attribution-NonCommercial-NoD...      168.0      NaN   \n",
       "106573  Creative Commons Attribution-NonCommercial-NoD...      294.0      NaN   \n",
       "106574                          Attribution-NonCommercial      705.0      NaN   \n",
       "\n",
       "        number publisher                                             tags.2  \\\n",
       "106570     3.0       NaN                                                 []   \n",
       "106571     4.0       NaN                                                 []   \n",
       "106572     6.0       NaN                                                 []   \n",
       "106573     5.0       NaN                                                 []   \n",
       "106574     7.0       NaN  ['ballad', 'epic', 'rockabilly', 'curse', 'hex...   \n",
       "\n",
       "                                          title.1  \n",
       "106570                                  The Auger  \n",
       "106571                            Let's Skin Ruby  \n",
       "106572         My House Smells Like Kim Deal/Pulp  \n",
       "106573                    The Man With Two Mouths  \n",
       "106574  Another Trick Up My Sleeve (Instrumental)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks = pd.read_csv('fma_metadata/tracks.csv', header=1)\n",
    "tracks = tracks.iloc[1:]\n",
    "pd.set_option('display.max_columns', None)  # Unlimited columns\n",
    "tracks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T00:57:10.770650Z",
     "start_time": "2019-04-12T00:57:09.543407Z"
    }
   },
   "outputs": [],
   "source": [
    "# cats = ['genre_top']\n",
    "bdf = tracks.copy()\n",
    "# genre_top_columns = list(bdf.genre_top.unique())\n",
    "# # 2008-11-26 01:44:45\n",
    "# bdf['Genre_top_Index'] = bdf.genre_top.apply(lambda g: genre_top_columns.index(g))\n",
    "bdf['Date_created_timestamp'] = bdf.date_created. \\\n",
    "  apply(lambda d: datetime.strptime(d, \"%Y-%m-%d %X\").timestamp() if str(type(d)) == \"<class 'str'>\" else 0  )\n",
    "dfbc = bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T01:09:19.938813Z",
     "start_time": "2019-04-12T01:09:18.650762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_0</th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>name_3</th>\n",
       "      <th>name_4</th>\n",
       "      <th>name_5</th>\n",
       "      <th>name_6</th>\n",
       "      <th>name_7</th>\n",
       "      <th>name_8</th>\n",
       "      <th>name_9</th>\n",
       "      <th>name_10</th>\n",
       "      <th>name_11</th>\n",
       "      <th>name_12</th>\n",
       "      <th>name_13</th>\n",
       "      <th>name_14</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_released</th>\n",
       "      <th>engineer</th>\n",
       "      <th>favorites</th>\n",
       "      <th>id</th>\n",
       "      <th>information</th>\n",
       "      <th>listens</th>\n",
       "      <th>producer</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>tracks</th>\n",
       "      <th>type</th>\n",
       "      <th>active_year_begin</th>\n",
       "      <th>active_year_end</th>\n",
       "      <th>associated_labels</th>\n",
       "      <th>bio</th>\n",
       "      <th>comments.1</th>\n",
       "      <th>date_created.1</th>\n",
       "      <th>favorites.1</th>\n",
       "      <th>id.1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>members</th>\n",
       "      <th>related_projects</th>\n",
       "      <th>tags.1</th>\n",
       "      <th>website</th>\n",
       "      <th>wikipedia_page</th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments.2</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created.2</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites.2</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>information.1</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens.1</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags.2</th>\n",
       "      <th>title.1</th>\n",
       "      <th>Date_created_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:12</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Food</td>\n",
       "      <td>1.227682e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>medium</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:14</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>514.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Electric Ave</td>\n",
       "      <td>1.227682e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:44:45</td>\n",
       "      <td>2009-01-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;A Way Of Life, A Collective of Hip-Hop from...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:42:32</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.058324</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>-74.405661</td>\n",
       "      <td>Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...</td>\n",
       "      <td>The list of past projects is 2 long but every1...</td>\n",
       "      <td>['awol']</td>\n",
       "      <td>http://www.AzillionRecords.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:20</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>This World</td>\n",
       "      <td>1.227682e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:45:08</td>\n",
       "      <td>2008-02-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexican Summer, Richie Records, Woodsist, Skul...</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family:Verdana, Geneva, A...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2008-11-26 01:42:55</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile, the Violators</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['philly', 'kurt vile']</td>\n",
       "      <td>http://kurtvile.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>small</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>2008-11-25 17:49:06</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>161.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54881.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>50135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>1.227682e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-11-26 01:45:05</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;p&gt;Â \"spiritual songs\" from Nicky Cook&lt;/p&gt;</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Niris</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Album</td>\n",
       "      <td>1990-01-01 00:00:00</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Songs written by: Nicky Cook&lt;/p&gt;\\n&lt;p&gt;VOCALS...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008-11-26 01:42:52</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.895927</td>\n",
       "      <td>Colchester England</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>Nicky Cook\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['instrumentals', 'experimental pop', 'post pu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>training</td>\n",
       "      <td>large</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:48:56</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[76, 103]</td>\n",
       "      <td>[17, 10, 76, 103]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
       "      <td>361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Spiritual Level</td>\n",
       "      <td>1.227682e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_0  name_1  name_2  name_3  name_4  name_5  name_6  name_7  name_8  \\\n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   name_9  name_10  name_11  name_12  name_13  name_14 Unnamed: 0  comments  \\\n",
       "1       0        0        0        0        0        1          2       0.0   \n",
       "2       0        0        0        0        0        1          3       0.0   \n",
       "3       0        0        0        0        0        1          5       0.0   \n",
       "4       0        0        0        0        1        0         10       0.0   \n",
       "5       0        0        0        0        1        1         20       0.0   \n",
       "\n",
       "          date_created        date_released engineer  favorites   id  \\\n",
       "1  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN        4.0  1.0   \n",
       "2  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN        4.0  1.0   \n",
       "3  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN        4.0  1.0   \n",
       "4  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN        4.0  6.0   \n",
       "5  2008-11-26 01:45:05  2009-01-06 00:00:00      NaN        2.0  4.0   \n",
       "\n",
       "                                 information  listens producer tags  \\\n",
       "1                                    <p></p>   6073.0      NaN   []   \n",
       "2                                    <p></p>   6073.0      NaN   []   \n",
       "3                                    <p></p>   6073.0      NaN   []   \n",
       "4                                        NaN  47632.0      NaN   []   \n",
       "5  <p>Â \"spiritual songs\" from Nicky Cook</p>   2710.0      NaN   []   \n",
       "\n",
       "                  title  tracks   type    active_year_begin  \\\n",
       "1  AWOL - A Way Of Life     7.0  Album  2006-01-01 00:00:00   \n",
       "2  AWOL - A Way Of Life     7.0  Album  2006-01-01 00:00:00   \n",
       "3  AWOL - A Way Of Life     7.0  Album  2006-01-01 00:00:00   \n",
       "4     Constant Hitmaker     2.0  Album                  NaN   \n",
       "5                 Niris    13.0  Album  1990-01-01 00:00:00   \n",
       "\n",
       "       active_year_end                                  associated_labels  \\\n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN                                                NaN   \n",
       "4                  NaN  Mexican Summer, Richie Records, Woodsist, Skul...   \n",
       "5  2011-01-01 00:00:00                                                NaN   \n",
       "\n",
       "                                                 bio  comments.1  \\\n",
       "1  <p>A Way Of Life, A Collective of Hip-Hop from...         0.0   \n",
       "2  <p>A Way Of Life, A Collective of Hip-Hop from...         0.0   \n",
       "3  <p>A Way Of Life, A Collective of Hip-Hop from...         0.0   \n",
       "4  <p><span style=\"font-family:Verdana, Geneva, A...         3.0   \n",
       "5  <p>Songs written by: Nicky Cook</p>\\n<p>VOCALS...         2.0   \n",
       "\n",
       "        date_created.1  favorites.1  id.1   latitude            location  \\\n",
       "1  2008-11-26 01:42:32          9.0   1.0  40.058324          New Jersey   \n",
       "2  2008-11-26 01:42:32          9.0   1.0  40.058324          New Jersey   \n",
       "3  2008-11-26 01:42:32          9.0   1.0  40.058324          New Jersey   \n",
       "4  2008-11-26 01:42:55         74.0   6.0        NaN                 NaN   \n",
       "5  2008-11-26 01:42:52         10.0   4.0  51.895927  Colchester England   \n",
       "\n",
       "   longitude                                            members  \\\n",
       "1 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...   \n",
       "2 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...   \n",
       "3 -74.405661  Sajje Morocco,Brownbum,ZawidaGod,Custodian of ...   \n",
       "4        NaN                           Kurt Vile, the Violators   \n",
       "5   0.891874                                       Nicky Cook\\n   \n",
       "\n",
       "                                    related_projects  \\\n",
       "1  The list of past projects is 2 long but every1...   \n",
       "2  The list of past projects is 2 long but every1...   \n",
       "3  The list of past projects is 2 long but every1...   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                              tags.1  \\\n",
       "1                                           ['awol']   \n",
       "2                                           ['awol']   \n",
       "3                                           ['awol']   \n",
       "4                            ['philly', 'kurt vile']   \n",
       "5  ['instrumentals', 'experimental pop', 'post pu...   \n",
       "\n",
       "                                   website wikipedia_page     split  subset  \\\n",
       "1  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "2  http://www.AzillionRecords.blogspot.com            NaN  training  medium   \n",
       "3  http://www.AzillionRecords.blogspot.com            NaN  training   small   \n",
       "4                      http://kurtvile.com            NaN  training   small   \n",
       "5                                      NaN            NaN  training   large   \n",
       "\n",
       "   bit_rate  comments.2   composer       date_created.2        date_recorded  \\\n",
       "1  256000.0         0.0        NaN  2008-11-26 01:48:12  2008-11-26 00:00:00   \n",
       "2  256000.0         0.0        NaN  2008-11-26 01:48:14  2008-11-26 00:00:00   \n",
       "3  256000.0         0.0        NaN  2008-11-26 01:48:20  2008-11-26 00:00:00   \n",
       "4  192000.0         0.0  Kurt Vile  2008-11-25 17:49:06  2008-11-26 00:00:00   \n",
       "5  256000.0         0.0        NaN  2008-11-26 01:48:56  2008-01-01 00:00:00   \n",
       "\n",
       "   duration  favorites.2  genre_top     genres         genres_all  \\\n",
       "1     168.0          2.0          1       [21]               [21]   \n",
       "2     237.0          1.0          1       [21]               [21]   \n",
       "3     206.0          6.0          1       [21]               [21]   \n",
       "4     161.0        178.0          2       [10]               [10]   \n",
       "5     311.0          0.0          3  [76, 103]  [17, 10, 76, 103]   \n",
       "\n",
       "  information.1  interest language_code  \\\n",
       "1           NaN    4656.0            en   \n",
       "2           NaN    1470.0            en   \n",
       "3           NaN    1933.0            en   \n",
       "4           NaN   54881.0            en   \n",
       "5           NaN     978.0            en   \n",
       "\n",
       "                                             license  listens.1 lyricist  \\\n",
       "1  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1293.0      NaN   \n",
       "2  Attribution-NonCommercial-ShareAlike 3.0 Inter...      514.0      NaN   \n",
       "3  Attribution-NonCommercial-ShareAlike 3.0 Inter...     1151.0      NaN   \n",
       "4  Attribution-NonCommercial-NoDerivatives (aka M...    50135.0      NaN   \n",
       "5  Attribution-NonCommercial-NoDerivatives (aka M...      361.0      NaN   \n",
       "\n",
       "   number publisher tags.2          title.1  Date_created_timestamp  \n",
       "1     3.0       NaN     []             Food            1.227682e+09  \n",
       "2     4.0       NaN     []     Electric Ave            1.227682e+09  \n",
       "3     6.0       NaN     []       This World            1.227682e+09  \n",
       "4     1.0       NaN     []          Freeway            1.227682e+09  \n",
       "5     3.0       NaN     []  Spiritual Level            1.227682e+09  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders = Pipeline([\n",
    "                ('category', ce.OrdinalEncoder(cols=['genre_top'])),\n",
    "                ('binary', ce.BinaryEncoder(cols=['name']))\n",
    "#                 ('onehot', ce.OneHotEncoder(use_cat_names=True,cols=['type']))\n",
    "            ])\n",
    "df_ = encoders.fit_transform(dfbc)\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T04:01:26.041788Z",
     "start_time": "2019-04-12T04:01:23.889217Z"
    }
   },
   "outputs": [],
   "source": [
    "active_columns = [('name_' + str(j)) for j in range(0,15)]\n",
    "active_columns.append('Date_created_timestamp')\n",
    "X = df_[active_columns]\n",
    "y = df_['genre_top']\n",
    "# print(X.shape, y.shape)\n",
    "logreg = LogisticRegression(solver='liblinear', multi_class='ovr').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T04:01:26.077329Z",
     "start_time": "2019-04-12T04:01:26.043795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.845525174995778, -0.24214820266725523)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py = logreg.predict(X)\n",
    "mean_squared_error(y,py), r2_score(y,py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T01:20:52.818270Z",
     "start_time": "2019-04-12T01:20:52.776413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on genre_top: 0.53\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on genre_top: {:.2f}'.format(logreg.score(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T01:21:18.801509Z",
     "start_time": "2019-04-12T01:21:18.753004Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y.values, train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:04:06.093864Z",
     "start_time": "2019-04-12T01:21:20.142666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -0.9728358490999287\n",
      "Generation 2 - Current best internal CV score: -0.9728358490999287\n",
      "Generation 3 - Current best internal CV score: -0.9728358490999287\n",
      "Generation 4 - Current best internal CV score: -0.9728358490999287\n",
      "Generation 5 - Current best internal CV score: -0.9728358490999287\n",
      "\n",
      "Best pipeline: KNeighborsRegressor(SelectFromModel(input_matrix, max_features=0.8, n_estimators=100, threshold=0.25), n_neighbors=15, p=1, weights=distance)\n",
      "-0.7654462629567014\n",
      "CPU times: user 1h 42min 37s, sys: 4.18 s, total: 1h 42min 41s\n",
      "Wall time: 1h 42min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T03:55:37.601414Z",
     "start_time": "2019-04-12T03:55:37.466613Z"
    }
   },
   "outputs": [],
   "source": [
    "py = tpot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T04:00:33.356450Z",
     "start_time": "2019-04-12T04:00:33.340167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7654462629567014, 0.9034431183948416)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,py), r2_score(y_test,py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T04:03:26.994144Z",
     "start_time": "2019-04-12T04:03:23.435076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting automl_gs\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/51/27833a08fe4f83711b09836ddd9128e275a6900c47e0e5782112ed611484/automl_gs-0.2.1.tar.gz\n",
      "Requirement already satisfied: pandas in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from automl_gs) (0.24.2)\n",
      "Requirement already satisfied: scikit-learn in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from automl_gs) (0.20.2)\n",
      "Requirement already satisfied: autopep8 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from automl_gs) (1.4.3)\n",
      "Requirement already satisfied: tqdm in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from automl_gs) (4.29.1)\n",
      "Requirement already satisfied: jinja2>=2.8 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from automl_gs) (2.10)\n",
      "Requirement already satisfied: pyyaml in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from automl_gs) (3.13)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from pandas->automl_gs) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from pandas->automl_gs) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from pandas->automl_gs) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from scikit-learn->automl_gs) (1.2.0)\n",
      "Requirement already satisfied: pycodestyle>=2.4.0 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from autopep8->automl_gs) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from jinja2>=2.8->automl_gs) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mark/anaconda3/envs/myf/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->automl_gs) (1.12.0)\n",
      "Building wheels for collected packages: automl-gs\n",
      "  Building wheel for automl-gs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/mark/.cache/pip/wheels/2d/5e/f0/deffbd0fcc4afd6b065366dded7b9c8cd1b7c02f6b39c24552\n",
      "Successfully built automl-gs\n",
      "Installing collected packages: automl-gs\n",
      "Successfully installed automl-gs-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install automl_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T04:57:17.569164Z",
     "start_time": "2019-04-12T04:57:15.625337Z"
    }
   },
   "outputs": [],
   "source": [
    "active_columns.append('genre_top')\n",
    "df = df_[active_columns]\n",
    "with open('atracts.csv', 'w', newline=\"\\n\") as file: \n",
    "    df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T06:08:14.880999Z",
     "start_time": "2019-04-12T04:57:48.905541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a classification problem, maximizing accuracy using tensorflow.\n",
      "\n",
      "Modeling with field specifications:\n",
      "Unnamed: 0: numeric\n",
      "name_0: categorical\n",
      "name_1: categorical\n",
      "name_2: categorical\n",
      "name_3: categorical\n",
      "name_4: categorical\n",
      "name_5: categorical\n",
      "name_6: categorical\n",
      "name_7: categorical\n",
      "name_8: categorical\n",
      "name_9: categorical\n",
      "name_10: categorical\n",
      "name_11: categorical\n",
      "name_12: categorical\n",
      "name_13: categorical\n",
      "name_14: categorical\n",
      "Date_created_timestamp: numeric\n",
      "genre_top.1: categorical\n",
      "genre_top.2: categorical\n",
      "genre_top.3: categorical\n",
      "genre_top.4: categorical\n",
      "genre_top.5: categorical\n",
      "genre_top.6: categorical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234e00a16b0444d68b87e290d90f7ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e704329102ee4df19e5d3a146b1947d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics:\n",
      "trial_id: edde93b3-cbbb-4270-bec2-4abc73b4c557\n",
      "epoch: 20\n",
      "time_completed: 2019-04-12 04:58:53\n",
      "log_loss: 0.2208683409689864\n",
      "accuracy: 0.9232164638914084\n",
      "precision: 0.9232164638914084\n",
      "recall: 0.9232164638914084\n",
      "f1: 0.9232164638914084\n",
      "\n",
      "\n",
      "Metrics:\n",
      "trial_id: 9bb6447b-7dba-4f0f-a52c-6c3258e9dd88\n",
      "epoch: 20\n",
      "time_completed: 2019-04-12 05:15:30\n",
      "log_loss: 0.19406078098951712\n",
      "accuracy: 0.968285741094048\n",
      "precision: 0.968285741094048\n",
      "recall: 0.968285741094048\n",
      "f1: 0.968285741094048\n",
      "\n",
      "\n",
      "Metrics:\n",
      "trial_id: 8eb631f7-d20e-4ce4-9610-6ac75ae719a2\n",
      "epoch: 20\n",
      "time_completed: 2019-04-12 05:48:26\n",
      "log_loss: 0.10776638436740536\n",
      "accuracy: 0.9684733994307696\n",
      "precision: 0.9684733994307696\n",
      "recall: 0.9684733994307696\n",
      "f1: 0.9684733994307696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-82ff67e21928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautoml_gs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautoml_grid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mautoml_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'atracts.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genre_top'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myf/lib/python3.6/site-packages/automl_gs/automl_gs.py\u001b[0m in \u001b[0;36mautoml_grid_search\u001b[0;34m(csv_path, target_field, target_metric, framework, model_name, context, num_trials, split, num_epochs, col_types, gpu, tpu_address)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Execute model training using the generated files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mtrain_generated_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Load the training results from the generated CSV,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myf/lib/python3.6/site-packages/automl_gs/utils_automl.py\u001b[0m in \u001b[0;36mtrain_generated_model\u001b[0;34m(cmd, num_epochs, train_folder, pbar_sub)\u001b[0m\n\u001b[1;32m    323\u001b[0m               universal_newlines=True) \n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EPOCH_END\\n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mpbar_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from automl_gs import automl_grid_search\n",
    "\n",
    "automl_grid_search('atracts.csv', 'genre_top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics:\n",
    "trial_id: 8eb631f7-d20e-4ce4-9610-6ac75ae719a2\n",
    "epoch: 20\n",
    "time_completed: 2019-04-12 05:48:26\n",
    "log_loss: 0.10776638436740536\n",
    "accuracy: 0.9684733994307696\n",
    "precision: 0.9684733994307696\n",
    "recall: 0.9684733994307696\n",
    "f1: 0.9684733994307696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "Stretch goals\n",
    "- Apply AutoML to more data, including data you've not analyzed or data you're considering for project work\n",
    "- Try to work with the GPU/TPU options, and see if you can accelerate your AutoML\n",
    "- Check out other competing AutoML systems (see resources or search and share - many are cloud hosted which is why we went with this)\n",
    "- Write a blog post summarizing your experience learning Data Science at Lambda School!\n",
    "\n",
    "Resources\n",
    "- [What to expect from AutoML software](https://epistasislab.github.io/tpot/using/#what-to-expect-from-automl-software)\n",
    "- [TPOT examples](https://epistasislab.github.io/tpot/examples/)\n",
    "- [Google Cloud AutoML](https://cloud.google.com/automl/) - the Google offering in the AutoML space (also has vision, video, NLP, and translation)\n",
    "- [Microsoft AutoML](https://www.microsoft.com/en-us/research/project/automl/)\n",
    "- [AutoML.org](https://www.automl.org)\n",
    "- [Ludwig](https://uber.github.io/ludwig/) - a toolbox for deep learning that doesn't require coding, from Uber\n",
    "- [USENIX Security '18-Q: Why Do Keynote Speakers Keep Suggesting That Improving Security Is Possible?](https://youtu.be/ajGX7odA87k) - a humorous but informative presentation by James Mickens, focused on security but with a consideration of data and machine learning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_444_AGI_and_The_Future.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
