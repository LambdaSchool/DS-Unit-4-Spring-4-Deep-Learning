{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and AutoEncoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe the components of an autoencoder\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - RNNs\n",
    "\n",
    "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=723812,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), (2246,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 1s 1us/step\n",
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30980\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (8982, 200)\n",
      "X_test shape: (2246, 200)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "batch_size = 46\n",
    "max_features = len(word_index.values())  + 1\n",
    "\n",
    "print(max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "# TODO - your code!\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "8982/8982 [==============================] - 252s 28ms/sample - loss: -115.1470 - acc: 0.0469 - val_loss: -124.4585 - val_acc: 0.0396\n",
      "2246/2246 [==============================] - 10s 4ms/sample - loss: -124.4585 - acc: 0.0396\n",
      "Test score: -124.45849542116758\n",
      "Test accuracy: 0.039626002\n"
     ]
    }
   ],
   "source": [
    "# You should only run this cell once your model has been properly configured\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
    "\n",
    "The pad_sequences method makes the training data a 2-D array where each column is a new sequence of equal length. It is help limit data so the computer doesn't have such a rough time.\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "\n",
    "A LSTM is able to retain memory in moments of long time lags and thus, reduces error that occurs during backpropagation.\n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "\n",
    "LSTM: if you having a vanishing gradient problem, if you are working with time series data, and if you are answering a NLP problem or an image classification problem. LSTM's are designed to deal long lags sometime occur during training and testing. Because of their design, LSTM's work best with sequences of data (such as Times series' or text data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_images_download\n",
      "Collecting selenium (from google_images_download)\n",
      "  Using cached https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3 in c:\\users\\samue\\anaconda3\\lib\\site-packages (from selenium->google_images_download) (1.24.2)\n",
      "Installing collected packages: selenium, google-images-download\n",
      "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = animal pond\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
      "Completed Image ====> 1.PKLS4116_inline.png\n",
      "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
      "Completed Image ====> 2.hqdefault.jpg\n",
      "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
      "Completed Image ====> 3.PKLS4116.png\n",
      "Image URL: https://i.pinimg.com/originals/12/ae/e2/12aee2aa186a7b69a66563f138bba822.jpg\n",
      "Completed Image ====> 4.12aee2aa186a7b69a66563f138bba822.jpg\n",
      "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
      "Completed Image ====> 5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\": \"animal pond\", \"limit\": 5, \"print_urls\": True}\n",
    "absolute_image_paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goal* - also check for fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [],
   "source": [
    "# You've got something to do in this cell. ;)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "    \"\"\" Scans image for Frogs\n",
    "    \n",
    "    Should return a integer with the number of frogs detected in an\n",
    "    image.\n",
    "    \n",
    "    Inputs:\n",
    "    ---------\n",
    "    img:  Precrossed image ready for prediction. The `process_img_path`\n",
    "    function should already be applied to the image. \n",
    "    \n",
    "    Returns: \n",
    "    ---------\n",
    "    frogs (boolean):  TRUE or FALSE - There are frogs in the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Your Code Here\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=3)[0]\n",
    "    print(results)\n",
    "    frogs = False\n",
    "    for entry in results:\n",
    "        if entry[1] == 'bullfrog' | entry[1] == 'tree frog' | entry[1] == 'tailed frog':\n",
    "            frogs = True            \n",
    "    return frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Predictions\n",
    "The next two cells are just to display some of your predictions. You will not be graded on their output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_predictions(urls):\n",
    "    image_data = []\n",
    "    frogs = []\n",
    "    for url in urls:\n",
    "        x = process_img_path(url)\n",
    "        x = image.img_to_array(x)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        image_data.append(x)\n",
    "        frogs.append(img_contains_frog(x))\n",
    "    \n",
    "    return image_data,frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported image shape: (1, 224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-47f5ae195041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabsolute_image_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'animal pond'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-ee7c978c8994>\u001b[0m in \u001b[0;36mdisplay_predictions\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mimage_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mfrogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_contains_frog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-3a74abd45260>\u001b[0m in \u001b[0;36mimg_contains_frog\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Your Code Here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;31m#     x = np.expand_dims(x, axis=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S3-DNN\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S3-DNN\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unsupported image shape: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported image shape: (1, 224, 224, 3)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(2,2)\n",
    "\n",
    "imgs, frogs = display_predictions(absolute_image_paths[0]['animal pond'])\n",
    "\n",
    "for x,y in [(0,0),(0,1), (1,0), (1,1)]:  \n",
    "    axarr[x,y].imshow(np.squeeze(imgs[x], axis=0) / 255)\n",
    "    axarr[x,y].set_title(f\"Frog: {frogs[x]}\")\n",
    "    axarr[x,y].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
    "\n",
    "__Natural Language Processing: Trying to predict what the next word is.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?\n",
    "- What area of Data Science would you most like to learn more about, and why?\n",
    "- Where do you think Data Science will be in 5 years?\n",
    "- What are the threats posed by AI to our society?\n",
    "- How do you think we can counteract those threats? \n",
    "- Do you think achieving General Artifical Intelligence is ever possible?\n",
    "\n",
    "A few sentences per answer is fine - only elaborate if time allows.\n",
    "- I feel that my strongest area is cleaning data because we've done so much of it every week.\n",
    "- I think NLP and CNN's are really cool.\n",
    "- I'm not sure about where Data Science will be. I do know that more and more businesses (small to big) will be hiring more data scientists and because of that, I think we'll start venturing in directions we never thought of.\n",
    "- I think the biggest one for society is AI taking jobs that people don't want and jobs that they could do. For instance, I think instead of bouncers (at bars and clubs) they'll have a scanner that you show your id in order to enter certain establishments. Likewise, security guards won't be a thing. We'll have cameras that recognize guns in certain dangeroud positions and call the police and lock the place down so they can't easily escape.\n",
    "- I'm not sure it's a bad thing that AI is taking jobs because they aren't great jobs and it'll mean that other positons are created and people start to go into alternate schooling options.\n",
    "- Not right now. We need to understand how our own brains work before we created a robot brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "U4-S3-DNN",
   "language": "python",
   "name": "u4-s3-dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
