{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Sinclair_LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69xYoNGuhDoz",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "Load a pretrained network from TensorFlow Hub, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
        "\n",
        "```python\n",
        "module = hub.Module(\"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1\")\n",
        "height, width = hub.get_expected_image_size(module)\n",
        "images = ...  # A batch of images with shape [batch_size, height, width, 3].\n",
        "logits = module(images)  # Logits with shape [batch_size, num_classes].\n",
        "```\n",
        "\n",
        "Apply it to classify the images downloaded below (images from a search for animals in national parks):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZwRoyFOieg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx0wukF-in72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObIWTczxoyzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa168203-0ea5-4659-b464-184eed4102bc"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h6sMrlvLKT5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "f7f8e7d8-21cb-4907-b8bb-4c8efe8d6f42"
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"animal national park\", \"limit\": 20,\n",
        "             \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = animal national park\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://i.ytimg.com/vi/P8NJa_YoRxk/maxresdefault.jpg\n",
            "Completed Image ====> 1.maxresdefault.jpg\n",
            "Image URL: https://k6u8v6y8.stackpathcdn.com/blog/wp-content/uploads/2017/06/Royal-Bengal-Tiger.jpg\n",
            "Completed Image ====> 2.Royal-Bengal-Tiger.jpg\n",
            "Image URL: https://www.nps.gov/arch/learn/nature/images/ARK_6.jpg?maxwidth=1200&maxheight=1200&autorotate=false\n",
            "Completed Image ====> 3.ARK_6.jpg\n",
            "Image URL: https://www.corbettnationalpark.in/blog/wp-content/uploads/2015/08/cropped-13625772024_1fd7467d29_k1.jpg\n",
            "Completed Image ====> 4.cropped-13625772024_1fd7467d29_k1.jpg\n",
            "Image URL: https://npca.s3.amazonaws.com/images/8135/2c7e0d75-c7ff-4336-99d7-259448d03a4d-banner.jpg?1445969501\n",
            "Completed Image ====> 5.2c7e0d75-c7ff-4336-99d7-259448d03a4d-banner.jpg\n",
            "Image URL: https://k6u8v6y8.stackpathcdn.com/blog/wp-content/uploads/2014/04/national-parks-and-wildlife-sanctuaries-in-india.png\n",
            "Completed Image ====> 6.national-parks-and-wildlife-sanctuaries-in-india.png\n",
            "Image URL: https://www.nps.gov/voya/learn/nature/images/VOYA_web_deer.jpg?maxwidth=1200&maxheight=1200&autorotate=false\n",
            "Completed Image ====> 7.VOYA_web_deer.jpg\n",
            "Image URL: https://www.nationalpark-harz.de/__thumbs__/7017_13_Rotwild_KarlHeinz_Volkmar.jpg?m=1463043637\n",
            "Completed Image ====> 8.7017_13_Rotwild_KarlHeinz_Volkmar.jpg\n",
            "Image URL: https://npca.s3.amazonaws.com/images/11194/a2d539ed-8489-4eb4-a135-14e7e9e0e84a-banner.jpg?1495201170\n",
            "Completed Image ====> 9.a2d539ed-8489-4eb4-a135-14e7e9e0e84a-banner.jpg\n",
            "Image URL: https://www.kideponationalpark.com/wp-content/uploads/2016/11/zebras-in-kidepo-750x450.jpg\n",
            "Completed Image ====> 10.zebras-in-kidepo-750x450.jpg\n",
            "Image URL: http://jacksonhole-traveler-production.s3.amazonaws.com/wp-content/uploads/2014/05/moose-moosecalf-1280x853.jpg\n",
            "Completed Image ====> 11.moose-moosecalf-1280x853.jpg\n",
            "Image URL: http://www.nature-reserve.co.za/images/addo-elephant-national-park-elephants-590x390.jpg\n",
            "Completed Image ====> 12.addo-elephant-national-park-elephants-590x390.jpg\n",
            "Image URL: https://allaboutassam.in/wp-content/uploads/2018/12/nameri-national-park-is-famous-for-which-animal.jpg\n",
            "Completed Image ====> 13.nameri-national-park-is-famous-for-which-animal.jpg\n",
            "Image URL: https://upload.wikimedia.org/wikipedia/commons/5/54/Nairobi_National_Park%2C_Kenya_%2832570316676%29.jpg\n",
            "Completed Image ====> 14.Nairobi_National_Park%2C_Kenya_%2832570316676%29.jpg\n",
            "Image URL: https://lowvelder.co.za/wp-content/uploads/sites/44/2019/01/lion-520x400.jpg\n",
            "Completed Image ====> 15.lion-520x400.jpg\n",
            "Image URL: https://ihplb.b-cdn.net/wp-content/uploads/2014/06/Bandhavgarh.jpg\n",
            "Completed Image ====> 16.Bandhavgarh.jpg\n",
            "Image URL: https://upload.wikimedia.org/wikipedia/commons/1/1f/Tiger_Kanha_National_Park.jpg\n",
            "Completed Image ====> 17.Tiger_Kanha_National_Park.jpg\n",
            "Image URL: https://pcacdn.azureedge.net/-/media/pn-np/ab/banff/WET4/decouvrir-discover/animaux-animals/mammifieres-mammals/faune-wildlife/Grizzly-DanRafla.jpg?modified=20170314151358\n",
            "Completed Image ====> 18.Grizzly-DanRafla.jpg\n",
            "Image URL: https://assets.traveltriangle.com/blog/wp-content/uploads/2016/08/Sariska-national-Park.jpg\n",
            "Completed Image ====> 19.Sariska-national-Park.jpg\n",
            "Image URL: https://static.toiimg.com/thumb/50927262/Dudhwa-National-Park.jpg?width=748&height=499\n",
            "Completed Image ====> 20.Dudhwa-National-Park.jpg\n",
            "\n",
            "Errors: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zKaJ3uOiMAv0",
        "colab": {}
      },
      "source": [
        "image_list = absolute_image_paths[0]['animal national park']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJcuXpyhAn4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(img):\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize(img, [224, 224])\n",
        "  img /= 255.0 # normalize to [0,1]\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r5IWB5tBJwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_preprocess(path):\n",
        "  img = tf.read_file(path)\n",
        "  return preprocess_image(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBQSJqnpT6-v",
        "colab_type": "code",
        "outputId": "197df891-bb3b-4960-f072-5dbd8237f56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test on single image\n",
        "load_and_preprocess(image_list[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'truediv:0' shape=(224, 224, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4jQ2o2WUXXN",
        "colab_type": "code",
        "outputId": "a29370d8-5cbf-4ad5-bf1a-9c3498bc6cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Packs the list of tensors in `values` into a tensor with rank one higher than\n",
        "# each tensor in `values`, by packing them along the `axis` dimension.\n",
        "# Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
        "\n",
        "stacked_input = tf.stack([load_and_preprocess(i) for i in image_list])\n",
        "stacked_input"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'stack:0' shape=(20, 224, 224, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeyZoNfn3A_a",
        "colab_type": "text"
      },
      "source": [
        "## Module Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIxsbF8viy17",
        "colab_type": "code",
        "outputId": "630d018d-969e-4b9c-e055-9408dc87456c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# must set trainable=True to modify the weights\n",
        "module = hub.Module(\"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1\")\n",
        "height, weight = hub.get_expected_image_size(module)\n",
        "height, weight"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ7hCa4fX0gI",
        "colab_type": "code",
        "outputId": "7e68eb4c-498d-4ca8-c8e1-9575488dd91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "logits = module(stacked_input, signature='image_classification')\n",
        "logits"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'module_apply_image_classification_3/resnet_v1_50/SpatialSqueeze:0' shape=(20, 1001) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iumJHZBlii9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32596100-2c13-47e0-d1ea-22cdc5e3bf22"
      },
      "source": [
        "logits2 = module(dict(images=stacked_input))\n",
        "logits2"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'module_apply_default/resnet_v1_50/SpatialSqueeze:0' shape=(20, 1001) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SC5n4BSho5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax = tf.nn.softmax(logits)\n",
        "top_predictions = tf.nn.top_k(softmax, k=3, name='top_predictions')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-1haMaRjEYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3ee79ad-702e-42f2-ccd4-c4f6547d37f8"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'top_predictions:0' shape=(20, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0VVFFGi4sF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ce0585ff-b41d-4709-a506-f27af23acb03"
      },
      "source": [
        "help(tf.nn.top_k)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function top_k in module tensorflow.python.ops.nn_ops:\n",
            "\n",
            "top_k(input, k=1, sorted=True, name=None)\n",
            "    Finds values and indices of the `k` largest entries for the last dimension.\n",
            "    \n",
            "    If the input is a vector (rank=1), finds the `k` largest entries in the vector\n",
            "    and outputs their values and indices as vectors.  Thus `values[j]` is the\n",
            "    `j`-th largest entry in `input`, and its index is `indices[j]`.\n",
            "    \n",
            "    For matrices (resp. higher rank input), computes the top `k` entries in each\n",
            "    row (resp. vector along the last dimension).  Thus,\n",
            "    \n",
            "        values.shape = indices.shape = input.shape[:-1] + [k]\n",
            "    \n",
            "    If two elements are equal, the lower-index element appears first.\n",
            "    \n",
            "    Args:\n",
            "      input: 1-D or higher `Tensor` with last dimension at least `k`.\n",
            "      k: 0-D `int32` `Tensor`.  Number of top elements to look for along the last\n",
            "        dimension (along each row for matrices).\n",
            "      sorted: If true the resulting `k` elements will be sorted by the values in\n",
            "        descending order.\n",
            "      name: Optional name for the operation.\n",
            "    \n",
            "    Returns:\n",
            "      values: The `k` largest elements along each last dimensional slice.\n",
            "      indices: The indices of `values` within the last dimension of `input`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx9eNf9vgYy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "ab218087-765d-43ca-aaf9-1143f3596ae8"
      },
      "source": [
        "decode_predictions(logits, top=3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c3368fbf05c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                          \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
            "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (20, 1001)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfWs-Aplj40f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "04d79f86-ef95-467f-a717-1612b7e83791"
      },
      "source": [
        "help(decode_predictions())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-17dcc40b9759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: decode_predictions() missing 1 required positional argument: 'preds'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h45JlhiNcWLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Will's solution\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "i = 0\n",
        "for x in images:\n",
        "    i = i+1\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    features = model.predict(x)\n",
        "    results = decode_predictions(features, top=3)[0]\n",
        "    for result in results:\n",
        "        print(\"Image \" + str(i))\n",
        "        print(result[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzjEPMiYaAXG",
        "colab_type": "code",
        "outputId": "d2ce30f9-9b94-4b17-a4e6-72deb3825a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# why won't you work!?\n",
        "results = decode_predictions(logits, top=3)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-1aa7435a668a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                          \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
            "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (21, 1001)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gsR5F-Y3zR_",
        "colab_type": "text"
      },
      "source": [
        "## Expected Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bZnuz-Z31cU",
        "colab_type": "code",
        "outputId": "0da2ec6a-506d-4e85-e7c7-2702beaf25d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(module.get_input_info_dict())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'images': <hub.ParsedTensorInfo shape=(?, 224, 224, 3) dtype=float32 is_sparse=False>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39NQcVuR36Gt",
        "colab_type": "code",
        "outputId": "90212668-8b3e-43f2-b869-e49795b3ca57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(module.get_input_info_dict(signature='image_feature_vector'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'images': <hub.ParsedTensorInfo shape=(?, 224, 224, 3) dtype=float32 is_sparse=False>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qArkPsSM4JgB",
        "colab_type": "code",
        "outputId": "e4bc9797-ad66-4a78-8c7f-3a5daa93ad0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# shape will be (?, 1001) for default signature\n",
        "print(module.get_output_info_dict(signature='image_classification'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'resnet_v1_50/block2/unit_3/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'default': <hub.ParsedTensorInfo shape=(?, 1001) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_2/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/conv1': <hub.ParsedTensorInfo shape=(?, 112, 112, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/predictions': <hub.ParsedTensorInfo shape=(?, 1001) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_3/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 28, 28, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_2/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_4/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_2/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_4/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_2/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_4/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_2/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/global_pool': <hub.ParsedTensorInfo shape=(?, 1, 1, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_1/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 7, 7, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_1/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 7, 7, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_2/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_1/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_1/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_3/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 56, 56, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_2/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 56, 56, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1': <hub.ParsedTensorInfo shape=(?, 28, 28, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_3/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 28, 28, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2': <hub.ParsedTensorInfo shape=(?, 14, 14, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_1/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_3/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 28, 28, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/logits': <hub.ParsedTensorInfo shape=(?, 1, 1, 1001) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3': <hub.ParsedTensorInfo shape=(?, 7, 7, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_2/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_2/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_2/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_1/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_6/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 7, 7, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut': <hub.ParsedTensorInfo shape=(?, 56, 56, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_1/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 56, 56, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_5/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_5/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_3/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_5/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_1/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 56, 56, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_3/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_3/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_1/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 56, 56, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_1/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 56, 56, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_2/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 7, 7, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_5/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_2/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 7, 7, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_2/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/spatial_squeeze': <hub.ParsedTensorInfo shape=(?, 1001) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_3/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_1/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_3/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_3/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_1/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_1/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 28, 28, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_4/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_4/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 14, 14, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_3/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_6/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_4/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 28, 28, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_6/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 7, 7, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_4/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 14, 14, 128) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_6/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 7, 7, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_2/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 56, 56, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block2/unit_4/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 14, 14, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_2/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 56, 56, 64) dtype=float32 is_sparse=False>, 'resnet_v1_50/block1/unit_2/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 56, 56, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_3/bottleneck_v1': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_3/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 7, 7, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_3/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 7, 7, 512) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_1/bottleneck_v1/conv1': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_1/bottleneck_v1/conv2': <hub.ParsedTensorInfo shape=(?, 14, 14, 256) dtype=float32 is_sparse=False>, 'resnet_v1_50/block4/unit_3/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 7, 7, 2048) dtype=float32 is_sparse=False>, 'resnet_v1_50/block3/unit_1/bottleneck_v1/conv3': <hub.ParsedTensorInfo shape=(?, 14, 14, 1024) dtype=float32 is_sparse=False>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkgzNQfw4-15",
        "colab_type": "text"
      },
      "source": [
        "## Collecting required layers of module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np_ddxjU4Wqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = tf.placeholder(tf.float32, (None, 224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkFFTbnC-RQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkBuY_8Y65Bu",
        "colab_type": "code",
        "outputId": "e80f3e99-91a4-4d2a-c116-ee2fed9906ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "logits1 = module(dict(images=stacked_input))\n",
        "print(logits1)\n",
        "# Tensor(\"module_apply_default_44/resnet_v1_50/SpatialSqueeze:0\", shape=(?, 1001), dtype=float32)\n",
        "\n",
        "module_features = module(dict(images=stacked_input), signature='image_classification', as_dict=True)\n",
        "# stores all layers in key-value pairs\n",
        "\n",
        "logits2 = module_features['resnet_v1_50/logits']\n",
        "print(logits2)\n",
        "# Tensor(\"module_apply_image_classification_2/resnet_v1_50/logits/BiasAdd:0\", shape=(?, 1, 1, 1001), dtype=float32)\n",
        "\n",
        "global_pool = module_features['resnet_v1_50/global_pool']\n",
        "print(global_pool)\n",
        "# Tensor(\"module_apply_image_classification_3/resnet_v1_50/pool5:0\", shape=(?, 1, 1, 2048), dtype=float32) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"module_1_apply_default_1/resnet_v1_50/SpatialSqueeze:0\", shape=(21, 1001), dtype=float32)\n",
            "Tensor(\"module_1_apply_image_classification/resnet_v1_50/logits/BiasAdd:0\", shape=(21, 1, 1, 1001), dtype=float32)\n",
            "Tensor(\"module_1_apply_image_classification/resnet_v1_50/pool5:0\", shape=(21, 1, 1, 2048), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcD7ZMIP9SOM",
        "colab_type": "text"
      },
      "source": [
        "## Initialising TF Hub Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO1PUJHa9Vn2",
        "colab_type": "code",
        "outputId": "30d17680-290f-490c-f060-f8e4c603dfa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "with tf.Session as ses:\n",
        "  ses.run([tf.tables_initializer()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-8a040d569cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: __enter__"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hly75VuiMQE1"
      },
      "source": [
        "Report both the most likely estimated class for any image, and also investigate (a) images where the classifier isn't that certain (the best estimate is low), and (b) images where the classifier fails.\n",
        "\n",
        "Answer (in writing in the notebook) the following - \"What sorts of images do CNN classifiers do well with? What sorts do they not do so well? And what are your hypotheses for why?\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3wGRaT9hDqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "# Resources and Stretch Goals\n",
        "\n",
        "Stretch goals\n",
        "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
        "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
        "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
        "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
        "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
        "\n",
        "Resources\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
        "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
        "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
        "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
        "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
      ]
    }
  ]
}