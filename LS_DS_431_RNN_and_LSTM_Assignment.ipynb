{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "text = '100-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(text, 'r', encoding='utf8') as f:\n",
    "    data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = [re.sub('\\ufeff', ' ', i) for i in data]\n",
    "data = [re.sub('\\n', ' ', i) for i in data]\n",
    "data = [re.sub(r\"\\'\", \"'\", i) for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Project Gutenberg’s The Complete Works of William Shakespeare, by William Shakespeare  This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_string = ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(giant_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_char = int_char\n",
    "char_indices = char_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1114623\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in giant_string]\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i: i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "\n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char] = 1\n",
    "\n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = giant_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen)\n",
    "    for diversity in [0.2, 0.5, 0.75, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(500):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1114623 samples\n",
      "Epoch 1/4\n",
      "1114112/1114623 [============================>.] - ETA: 0s - loss: 1.5001\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"hard wall: Call, good Mercutio.  MERCUTI\"\n",
      "hard wall: Call, good Mercutio.  MERCUTIO. I will be the strange of the world of the world     That shall be a man and the strange that the heart in the world in the seeks     The mortal such a mortal that the propose of the world and the stand     That he seems the seem of the stand of the such a seek the part of the strange of the world     That is the such a doubt the world that the such a strange that shall be the strange of the heart of the stands     That we make the such a distressed with the face     That have she seeks the pr\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hard wall: Call, good Mercutio.  MERCUTI\"\n",
      "hard wall: Call, good Mercutio.  MERCUTIO. No, sir, and the others have stand this race.     Nor the death of a world with state.   MARGA. And the son are when she strange him and the field.   ROSALIND. No, the straight in the see of the winds.                                                              [Pereave._]                                                                                                                                                                                                                               \n",
      "----- diversity: 0.75\n",
      "----- Generating with seed: \"hard wall: Call, good Mercutio.  MERCUTI\"\n",
      "hard wall: Call, good Mercutio.  MERCUTIO. Sir But works, in a duive ungent of straight.   CASSIUS. What that I makes the own heart she tist.   Enter Captaet and Tappose but that I take that he can one on him.     He’s saugy of the hold an attal face And where the sabless with which the fawer; And bark this sight out out which mangion matter Of you’lls thy beropon'd That it will be none of our two some that gentle was the last lurn of him.   HAMARIO. I think thy argufure tears of Cambet open.         a King all worth room of Better ha\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"hard wall: Call, good Mercutio.  MERCUTI\"\n",
      "hard wall: Call, good Mercutio.  MERCUTIUS. My lord, acTin? My Lord of this swow Distries us philes. Do she hath sees or malice, there     cere wound that adfurm’d dare.  VIOLA. He has nothing home with you.     My lied not all pows Frome’s time and bear kast, and belike, And see wencice huser, or your wove of the pregity     Was see within blace me of yies, Since pracakion where.   LADY. My dispisses fronts their done: and swoon with respliuge, if I one this, where, That since to know and gatter least.  HELTOy. A gettle that he haste\n",
      "1114623/1114623 [==============================] - 355s 318us/sample - loss: 1.5001\n",
      "Epoch 2/4\n",
      "1114112/1114623 [============================>.] - ETA: 0s - loss: 1.4709\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"st thou like this jewel, Apemantus?   AP\"\n",
      "st thou like this jewel, Apemantus?   APEMANTUS. The gods the seeme of the sense of the words     To me the stand of the sense of the words     And the stand of the words of the season of the sense of the words     To the stand of my lordship be the state of the state of the war     To the stone of the constant of the stand     The constice of the still of the stand of the world of a beard     That she shall be seen the strong of the stand of the constant of the seem of the service     And the sears of the seemed of the country to the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"st thou like this jewel, Apemantus?   AP\"\n",
      "st thou like this jewel, Apemantus?   APEMANTUS. He that she art the little rest thou thing.     The words and sweet of the rest perporting of the father     Though he is feed with thine is a face That more from the stand of himself against you and leave.   SALISBURY. 'Tis her the prince of her wind of his consting     That in the arms of the great mighting                                                                                                                                                                                     \n",
      "----- diversity: 0.75\n",
      "----- Generating with seed: \"st thou like this jewel, Apemantus?   AP\"\n",
      "st thou like this jewel, Apemantus?   APEMANTUS. Why, then might thou make me from their strengthing.   YORK. To stone is were goings in their loping of a chain,     No shall philiwer to faith; for you for your false     mind world speak with him of     Romelin?                   Exeunt LORD LEONA,         Enter EROGHER          Come Scene VI. But was of thoughts.  FIRST GENT. My lord, so, my death for thee witchpes upon with the Saidon And will no stick fair that he house go this contrams’d: And not us in mindy than but infund thee. \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"st thou like this jewel, Apemantus?   AP\"\n",
      "st thou like this jewel, Apemantus?   APEMANTIA. Alas, the she mat from a       but love as farneal told     oreture With as bosom awtire Not the ofs. more that I wurn to chay     That use of the that would my foreweech gresdence to by himself     The eftrication for fast my Porew Fear’s king, though I am you, And please are plaince forsakes of conknce. Why, these I did.                                          Exit SARVIO, airding and Thanis.  TANDREW, ULENT's To sculs me for gives him?     Thou canst thou with as have shows; but spu\n",
      "1114623/1114623 [==============================] - 357s 320us/sample - loss: 1.4709\n",
      "Epoch 3/4\n",
      "1114112/1114623 [============================>.] - ETA: 0s - loss: 1.4528\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \", As had he been incorps’d and demi-natu\"\n",
      ", As had he been incorps’d and demi-nature of the strongle of the present of the straight of his lives     The true of the soul with the straight of the sun of the straight.     I have so the straight of the straight of the straight of the straight of the straight of the straight of the straight of the straight of the state     That the stranger of the straight of the commons.     The straight of the stand of the straight of his prison.     And there is the substance of the straight of his country.                                     \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \", As had he been incorps’d and demi-natu\"\n",
      ", As had he been incorps’d and demi-nature.                                                                                                                                                                                                                                                                    Exit   ESPRIAR      And so the words of the practed of his great suits,     I am all and the mens of thee.   KING HENRY. Why, whence of home, this strike the tain and bear thee this proper that many now this pointy     And the commanded \n",
      "----- diversity: 0.75\n",
      "----- Generating with seed: \", As had he been incorps’d and demi-natu\"\n",
      ", As had he been incorps’d and demi-nature speaks That she prayn that stards them see we was whether the bring of her.     The world of their friend on your prince In Somerse.   KING HENRY. Will it is his blood; our tood     curse it is blood, they will wait     That he wish’d him beaven with your my head.     And or for thee doth it is lives me so the Caesar       in proppry arms, I know you truth,   Were speak within, and every depart to thee royal old may man thought for me,   And shall be saves the man,     have more hearts of all\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \", As had he been incorps’d and demi-natu\"\n",
      ", As had he been incorps’d and demi-nature, For at this     fortasiance makes     To insurnor it doth at aeaven doth know thy peace, and they,     I'll casted on such the sAlectard’s than you come too aftratus ;   And sudden can bears masters! Besala hear’d BenDighis willst.  EUPHERNET. Nugstury, John carred all. If HELONG    [_Exeunt Hers'd can heavFen thy cooled. Was we not; it were thee Kings, takest not, whose kist, Is pratkdly, they upon one arm’d not; not as predest     Sho forsible, sir, thou would you.  PORTIA. or and horse th\n",
      "1114623/1114623 [==============================] - 360s 323us/sample - loss: 1.4528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n",
      "1114112/1114623 [============================>.] - ETA: 0s - loss: 1.4400\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"and reign as king.     Earl of Northumbe\"\n",
      "and reign as king.     Earl of Northumber                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"and reign as king.     Earl of Northumbe\"\n",
      "and reign as king.     Earl of Northumber and                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "----- diversity: 0.75\n",
      "----- Generating with seed: \"and reign as king.     Earl of Northumbe\"\n",
      "and reign as king.     Earl of Northumber receivent to him Growme in all will cannot god To feed one for their sleeps the alten, this made a day beside on my like And say whele it.                                                                                    Exeunn a man of Duking own._]  ISABER. His desires on my hands     And not be prodigited withs with one fresh;     The promise of the wors of his love of him,     The world it to bear Should harden noble, The seems and bear’d of the cearmence against               Some de sta\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"and reign as king.     Earl of Northumbe\"\n",
      "and reign as king.     Earl of Northumbers, mine each, which now drum before,     I pray we his sorrist worship! This carnea throne would make a perstarn,     So you that man by him clear and ear use feast, It rank. Be not, his swills with me; and have you speak Ante bad and our instant the numbert I without looks     Some rights old voying, like beth, Likes mad call discrections;     No more. [_To Lundians. Enter BARDOLPH    FALSTAFF. How so'; if you, I knee him. Where?   MENENAN. Marries head given propend I wish his nay stands here\n",
      "1114623/1114623 [==============================] - 399s 358us/sample - loss: 1.4399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad91ccb400>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=512,\n",
    "          epochs=4,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
