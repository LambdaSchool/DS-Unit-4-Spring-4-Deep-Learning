{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar(object):\n",
    "    \"\"\"Class that measures the time and reports duration in s/m/h format\"\"\"\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def elapsed(self, seconds):\n",
    "        if seconds < 60:\n",
    "            return str(seconds) + \" sec\"\n",
    "        elif seconds < (60 * 60):\n",
    "            return str(seconds / 60) + \" min\"\n",
    "        else:\n",
    "            return str(seconds / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with generating anime images\n",
    "\n",
    "    We start by defining a class that expects to take in images of 400 x 400 size in RGB format.\n",
    "    We will build a utility later on with OpenCV to ensure all images in our training data are converted to the correct format.\n",
    "    We go ahead and initilize all the model parts and set them to None to be added at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeGAN(object):\n",
    "    def __init__(self, img_rows=400, img_cols=400, channel=3):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.discriminator = None   # discriminator\n",
    "        self.generator = None   # generator\n",
    "        self.adv_model = None  # adversarial model\n",
    "        self.disc_model = None  # discriminator model\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " def discriminator(self):\n",
    "        if self.discriminator:\n",
    "            return self.discriminator\n",
    "        \n",
    "        self.discriminator = Sequential()\n",
    "        dropout = 0.2\n",
    "        \n",
    "        # In: 400 x 400 x 1, depth = 1\n",
    "        # Out: 14 x 14 x 1, depth=64\n",
    "        \n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        \n",
    "        self.discriminator.add(Conv2D(filters = 256, kernel_size=10, strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.3))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "\n",
    "        self.discriminator.add(Conv2D(512, 10, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.3))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "\n",
    "        self.discriminator.add(Conv2D(1024, 10, strides=2, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.3))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "\n",
    "        self.discriminator.add(Conv2D(2048, 10, strides=1, padding='same'))\n",
    "        self.discriminator.add(LeakyReLU(alpha=0.3))\n",
    "        self.discriminator.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.discriminator.add(Flatten())\n",
    "        self.discriminator.add(Dense(1))\n",
    "        self.discriminator.add(Activation('sigmoid'))\n",
    "        self.discriminator.summary()\n",
    "        return self.discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(self):\n",
    "        if self.generator:\n",
    "            return self.generator\n",
    "        self.generator = Sequential()\n",
    "        dropout = 0.2\n",
    "        depth = 256*4\n",
    "        dim = 7\n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        self.generator.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "        self.generator.add(Reshape((dim, dim, depth)))\n",
    "        self.generator.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth / 2), 10, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "\n",
    "        self.generator.add(UpSampling2D())\n",
    "        self.generator.add(Conv2DTranspose(int(depth / 4), 10, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "\n",
    "        self.generator.add(Conv2DTranspose(int(depth / 8), 10, padding='same'))\n",
    "        self.generator.add(BatchNormalization(momentum=0.9))\n",
    "        self.generator.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        self.generator.add(Conv2DTranspose(1, 10, padding='same'))\n",
    "        self.generator.add(Activation('sigmoid'))\n",
    "        self.generator.summary()\n",
    "        return self.generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model(self):\n",
    "        if self.discriminator_model:\n",
    "            return self.discriminator_model\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.discriminator_model = Sequential()\n",
    "        self.discriminator_model.add(self.discriminator())\n",
    "        self.discriminator_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.discriminator_model\n",
    "\n",
    "def adversarial_model(self):\n",
    "    if self.adversarial_model:\n",
    "        return self.adversarial_model\n",
    "    optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "    self.adversarial_model = Sequential()\n",
    "    self.adversarial_model.add(self.generator())\n",
    "    self.adversarial_model.add(self.discriminator())\n",
    "    self.adversarial_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return self.adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainAnimeGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = 400\n",
    "        self.img_cols = 400\n",
    "        self.channel = 3\n",
    "\n",
    "        self.x_train = input_data.read_data_sets(\"mnist\",\\\n",
    "        \tone_hot=True).train.images\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
    "        \tself.img_cols, 1).astype(np.float32)\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
