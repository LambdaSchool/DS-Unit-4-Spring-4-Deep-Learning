{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_data = open('shakespeare.txt', encoding=\"utf-8-sig\").read().lower()\n",
    "\n",
    "def replace_many(string_data, to_replace, new_string):\n",
    "    # Iterate over the strings in text data\n",
    "    for elem in to_replace :\n",
    "        # Check if string is in the main string\n",
    "        if elem in string_data :\n",
    "            # Replace the string\n",
    "            string_data = string_data.replace(elem, new_string)\n",
    "    \n",
    "    return  string_data\n",
    "\n",
    "shakespeare_data = replace_many(shakespeare_data, ['\\t', '\\n', '[', ']', '\\\\', '_', '|', '}'] , \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'æ', 'è', 'œ', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "single_chars = sorted(list(set(shakespeare_data)))\n",
    "print(single_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5471300\n"
     ]
    }
   ],
   "source": [
    "char_length = len(shakespeare_data)\n",
    "print(char_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "unique_chars = len(single_chars)\n",
    "print(unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process to dictionary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '$': 3, '%': 4, '&': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '@': 27, '`': 28, 'a': 29, 'b': 30, 'c': 31, 'd': 32, 'e': 33, 'f': 34, 'g': 35, 'h': 36, 'i': 37, 'j': 38, 'k': 39, 'l': 40, 'm': 41, 'n': 42, 'o': 43, 'p': 44, 'q': 45, 'r': 46, 's': 47, 't': 48, 'u': 49, 'v': 50, 'w': 51, 'x': 52, 'y': 53, 'z': 54, 'à': 55, 'æ': 56, 'è': 57, 'œ': 58, '—': 59, '‘': 60, '’': 61, '“': 62, '”': 63}\n"
     ]
    }
   ],
   "source": [
    "char_mapping = {char:numeric for numeric, char in enumerate(single_chars)}\n",
    "print(char_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '\"', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '@', 28: '`', 29: 'a', 30: 'b', 31: 'c', 32: 'd', 33: 'e', 34: 'f', 35: 'g', 36: 'h', 37: 'i', 38: 'j', 39: 'k', 40: 'l', 41: 'm', 42: 'n', 43: 'o', 44: 'p', 45: 'q', 46: 'r', 47: 's', 48: 't', 49: 'u', 50: 'v', 51: 'w', 52: 'x', 53: 'y', 54: 'z', 55: 'à', 56: 'æ', 57: 'è', 58: 'œ', 59: '—', 60: '‘', 61: '’', 62: '“', 63: '”'}\n"
     ]
    }
   ],
   "source": [
    "reverse_mapping = {numeric:char for numeric, char in enumerate(single_chars)}\n",
    "print(reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_threshold = 100\n",
    "inputs = []\n",
    "outputs = []\n",
    "char_counter = char_length - char_threshold\n",
    "\n",
    "for i in range(0, char_counter, 1):\n",
    "    \n",
    "    input_chars = shakespeare_data[i:i + char_threshold]\n",
    "    # this retrieves the threshold values character\n",
    "    output_chars = shakespeare_data[i + char_threshold]\n",
    "    #Appends threshold value char ids as a list into inputs\n",
    "    inputs.append([char_mapping[char] for char in input_chars])\n",
    "    #For every 100 values there is one y value which is the output\n",
    "    outputs.append(char_mapping[output_chars])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 36, 33, 0, 47, 43, 42, 42, 33, 48, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 40, 40, 61, 47, 0, 51, 33, 40, 40, 0, 48, 36, 29, 48, 0, 33, 42, 32, 47, 0, 51, 33, 40, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 36, 33, 0, 48, 46, 29, 35, 33, 32, 53, 0, 43, 34, 0, 29, 42, 48, 43, 42]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(outputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding one-hot encoding for char maps\n",
    "    We convert our reshaped data below in data_to_use into a one-hot vector. \n",
    "    Essentially an array of 0s and 1s. \n",
    "    The 1 only occurs at the position where the chracter_id that we mapped earlier is true. \n",
    "    For example, say we have some unique character IDs, [12, 11, 6, 3, 1].\n",
    "    Then say we have 1 single data output equal to 1, output = ([[0, 1, 0, 0, 0]]). Notice how the 1 only occurs at the position of 11.  So it means we have a binary\n",
    "    representation of that character occuring with other chars.\n",
    "    We do this iteratively in batch sizes using the threshold we determined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we reshape to 1 because we only plan to predict 1 char\n",
    "reshaped_data = np.reshape(inputs, (len(inputs), char_threshold, 1))\n",
    "\n",
    "# normalize our data \n",
    "reshaped_data = reshaped_data / float(unique_chars)\n",
    "\n",
    "# finally, we want categorical data to feed into our LSTM\n",
    "\n",
    "data_to_use = np_utils.to_categorical(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\Data_Science_Learning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "2849024/5471200 [==============>...............] - ETA: 40:37 - loss: 2.5808"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Since we know the shape of our Data we can input the timestep and feature data\n",
    "#The number of timestep sequence are dealt with in the fit function\n",
    "model.add(LSTM(256, input_shape=(reshaped_data.shape[1], reshaped_data.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(data_to_use.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(reshaped_data, data_to_use, epochs=5, batch_size=128)\n",
    "model.save_weights(\"shakespeare.hdf5\")\n",
    "#model.load_weights(\"Othello.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
