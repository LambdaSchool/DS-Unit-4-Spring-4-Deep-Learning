{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_data = open('shakespeare.txt', encoding=\"utf-8-sig\").read().lower()\n",
    "\n",
    "def replace_many(string_data, to_replace, new_string):\n",
    "    # Iterate over the strings in text data\n",
    "    for elem in to_replace :\n",
    "        # Check if string is in the main string\n",
    "        if elem in string_data :\n",
    "            # Replace the string\n",
    "            string_data = string_data.replace(elem, new_string)\n",
    "    \n",
    "    return  string_data\n",
    "\n",
    "shakespeare_data = replace_many(shakespeare_data, ['\\t', '\\n', '[', ']', '\\\\', '_', '|', '}', '%', '$', '0', '1' , '2', '3', '4', '5', '6', '7', '8', '9', '10', '@'] , \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', ':', ';', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'æ', 'è', 'œ', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "single_chars = sorted(list(set(shakespeare_data)))\n",
    "print(single_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5469373\n"
     ]
    }
   ],
   "source": [
    "char_length = len(shakespeare_data)\n",
    "print(char_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "unique_chars = len(single_chars)\n",
    "print(unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process to dictionary mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '\"': 2, '&': 3, \"'\": 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, '/': 11, ':': 12, ';': 13, '?': 14, '`': 15, 'a': 16, 'b': 17, 'c': 18, 'd': 19, 'e': 20, 'f': 21, 'g': 22, 'h': 23, 'i': 24, 'j': 25, 'k': 26, 'l': 27, 'm': 28, 'n': 29, 'o': 30, 'p': 31, 'q': 32, 'r': 33, 's': 34, 't': 35, 'u': 36, 'v': 37, 'w': 38, 'x': 39, 'y': 40, 'z': 41, 'à': 42, 'æ': 43, 'è': 44, 'œ': 45, '—': 46, '‘': 47, '’': 48, '“': 49, '”': 50}\n"
     ]
    }
   ],
   "source": [
    "char_mapping = {char:numeric for numeric, char in enumerate(single_chars)}\n",
    "print(char_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '\"', 3: '&', 4: \"'\", 5: '(', 6: ')', 7: '*', 8: ',', 9: '-', 10: '.', 11: '/', 12: ':', 13: ';', 14: '?', 15: '`', 16: 'a', 17: 'b', 18: 'c', 19: 'd', 20: 'e', 21: 'f', 22: 'g', 23: 'h', 24: 'i', 25: 'j', 26: 'k', 27: 'l', 28: 'm', 29: 'n', 30: 'o', 31: 'p', 32: 'q', 33: 'r', 34: 's', 35: 't', 36: 'u', 37: 'v', 38: 'w', 39: 'x', 40: 'y', 41: 'z', 42: 'à', 43: 'æ', 44: 'è', 45: 'œ', 46: '—', 47: '‘', 48: '’', 49: '“', 50: '”'}\n"
     ]
    }
   ],
   "source": [
    "reverse_mapping = {numeric:char for numeric, char in enumerate(single_chars)}\n",
    "print(reverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_threshold = 150\n",
    "inputs = []\n",
    "outputs = []\n",
    "char_counter = char_length - char_threshold\n",
    "\n",
    "for i in range(0, char_counter, 1):\n",
    "    \n",
    "    input_chars = shakespeare_data[i:i + char_threshold]\n",
    "    # this retrieves the threshold values character\n",
    "    output_chars = shakespeare_data[i + char_threshold]\n",
    "    #Appends threshold value char ids as a list into inputs\n",
    "    inputs.append([char_mapping[char] for char in input_chars])\n",
    "    #For every 100 values there is one y value which is the output\n",
    "    outputs.append(char_mapping[output_chars])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 23, 20, 0, 34, 30, 29, 29, 20, 35, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 27, 27, 48, 34, 0, 38, 20, 27, 27, 0, 35, 23, 16, 35, 0, 20, 29, 19, 34, 0, 38, 20, 27, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 23, 20, 0, 35, 33, 16, 22, 20, 19, 40, 0, 30, 21, 0, 16, 29, 35, 30, 29, 40, 0, 16, 29, 19, 0, 18, 27, 20, 30, 31, 16, 35, 33, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 34, 0, 40, 30, 36, 0, 27, 24, 26, 20, 0, 24, 35, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding one-hot encoding for char maps\n",
    "    We convert our reshaped data below in data_to_use into a one-hot vector. \n",
    "    Essentially an array of 0s and 1s. \n",
    "    The 1 only occurs at the position where the chracter_id that we mapped earlier is true. \n",
    "    For example, say we have some unique character IDs, [12, 11, 6, 3, 1].\n",
    "    Then say we have 1 single data output equal to 1, output = ([[0, 1, 0, 0, 0]]). Notice how the 1 only occurs at the position of 11.  \n",
    "    So it means we have a binar representation of that character occuring with other chars.\n",
    "    We do this iteratively in batch sizes using the threshold we determined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we reshape to 1 because we only plan to predict 1 char at a time, \n",
    "reshaped_data = np.reshape(inputs, (len(inputs), char_threshold, 1))\n",
    "\n",
    "# normalize our data \n",
    "reshaped_data = reshaped_data / float(unique_chars)\n",
    "\n",
    "# finally, we want categorical data to feed into our LSTM\n",
    "\n",
    "cats = np_utils.to_categorical(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5469223/5469223 [==============================] - 341s 62us/step - loss: 2.7794\n",
      "Epoch 2/2\n",
      "5469223/5469223 [==============================] - 321s 59us/step - loss: 2.6500\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    model = Sequential()\n",
    "    #Since we know the shape of our Data we can input the timestep and feature data\n",
    "    #The number of timestep sequence are dealt with in the fit function\n",
    "    model.add(LSTM(42, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='he_uniform', recurrent_initializer='orthogonal', \n",
    "                   bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, \n",
    "                   activity_regularizer=None, \n",
    "                   kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.1, implementation=1, return_sequences=False, \n",
    "                   return_state=False, go_backwards=False, stateful=False, unroll=False))\n",
    "    # output layer\n",
    "    model.add(Dense(cats.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop')\n",
    "    model.fit(reshaped_data, cats, epochs=2, batch_size=4024)\n",
    "    model.save_weights(\"shakespeare.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"shakespeare.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n his soulo’er which his melancholy sits on brood,and i do doubt the hatch and the disclosewill be some danger, which for to prevent,i have in quick t\n",
      "e laid most heavy hand.  soothsayer. the fingers of the pow'rs above do tune    the harmony of this peace. the vision    which i made known to lucius \n",
      " to him.  agrippa. let us go.    good enobarbus, make yourself my guest    whilst you abide here.  enobarbus. humbly, sir, i thank you.               \n",
      " in health.  valentine. how does your lady, and how thrives your love?  proteus. my tales of love were wont to weary you;    i know you joy not in a s\n",
      "rt and a smock.nurse.peter!peter.anon.nurse.my fan, peter.mercutio.good peter, to hide her face; for her fan’s the fairer face.nurse.god ye good morr \n",
      "fore prepare thyself;the bark is ready, and the wind at help,th’associates tend, and everything is bentfor england.hamlet.for england?king.ay, hamlet \n",
      "repose, to be asleep    with eyes wide open; standing, speaking, moving,    and yet so fast asleep.  antonio. noble sebastian,    thou let'st thy for \n",
      " no more?  cloten. yes, and a gentlewoman's son.  lady. that's more    than some whose tailors are as dear as yours    can justly boast of. what's yoe\n",
      "for honour,    'tis a derivative from me to mine,    and only that i stand for. i appeal    to your own conscience, sir, before polixenes    came to t\n",
      " he shall have every day a several greeting,    or i'll unpeople egypt.                               exeuntact ii. scene i. messina. pompey's housee \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    randomVal = np.random.randint(0, len(inputs) - 1)\n",
    "    randomStart = inputs[randomVal]\n",
    "    x = np.reshape(randomStart, (1, len(randomStart), 1))\n",
    "    x = x/float(unique_chars)\n",
    "    pred = model.predict(x)\n",
    "    index = np.argmax(pred)\n",
    "    randomStart.append(index)\n",
    "    randomStart = randomStart[1: len(randomStart)]\n",
    "    #print(randomStart)\n",
    "    print(\"\".join([reverse_mapping[value] for value in randomStart]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
