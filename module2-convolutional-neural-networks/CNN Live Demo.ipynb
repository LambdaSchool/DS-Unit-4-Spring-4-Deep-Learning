{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = np.load('./full_numpy_bitmap_dog.npy')\n",
    "elephants = np.load('./full_numpy_bitmap_elephant.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((dogs, elephants), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279128, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279128, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_y = np.ones(len(dogs))\n",
    "ele_y = np.zeros(len(elephants))\n",
    "y_train = np.concatenate((dog_y, ele_y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = unison_shuffled_copies(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x145d1d2e8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(elephants[500].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279128, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPool1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(4, (2), padding='same', activation='relu', input_shape=(28,28)))\n",
    "    model.add(Conv1D(4, (2), activation='relu'))\n",
    "    model.add(MaxPool1D(pool_size=(2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 12:41:07.009786 4503033280 deprecation.py:323] From /Users/jonathansokoll/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 279128 samples\n",
      "Epoch 1/100\n",
      "279128/279128 [==============================] - 16s 56us/sample - loss: 4.8186 - accuracy: 0.6819\n",
      "Epoch 2/100\n",
      "279128/279128 [==============================] - 16s 59us/sample - loss: 4.1554 - accuracy: 0.7278\n",
      "Epoch 3/100\n",
      "279128/279128 [==============================] - 16s 59us/sample - loss: 3.9432 - accuracy: 0.7424\n",
      "Epoch 4/100\n",
      "279128/279128 [==============================] - 15s 55us/sample - loss: 3.8454 - accuracy: 0.7492\n",
      "Epoch 5/100\n",
      "279128/279128 [==============================] - 16s 57us/sample - loss: 3.9513 - accuracy: 0.7425\n",
      "Epoch 6/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.0123 - accuracy: 0.7385\n",
      "Epoch 7/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 3.8303 - accuracy: 0.7506\n",
      "Epoch 8/100\n",
      "279128/279128 [==============================] - 16s 56us/sample - loss: 3.9059 - accuracy: 0.7457\n",
      "Epoch 9/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 3.9745 - accuracy: 0.7412\n",
      "Epoch 10/100\n",
      "279128/279128 [==============================] - 16s 57us/sample - loss: 3.9358 - accuracy: 0.7436\n",
      "Epoch 11/100\n",
      "279128/279128 [==============================] - 16s 57us/sample - loss: 4.0419 - accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 3.9543 - accuracy: 0.7427\n",
      "Epoch 13/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 3.7942 - accuracy: 0.7531\n",
      "Epoch 14/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.3552 - accuracy: 0.7171\n",
      "Epoch 15/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.0884 - accuracy: 0.7343\n",
      "Epoch 16/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 3.8999 - accuracy: 0.7464\n",
      "Epoch 17/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.0004 - accuracy: 0.7400\n",
      "Epoch 18/100\n",
      "279128/279128 [==============================] - 16s 59us/sample - loss: 3.8931 - accuracy: 0.7468\n",
      "Epoch 19/100\n",
      "279128/279128 [==============================] - 18s 63us/sample - loss: 4.0296 - accuracy: 0.7377\n",
      "Epoch 20/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 3.9907 - accuracy: 0.7402\n",
      "Epoch 21/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.4351 - accuracy: 0.7112\n",
      "Epoch 22/100\n",
      "279128/279128 [==============================] - 15s 54us/sample - loss: 4.0297 - accuracy: 0.7379\n",
      "Epoch 23/100\n",
      "279128/279128 [==============================] - 16s 57us/sample - loss: 3.9273 - accuracy: 0.7447\n",
      "Epoch 24/100\n",
      "279128/279128 [==============================] - 19s 68us/sample - loss: 4.0524 - accuracy: 0.7364\n",
      "Epoch 25/100\n",
      "279128/279128 [==============================] - 18s 63us/sample - loss: 4.7449 - accuracy: 0.6920\n",
      "Epoch 26/100\n",
      "279128/279128 [==============================] - 18s 63us/sample - loss: 4.6169 - accuracy: 0.7002\n",
      "Epoch 27/100\n",
      "279128/279128 [==============================] - 16s 59us/sample - loss: 4.4462 - accuracy: 0.7105\n",
      "Epoch 28/100\n",
      "279128/279128 [==============================] - 16s 56us/sample - loss: 4.4424 - accuracy: 0.7109\n",
      "Epoch 29/100\n",
      "279128/279128 [==============================] - 17s 59us/sample - loss: 4.1765 - accuracy: 0.7285\n",
      "Epoch 30/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.2015 - accuracy: 0.7271\n",
      "Epoch 31/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.0791 - accuracy: 0.7345\n",
      "Epoch 32/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 4.0770 - accuracy: 0.7349\n",
      "Epoch 33/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.0805 - accuracy: 0.7346\n",
      "Epoch 34/100\n",
      "279128/279128 [==============================] - 16s 57us/sample - loss: 3.9759 - accuracy: 0.7413\n",
      "Epoch 35/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 3.9361 - accuracy: 0.7438\n",
      "Epoch 36/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.2857 - accuracy: 0.7210\n",
      "Epoch 37/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 4.2982 - accuracy: 0.7204\n",
      "Epoch 38/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 4.1506 - accuracy: 0.7300\n",
      "Epoch 39/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.0078 - accuracy: 0.7393\n",
      "Epoch 40/100\n",
      "279128/279128 [==============================] - 16s 56us/sample - loss: 3.8107 - accuracy: 0.7521\n",
      "Epoch 41/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 3.7895 - accuracy: 0.7536\n",
      "Epoch 42/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 3.9244 - accuracy: 0.7450\n",
      "Epoch 43/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.0333 - accuracy: 0.7378\n",
      "Epoch 44/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 3.9668 - accuracy: 0.7421\n",
      "Epoch 45/100\n",
      "279128/279128 [==============================] - 18s 64us/sample - loss: 4.0380 - accuracy: 0.7375\n",
      "Epoch 46/100\n",
      "279128/279128 [==============================] - 16s 57us/sample - loss: 4.0948 - accuracy: 0.7338\n",
      "Epoch 47/100\n",
      "279128/279128 [==============================] - 15s 55us/sample - loss: 3.9579 - accuracy: 0.7424\n",
      "Epoch 48/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.0055 - accuracy: 0.7393\n",
      "Epoch 49/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.0248 - accuracy: 0.7385\n",
      "Epoch 50/100\n",
      "279128/279128 [==============================] - 15s 55us/sample - loss: 3.9846 - accuracy: 0.7407\n",
      "Epoch 51/100\n",
      "279128/279128 [==============================] - 15s 54us/sample - loss: 3.9781 - accuracy: 0.7412\n",
      "Epoch 52/100\n",
      "279128/279128 [==============================] - 16s 58us/sample - loss: 4.0185 - accuracy: 0.7389\n",
      "Epoch 53/100\n",
      "279128/279128 [==============================] - 17s 63us/sample - loss: 3.9404 - accuracy: 0.7438\n",
      "Epoch 54/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.1849 - accuracy: 0.7279\n",
      "Epoch 55/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.1084 - accuracy: 0.7330\n",
      "Epoch 56/100\n",
      "279128/279128 [==============================] - 17s 59us/sample - loss: 3.9265 - accuracy: 0.7448\n",
      "Epoch 57/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.0577 - accuracy: 0.7360\n",
      "Epoch 58/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 3.9772 - accuracy: 0.7412\n",
      "Epoch 59/100\n",
      "279128/279128 [==============================] - 18s 63us/sample - loss: 3.8331 - accuracy: 0.7507\n",
      "Epoch 60/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 3.8724 - accuracy: 0.7482\n",
      "Epoch 61/100\n",
      "279128/279128 [==============================] - 18s 63us/sample - loss: 4.2135 - accuracy: 0.7256\n",
      "Epoch 62/100\n",
      "279128/279128 [==============================] - 18s 63us/sample - loss: 3.9769 - accuracy: 0.7411\n",
      "Epoch 63/100\n",
      "279128/279128 [==============================] - 17s 63us/sample - loss: 4.2564 - accuracy: 0.7234\n",
      "Epoch 64/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.0732 - accuracy: 0.7351\n",
      "Epoch 65/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.2814 - accuracy: 0.7219\n",
      "Epoch 66/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 4.6535 - accuracy: 0.6981\n",
      "Epoch 67/100\n",
      "279128/279128 [==============================] - 17s 61us/sample - loss: 4.1888 - accuracy: 0.7279\n",
      "Epoch 68/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 3.8011 - accuracy: 0.7528\n",
      "Epoch 69/100\n",
      "279128/279128 [==============================] - 17s 62us/sample - loss: 3.7888 - accuracy: 0.7535\n",
      "Epoch 70/100\n",
      "279128/279128 [==============================] - 17s 60us/sample - loss: 3.8694 - accuracy: 0.7486\n",
      "Epoch 71/100\n",
      "279128/279128 [==============================] - 14s 50us/sample - loss: 3.9570 - accuracy: 0.7425\n",
      "Epoch 72/100\n",
      "279128/279128 [==============================] - 13s 46us/sample - loss: 4.2779 - accuracy: 0.7222\n",
      "Epoch 73/100\n",
      "279128/279128 [==============================] - 13s 46us/sample - loss: 3.8208 - accuracy: 0.7515\n",
      "Epoch 74/100\n",
      "279128/279128 [==============================] - 12s 43us/sample - loss: 4.2397 - accuracy: 0.7247\n",
      "Epoch 75/100\n",
      "279128/279128 [==============================] - 13s 48us/sample - loss: 3.9918 - accuracy: 0.7405\n",
      "Epoch 76/100\n",
      "279128/279128 [==============================] - 12s 44us/sample - loss: 4.1962 - accuracy: 0.7268\n",
      "Epoch 77/100\n",
      "279128/279128 [==============================] - 14s 50us/sample - loss: 4.2982 - accuracy: 0.7201\n",
      "Epoch 78/100\n",
      "279128/279128 [==============================] - 14s 50us/sample - loss: 4.6602 - accuracy: 0.6964\n",
      "Epoch 79/100\n",
      "279128/279128 [==============================] - 14s 50us/sample - loss: 4.1074 - accuracy: 0.7327\n",
      "Epoch 80/100\n",
      "279128/279128 [==============================] - 14s 50us/sample - loss: 3.9126 - accuracy: 0.7455\n",
      "Epoch 81/100\n",
      "279128/279128 [==============================] - 14s 50us/sample - loss: 3.9842 - accuracy: 0.7409\n",
      "Epoch 82/100\n",
      "279128/279128 [==============================] - 12s 44us/sample - loss: 4.0231 - accuracy: 0.7381\n",
      "Epoch 83/100\n",
      "279128/279128 [==============================] - 12s 44us/sample - loss: 4.4381 - accuracy: 0.7110\n",
      "Epoch 84/100\n",
      "279128/279128 [==============================] - 12s 44us/sample - loss: 4.0371 - accuracy: 0.7376\n",
      "Epoch 85/100\n",
      "279128/279128 [==============================] - 13s 48us/sample - loss: 3.9459 - accuracy: 0.7434\n",
      "Epoch 86/100\n",
      "279128/279128 [==============================] - 13s 46us/sample - loss: 3.8659 - accuracy: 0.7486\n",
      "Epoch 87/100\n",
      "279128/279128 [==============================] - 12s 43us/sample - loss: 3.8382 - accuracy: 0.7505\n",
      "Epoch 88/100\n",
      "279128/279128 [==============================] - 13s 45us/sample - loss: 4.0298 - accuracy: 0.7382\n",
      "Epoch 89/100\n",
      "279128/279128 [==============================] - 13s 45us/sample - loss: 3.9301 - accuracy: 0.7445\n",
      "Epoch 90/100\n",
      "279128/279128 [==============================] - 12s 43us/sample - loss: 3.8732 - accuracy: 0.7483\n",
      "Epoch 91/100\n",
      "180800/279128 [==================>...........] - ETA: 4s - loss: 3.7478 - accuracy: 0.7564"
     ]
    }
   ],
   "source": [
    "# Defined arch\n",
    "# Next step in Keras is to COMPILE!.... \n",
    "\n",
    "model = create_model()\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S3-DNN (Python 3.7)",
   "language": "python",
   "name": "u4-s3-dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
