{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lfZdD_cp1t5"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Load a pretrained network from TensorFlow Hub, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
    "\n",
    "```python\n",
    "module = hub.Module(\"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1\")\n",
    "height, width = hub.get_expected_image_size(module)\n",
    "images = ...  # A batch of images with shape [batch_size, height, width, 3].\n",
    "logits = module(images)  # Logits with shape [batch_size, num_classes].\n",
    "```\n",
    "\n",
    "Apply it to classify the images downloaded below (images from a search for animals in national parks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "GgTukFacGBBs",
    "outputId": "d8ebf892-a091-4ab5-98a3-9bb7ceddfd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_images_download\n",
      "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
      "Requirement already satisfied: selenium in c:\\users\\mhdal\\anaconda3\\envs\\lambda-neural\\lib\\site-packages (from google_images_download) (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\mhdal\\anaconda3\\envs\\lambda-neural\\lib\\site-packages (from selenium->google_images_download) (1.25.3)\n",
      "Building wheels for collected packages: google-images-download\n",
      "  Building wheel for google-images-download (setup.py): started\n",
      "  Building wheel for google-images-download (setup.py): finished with status 'done'\n",
      "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14554 sha256=3364350cbe2d305e6ebdf9d12f960e78970f31067882e0c84988fb59cb7bae53\n",
      "  Stored in directory: C:\\Users\\mhdal\\AppData\\Local\\pip\\Cache\\wheels\\1f\\28\\ad\\f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
      "Successfully built google-images-download\n",
      "Installing collected packages: google-images-download\n",
      "Successfully installed google-images-download-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "h6sMrlvLKT5X",
    "outputId": "0beade70-7047-45cc-d40c-6105ef967dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = animal national park\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Image URL: https://i.ytimg.com/vi/P8NJa_YoRxk/maxresdefault.jpg\n",
      "Completed Image ====> 1.maxresdefault.jpg\n",
      "Image URL: https://k6u8v6y8.stackpathcdn.com/blog/wp-content/uploads/2014/04/national-parks-and-wildlife-sanctuaries-in-india.png\n",
      "Completed Image ====> 2.national-parks-and-wildlife-sanctuaries-in-india.png\n",
      "Image URL: https://upload.wikimedia.org/wikipedia/commons/5/54/Nairobi_National_Park%2C_Kenya_%2832570316676%29.jpg\n",
      "Completed Image ====> 3.Nairobi_National_Park%2C_Kenya_%2832570316676%29.jpg\n",
      "Image URL: https://www.kideponationalpark.com/wp-content/uploads/2016/11/zebras-in-kidepo-750x450.jpg\n",
      "Completed Image ====> 4.zebras-in-kidepo-750x450.jpg\n",
      "Image URL: https://k6u8v6y8.stackpathcdn.com/blog/wp-content/uploads/2017/06/Royal-Bengal-Tiger.jpg\n",
      "Completed Image ====> 5.Royal-Bengal-Tiger.jpg\n",
      "Image URL: http://www.nature-reserve.co.za/images/addo-elephant-national-park-elephants-590x390.jpg\n",
      "Completed Image ====> 6.addo-elephant-national-park-elephants-590x390.jpg\n",
      "Image URL: https://www.corbettnationalpark.in/blog/wp-content/uploads/2015/08/cropped-13625772024_1fd7467d29_k1.jpg\n",
      "Completed Image ====> 7.cropped-13625772024_1fd7467d29_k1.jpg\n",
      "Image URL: https://npca.s3.amazonaws.com/images/8135/2c7e0d75-c7ff-4336-99d7-259448d03a4d-banner.jpg?1445969501\n",
      "Completed Image ====> 8.2c7e0d75-c7ff-4336-99d7-259448d03a4d-banner.jpg\n",
      "Image URL: https://www.nps.gov/arch/learn/nature/images/ARK_6.jpg?maxwidth=1200&maxheight=1200&autorotate=false\n",
      "Completed Image ====> 9.ARK_6.jpg\n",
      "Image URL: https://npca.s3.amazonaws.com/images/11194/a2d539ed-8489-4eb4-a135-14e7e9e0e84a-banner.jpg?1495201170\n",
      "Completed Image ====> 10.a2d539ed-8489-4eb4-a135-14e7e9e0e84a-banner.jpg\n",
      "Image URL: https://upload.wikimedia.org/wikipedia/commons/1/1f/Tiger_Kanha_National_Park.jpg\n",
      "Completed Image ====> 11.Tiger_Kanha_National_Park.jpg\n",
      "Image URL: https://greenglobaltravel.com/wp-content/uploads/2017/04/elephant-seal.jpg\n",
      "Completed Image ====> 12.elephant-seal.jpg\n",
      "Image URL: https://media-cdn.tripadvisor.com/media/photo-s/02/31/63/34/nairobi-national-park.jpg\n",
      "Completed Image ====> 13.nairobi-national-park.jpg\n",
      "Image URL: https://allaboutassam.in/wp-content/uploads/2018/12/nameri-national-park-is-famous-for-which-animal.jpg\n",
      "Completed Image ====> 14.nameri-national-park-is-famous-for-which-animal.jpg\n",
      "Image URL: https://www.nps.gov/voya/learn/nature/images/VOYA_web_deer.jpg?maxwidth=1200&maxheight=1200&autorotate=false\n",
      "Completed Image ====> 15.VOYA_web_deer.jpg\n",
      "Image URL: https://pcacdn.azureedge.net/-/media/pn-np/ab/banff/WET4/decouvrir-discover/animaux-animals/mammifieres-mammals/faune-wildlife/Grizzly-DanRafla.jpg?modified=20170314151358\n",
      "Completed Image ====> 16.Grizzly-DanRafla.jpg\n",
      "Image URL: http://images.huffingtonpost.com/2014-06-03-ChitwanNationalParkOlance.jpg\n",
      "Completed Image ====> 17.2014-06-03-ChitwanNationalParkOlance.jpg\n",
      "Image URL: https://www.princess.com/images/global/learn/cruise-destinations/alaska-cruises/alaska-cruise-tips/cruise-preparation-and-tips/spot-denali-national-parks-animals.jpg\n",
      "Completed Image ====> 18.spot-denali-national-parks-animals.jpg\n",
      "Image URL: https://static.toiimg.com/thumb/50927262/Dudhwa-National-Park.jpg?width=748&height=499\n",
      "Completed Image ====> 19.Dudhwa-National-Park.jpg\n",
      "Image URL: https://lowvelder.co.za/wp-content/uploads/sites/44/2019/01/lion-520x400.jpg\n",
      "Completed Image ====> 20.lion-520x400.jpg\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\": \"animal national park\", \"limit\": 20,\n",
    "             \"print_urls\": True}\n",
    "absolute_image_paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "zKaJ3uOiMAv0",
    "outputId": "2d27e452-1ec2-4c88-a038-8bfc4d041f70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'animal national park': ['C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\1.maxresdefault.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\2.national-parks-and-wildlife-sanctuaries-in-india.png',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\3.Nairobi_National_Park%2C_Kenya_%2832570316676%29.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\4.zebras-in-kidepo-750x450.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\5.Royal-Bengal-Tiger.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\6.addo-elephant-national-park-elephants-590x390.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\7.cropped-13625772024_1fd7467d29_k1.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\8.2c7e0d75-c7ff-4336-99d7-259448d03a4d-banner.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\9.ARK_6.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\10.a2d539ed-8489-4eb4-a135-14e7e9e0e84a-banner.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\11.Tiger_Kanha_National_Park.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\12.elephant-seal.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\13.nairobi-national-park.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\14.nameri-national-park-is-famous-for-which-animal.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\15.VOYA_web_deer.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\16.Grizzly-DanRafla.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\17.2014-06-03-ChitwanNationalParkOlance.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\18.spot-denali-national-parks-animals.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\19.Dudhwa-National-Park.jpg',\n",
       "   'C:\\\\Users\\\\mhdal\\\\github\\\\DS-Unit-4-Sprint-3-Deep-Learning\\\\module2-convolutional-neural-networks\\\\downloads\\\\animal national park\\\\20.lion-520x400.jpg']},\n",
       " 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hly75VuiMQE1"
   },
   "source": [
    "Report both the most likely estimated class for any image, and also investigate (a) images where the classifier isn't that certain (the best estimate is low), and (b) images where the classifier fails.\n",
    "\n",
    "Answer (in writing in the notebook) the following - \"What sorts of images do CNN classifiers do well with? What sorts do they not do so well? And what are your hypotheses for why?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'../module2-convolutional-neural-networks/downloads/animal national park/1.maxresdefault.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('../module2-convolutional-neural-networks/downloads/animal national park/1.maxresdefault.jpg', target_size = (height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape_2:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FM_ApKbGYM9S",
    "outputId": "4bfd7ce4-47e5-4320-d1b8-2b20e9f66416"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_banana(img):\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  model = ResNet50(weights='imagenet')\n",
    "  features = model.predict(x)\n",
    "  results = decode_predictions(features, top=3)[0]\n",
    "  print(results)\n",
    "  for entry in results:\n",
    "    if entry[1] == 'banana':\n",
    "      return entry[2]\n",
    "  return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'images': data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow_hub\\tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[1;34m(value, target, error_prefix)\u001b[0m\n\u001b[0;32m    118\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_or_indexed_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_or_indexed_slices\u001b[1;34m(value, dtype, name)\u001b[0m\n\u001b[0;32m   1349\u001b[0m   return internal_convert_to_tensor_or_indexed_slices(\n\u001b[1;32m-> 1350\u001b[1;33m       value=value, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[1;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     return internal_convert_to_tensor(\n\u001b[1;32m-> 1388\u001b[1;33m         value, dtype=dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 246\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[0;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;31m# is possible to convert to numpy array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m     \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-cb3d485c0e6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_image_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# A batch of images with shape [batch_size, height, width, 3].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Logits with shape [batch_size, num_classes]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[0;32m    248\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[0;32m    249\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[1;32m--> 250\u001b[1;33m                                                tags=self._tags))\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[1;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[0;32m    450\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[1;32m--> 452\u001b[1;33m                                                        tensor_info_map)\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow_hub\\tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[1;34m(values, targets)\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[1;32m--> 150\u001b[1;33m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[0;32m    151\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-neural\\lib\\site-packages\\tensorflow_hub\\tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[1;34m(value, target, error_prefix)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_or_indexed_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0merror_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_is_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_is_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert 'images': data type not understood"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "module = hub.Module(\"https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1\")\n",
    "height, width = hub.get_expected_image_size(module)\n",
    "images = [img, height, width, 3]  # A batch of images with shape [batch_size, height, width, 3].\n",
    "logits = module(images)  # Logits with shape [batch_size, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "ttt = Image(filename='../module2-convolutional-neural-networks/downloads/animal national park/1.maxresdefault.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloads\n",
      "example0.jpg\n",
      "example1.jpg\n",
      "LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb\n",
      "LS_DS_432_Convolutional_Neural_Networks_Lecture.ipynb\n",
      "LS_DS_432_Convolutional_Neural_Networks_Lecture_Assignment.ipynb.txt\n",
      "LS_DS_442_Convolutional_Neural_Networks.ipynb\n",
      "tower0.jpg\n",
      "tower1.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "# Resources and Stretch Goals\n",
    "\n",
    "Stretch goals\n",
    "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
    "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
    "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
    "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
    "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
    "\n",
    "Resources\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
    "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
    "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
    "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
    "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lambda-neural]",
   "language": "python",
   "name": "conda-env-lambda-neural-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
