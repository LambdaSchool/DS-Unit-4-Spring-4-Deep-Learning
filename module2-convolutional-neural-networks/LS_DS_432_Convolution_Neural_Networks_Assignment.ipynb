{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.23.1"
    },
    "colab": {
      "name": "LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ACpMNbNa7xH",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "- <a href=\"#p1\">Part 1:</a> Pre-Trained Model\n",
        "- <a href=\"#p2\">Part 2:</a> Custom CNN Model\n",
        "- <a href=\"#p3\">Part 3:</a> CNN with Data Augmentation\n",
        "\n",
        "\n",
        "You will apply three different CNN models to a binary image classification model using Keras. Classify images of Mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "|Mountain (+)|Forest (-)|\n",
        "|---|---|\n",
        "|![](https://github.com/richardOlson/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data/train/mountain/art1131.jpg?raw=1)|![](https://github.com/richardOlson/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data/validation/forest/cdmc317.jpg?raw=1)|\n",
        "\n",
        "The problem is relatively difficult given that the sample is tiny: there are about 350 observations per class. This sample size might be something that you can expect with prototyping an image classification problem/solution at work. Get accustomed to evaluating several different possible models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OxwYgj5ya7xJ"
      },
      "source": [
        "# Pre - Trained Model\n",
        "<a id=\"p1\"></a>\n",
        "\n",
        "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model # This is the functional API\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "```\n",
        "\n",
        "The `include_top` parameter in `ResNet50` will remove the full connected layers from the ResNet model. The next step is to turn off the training of the ResNet layers. We want to use the learned parameters without updating them in future training passes. \n",
        "\n",
        "```python\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "```\n",
        "\n",
        "Using the Keras functional API, we will need to additional additional full connected layers to our model. We we removed the top layers, we removed all preivous fully connected layers. In other words, we kept only the feature processing portions of our network. You can expert with additional layers beyond what's listed here. The `GlobalAveragePooling2D` layer functions as a really fancy flatten function by taking the average of each of the last convolutional layer outputs (which is two dimensional still). \n",
        "\n",
        "```python\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)\n",
        "```\n",
        "\n",
        "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "Steps to complete assignment: \n",
        "1. Load in Image Data into numpy arrays (`X`) \n",
        "2. Create a `y` for the labels\n",
        "3. Train your model with pre-trained layers from resnet\n",
        "4. Report your model's accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm4H1c3ca7xK",
        "colab_type": "text"
      },
      "source": [
        "## Load in Data\n",
        "\n",
        "This surprisingly more difficult than it seems, because you are working with directories of images instead of a single file. This boiler plate will help you download a zipped version of the directory of images. The directory is organized into \"train\" and \"validation\" which you can use inside an `ImageGenerator` class to stream batches of images thru your model.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkbO4oYa7xK",
        "colab_type": "text"
      },
      "source": [
        "### Download & Summarize the Data\n",
        "\n",
        "This step is completed for you. Just run the cells and review the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2w0s8LKa7xL",
        "colab_type": "code",
        "outputId": "13e3674f-ee33-4ce1-d794-680f9573c3f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "_URL = 'https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data.zip?raw=true'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('./data.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'data')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module2-convolutional-neural-networks/data.zip?raw=true\n",
            "42172416/42170838 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs-yss6fa7xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVKSO49m2z-h",
        "colab_type": "code",
        "outputId": "46d4797f-fc5d-4298-d91e-82126004a335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dir"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/./data/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M8Fyf6Wa7xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mountain_dir = os.path.join(train_dir, 'mountain')  # directory with our training cat pictures\n",
        "train_forest_dir = os.path.join(train_dir, 'forest')  # directory with our training dog pictures\n",
        "validation_mountain_dir = os.path.join(validation_dir, 'mountain')  # directory with our validation cat pictures\n",
        "validation_forest_dir = os.path.join(validation_dir, 'forest')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG3bKvnEa7xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_mountain_tr = len(os.listdir(train_mountain_dir))\n",
        "num_forest_tr = len(os.listdir(train_forest_dir))\n",
        "\n",
        "num_mountain_val = len(os.listdir(validation_mountain_dir))\n",
        "num_forest_val = len(os.listdir(validation_forest_dir))\n",
        "\n",
        "total_train = num_mountain_tr + num_forest_tr\n",
        "total_val = num_mountain_val + num_forest_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bn-5v_za7xZ",
        "colab_type": "code",
        "outputId": "ce226ec8-7baf-4e62-aa41-08abffc61d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "print('total training mountain images:', num_mountain_tr)\n",
        "print('total training forest images:', num_forest_tr)\n",
        "\n",
        "print('total validation mountain images:', num_mountain_val)\n",
        "print('total validation forest images:', num_forest_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training mountain images: 254\n",
            "total training forest images: 270\n",
            "total validation mountain images: 125\n",
            "total validation forest images: 62\n",
            "--\n",
            "Total training images: 524\n",
            "Total validation images: 187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jZhqk1ra7xc",
        "colab_type": "text"
      },
      "source": [
        "### Keras `ImageGenerator` to Process the Data\n",
        "\n",
        "This step is completed for you, but please review the code. The `ImageGenerator` class reads in batches of data from a directory and pass them to the model one batch at a time. Just like large text files, this method is advantageous, because it stifles the need to load a bunch of images into memory. \n",
        "\n",
        "Check out the documentation for this class method: [Keras `ImageGenerator` Class](https://keras.io/preprocessing/image/#imagedatagenerator-class). You'll expand it's use in the third assignment objective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn5tjIcga7xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doing some of the imports\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing  import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import  Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import  Layer, Dense\n",
        "from tensorflow.keras.models import  Model\n",
        "from tensorflow.keras import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7JAf9MHa7xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "epochs = 50\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC-SFY8Za7xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input, shear_range=.2, zoom_range=.2, horizontal_flip=True) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-fdmI5Ua7xi",
        "colab_type": "code",
        "outputId": "ef812275-d5d3-4ec5-f4dd-f212294ec451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 533 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4OdwH00p3cO",
        "colab_type": "code",
        "outputId": "d0426c03-eae8-48a3-ef8e-362c1447bff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data_gen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_preprocessing.image.directory_iterator.DirectoryIterator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71QBzzO2a7xl",
        "colab_type": "code",
        "outputId": "74182959-0eb8-4cdb-cd0c-7bd4762a63c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 195 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8pTv6Ora7xo",
        "colab_type": "text"
      },
      "source": [
        "## Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFmLWg2wfMfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmnEmcQ6rRj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b45d33e6-d5cb-4a48-9f15-95c85e678b35"
      },
      "source": [
        "# instanciating the resnet\n",
        "resnet = ResNet50(include_top=False, weights=\"imagenet\", pooling=\"avg\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoBY-p482HDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfweQcJ78d5T",
        "colab_type": "code",
        "outputId": "5fac365f-647b-45d7-eb77-1a7707f004cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYkGpkZyy8Jp",
        "colab_type": "code",
        "outputId": "f8977284-84d0-4c35-a3c4-ccebb07cb5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_data_gen[0][1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vHimDi11RDU",
        "colab_type": "code",
        "outputId": "3ccbe743-e2b0-4789-84a7-fc5ac3c4c4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "type(train_data_gen[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3K3_H3c1hm_",
        "colab_type": "code",
        "outputId": "7aecc50d-4360-40e9-8fc7-3441fe1bfbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_data_gen[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtI0NSHdrwh0",
        "colab_type": "code",
        "outputId": "f3db1c3e-7863-4ee9-a446-f3ef851edd29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_data_gen[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55aRHGsA39Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Will be adding a new layer to the the output of one\n",
        "# for the classification\n",
        "#adding 2 dense layers\n",
        "firstDense = Dense(1024, activation=\"relu\")\n",
        "outPutLayer = Dense(1, activation=\"sigmoid\")\n",
        "onlyOutPut = Dense(1, activation=\"sigmoid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XX4o4UY8e86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making the model that will only have the ouput layer added\n",
        "onlyOutPutModel = Sequential([resnet, onlyOutPut])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr0A8if75m2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the complete model\n",
        "completeModel = Sequential([resnet, firstDense, outPutLayer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpTjf1V7Cqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onlyOutPutModel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"], \n",
        "                        optimizer=tf.keras.optimizers.RMSprop(learning_rate=.0001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdPZHSsh6dFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now doing the compiling of the model\n",
        "completeModel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"],\n",
        "                      optimizer=tf.keras.optimizers.RMSprop(learning_rate=.0001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSjze2g48MAS",
        "colab_type": "code",
        "outputId": "757c0c83-880a-459c-8311-496c3ad6b37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "completeModel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 25,686,913\n",
            "Trainable params: 2,099,201\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bC9tX8l-Mbr",
        "colab_type": "code",
        "outputId": "490d0938-3e96-4d82-d93c-8bb56081b71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "onlyOutPutModel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 23,589,761\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBsQlTNsJ4X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-MPGDvlJ-Zw",
        "colab_type": "code",
        "outputId": "0e2b1ab5-5682-4e76-8788-28b3b89b668e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7OaNeQRLVVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the images out as a batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaX60G0Q7_gV",
        "colab_type": "code",
        "outputId": "cb88fdfd-929a-4800-f887-482bb4476f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Doing the evaluation of with just changing the \n",
        "# output to what we wanted\n",
        "# Doing the loop with the dataGenerator\n",
        "\n",
        "the_losses, the_accuracy = onlyOutPutModel.evaluate(train_data_gen)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 77s 2s/step - loss: 0.7522 - accuracy: 0.4859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfomuVqlO9Hg",
        "colab_type": "code",
        "outputId": "df2500a3-4658-4c77-e2da-6d54d8a4c385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Doing the evaluation again with the two layers for the \n",
        "# dense layers at the end\n",
        "# Will just do one epoch\n",
        "the_losses, the_accuracy = completeModel.evaluate(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 76s 2s/step - loss: 0.7455 - accuracy: 0.4859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL11ka5Da7xr",
        "colab_type": "text"
      },
      "source": [
        "## Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq0kJW5cQMeB",
        "colab_type": "code",
        "outputId": "3a437ef7-29a8-4ed6-e00e-462a60ddbdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This is with just just running the model with only able to train the output \n",
        "# layer\n",
        "history = onlyOutPutModel.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 8s 239ms/step - loss: 0.7737 - accuracy: 0.4870 - val_loss: 0.6468 - val_accuracy: 0.6534\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 7s 218ms/step - loss: 0.7539 - accuracy: 0.4810 - val_loss: 0.6535 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.7368 - accuracy: 0.5090 - val_loss: 0.6513 - val_accuracy: 0.3466\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 7s 214ms/step - loss: 0.7131 - accuracy: 0.5070 - val_loss: 0.6568 - val_accuracy: 0.3466\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.7035 - accuracy: 0.5010 - val_loss: 0.6613 - val_accuracy: 0.3409\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.7023 - accuracy: 0.5170 - val_loss: 0.6647 - val_accuracy: 0.3295\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6970 - accuracy: 0.5050 - val_loss: 0.6716 - val_accuracy: 0.3466\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6975 - accuracy: 0.5190 - val_loss: 0.6727 - val_accuracy: 0.3295\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6960 - accuracy: 0.5190 - val_loss: 0.6773 - val_accuracy: 0.3466\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6950 - accuracy: 0.5170 - val_loss: 0.6792 - val_accuracy: 0.3409\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6944 - accuracy: 0.5150 - val_loss: 0.6809 - val_accuracy: 0.3409\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6943 - accuracy: 0.5210 - val_loss: 0.6836 - val_accuracy: 0.3580\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 0.6937 - accuracy: 0.5156 - val_loss: 0.6835 - val_accuracy: 0.3466\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6934 - accuracy: 0.5130 - val_loss: 0.6837 - val_accuracy: 0.3352\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6931 - accuracy: 0.5090 - val_loss: 0.6841 - val_accuracy: 0.3409\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6937 - accuracy: 0.5230 - val_loss: 0.6850 - val_accuracy: 0.3409\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6929 - accuracy: 0.5070 - val_loss: 0.6859 - val_accuracy: 0.3580\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6930 - accuracy: 0.5110 - val_loss: 0.6853 - val_accuracy: 0.3409\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6931 - accuracy: 0.5170 - val_loss: 0.6855 - val_accuracy: 0.3352\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6932 - accuracy: 0.5190 - val_loss: 0.6860 - val_accuracy: 0.3523\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6931 - accuracy: 0.5190 - val_loss: 0.6858 - val_accuracy: 0.3466\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 0.6930 - accuracy: 0.5150 - val_loss: 0.6860 - val_accuracy: 0.3409\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.6932 - accuracy: 0.5230 - val_loss: 0.6862 - val_accuracy: 0.3466\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.6931 - accuracy: 0.5230 - val_loss: 0.6857 - val_accuracy: 0.3352\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6931 - accuracy: 0.5210 - val_loss: 0.6869 - val_accuracy: 0.3636\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.6928 - accuracy: 0.5156 - val_loss: 0.6863 - val_accuracy: 0.3523\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 7s 214ms/step - loss: 0.6927 - accuracy: 0.5130 - val_loss: 0.6864 - val_accuracy: 0.3523\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6926 - accuracy: 0.5170 - val_loss: 0.6862 - val_accuracy: 0.3580\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6921 - accuracy: 0.5050 - val_loss: 0.6837 - val_accuracy: 0.3068\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6924 - accuracy: 0.5117 - val_loss: 0.6854 - val_accuracy: 0.3580\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6926 - accuracy: 0.5150 - val_loss: 0.6846 - val_accuracy: 0.3409\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6924 - accuracy: 0.5150 - val_loss: 0.6842 - val_accuracy: 0.3409\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6851 - val_accuracy: 0.3636\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6916 - accuracy: 0.5010 - val_loss: 0.6825 - val_accuracy: 0.3352\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6924 - accuracy: 0.5170 - val_loss: 0.6823 - val_accuracy: 0.3352\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6926 - accuracy: 0.5234 - val_loss: 0.6820 - val_accuracy: 0.3352\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6815 - val_accuracy: 0.3295\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6917 - accuracy: 0.5090 - val_loss: 0.6828 - val_accuracy: 0.3580\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6920 - accuracy: 0.5190 - val_loss: 0.6811 - val_accuracy: 0.3409\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6924 - accuracy: 0.5210 - val_loss: 0.6823 - val_accuracy: 0.3580\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6816 - val_accuracy: 0.3580\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6923 - accuracy: 0.5230 - val_loss: 0.6806 - val_accuracy: 0.3409\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6921 - accuracy: 0.5230 - val_loss: 0.6791 - val_accuracy: 0.3295\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6915 - accuracy: 0.5150 - val_loss: 0.6798 - val_accuracy: 0.3466\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 7s 208ms/step - loss: 0.6913 - accuracy: 0.5130 - val_loss: 0.6794 - val_accuracy: 0.3466\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 7s 209ms/step - loss: 0.6920 - accuracy: 0.5230 - val_loss: 0.6810 - val_accuracy: 0.3693\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6912 - accuracy: 0.5130 - val_loss: 0.6757 - val_accuracy: 0.3182\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6781 - val_accuracy: 0.3523\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6905 - accuracy: 0.5090 - val_loss: 0.6763 - val_accuracy: 0.3466\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6906 - accuracy: 0.5130 - val_loss: 0.6752 - val_accuracy: 0.3466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8YoIUWQP8Tr",
        "colab_type": "code",
        "outputId": "5fb35cae-a480-4e62-be5b-b19fc8484736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Will have one dense layer before the \n",
        "# output layer that can be trained\n",
        "history = completeModel.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 8s 236ms/step - loss: 0.6965 - accuracy: 0.5190 - val_loss: 0.6810 - val_accuracy: 0.3409\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6932 - accuracy: 0.5190 - val_loss: 0.6859 - val_accuracy: 0.3409\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6913 - accuracy: 0.5130 - val_loss: 0.6592 - val_accuracy: 0.3182\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6900 - accuracy: 0.5210 - val_loss: 0.6799 - val_accuracy: 0.3636\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 7s 209ms/step - loss: 0.6887 - accuracy: 0.5190 - val_loss: 0.6415 - val_accuracy: 0.3580\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6872 - accuracy: 0.5170 - val_loss: 0.6546 - val_accuracy: 0.3523\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6816 - accuracy: 0.5090 - val_loss: 0.6212 - val_accuracy: 0.5909\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6802 - accuracy: 0.5269 - val_loss: 0.6284 - val_accuracy: 0.3750\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6770 - accuracy: 0.5549 - val_loss: 0.6545 - val_accuracy: 0.3523\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6714 - accuracy: 0.5749 - val_loss: 0.6020 - val_accuracy: 0.8011\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6686 - accuracy: 0.6008 - val_loss: 0.6124 - val_accuracy: 0.7102\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 7s 209ms/step - loss: 0.6675 - accuracy: 0.6128 - val_loss: 0.6061 - val_accuracy: 0.7216\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 7s 208ms/step - loss: 0.6617 - accuracy: 0.6587 - val_loss: 0.6342 - val_accuracy: 0.3920\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6638 - accuracy: 0.6387 - val_loss: 0.6289 - val_accuracy: 0.4091\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 7s 209ms/step - loss: 0.6570 - accuracy: 0.6547 - val_loss: 0.5929 - val_accuracy: 0.6420\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 7s 218ms/step - loss: 0.6551 - accuracy: 0.7046 - val_loss: 0.5989 - val_accuracy: 0.5170\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 0.6528 - accuracy: 0.6846 - val_loss: 0.5870 - val_accuracy: 0.6989\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6503 - accuracy: 0.6806 - val_loss: 0.5900 - val_accuracy: 0.6534\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6469 - accuracy: 0.7046 - val_loss: 0.5990 - val_accuracy: 0.5966\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6432 - accuracy: 0.7006 - val_loss: 0.5855 - val_accuracy: 0.6420\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 7s 209ms/step - loss: 0.6438 - accuracy: 0.7425 - val_loss: 0.5860 - val_accuracy: 0.6932\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6357 - accuracy: 0.7505 - val_loss: 0.5595 - val_accuracy: 0.8182\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6359 - accuracy: 0.7565 - val_loss: 0.5842 - val_accuracy: 0.6761\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6316 - accuracy: 0.7645 - val_loss: 0.5875 - val_accuracy: 0.6307\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.6369 - accuracy: 0.7605 - val_loss: 0.5675 - val_accuracy: 0.8182\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6279 - accuracy: 0.7745 - val_loss: 0.5733 - val_accuracy: 0.6477\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6305 - accuracy: 0.7665 - val_loss: 0.5560 - val_accuracy: 0.8182\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6310 - accuracy: 0.7844 - val_loss: 0.5626 - val_accuracy: 0.7670\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6209 - accuracy: 0.8283 - val_loss: 0.5661 - val_accuracy: 0.6932\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 7s 207ms/step - loss: 0.6181 - accuracy: 0.7964 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6183 - accuracy: 0.8204 - val_loss: 0.5578 - val_accuracy: 0.7898\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6195 - accuracy: 0.7984 - val_loss: 0.5681 - val_accuracy: 0.6875\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6186 - accuracy: 0.7964 - val_loss: 0.5567 - val_accuracy: 0.7955\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6147 - accuracy: 0.8383 - val_loss: 0.5515 - val_accuracy: 0.8409\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 7s 214ms/step - loss: 0.6114 - accuracy: 0.8343 - val_loss: 0.5620 - val_accuracy: 0.6875\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6171 - accuracy: 0.8184 - val_loss: 0.5565 - val_accuracy: 0.8125\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6110 - accuracy: 0.8363 - val_loss: 0.5348 - val_accuracy: 0.8750\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6138 - accuracy: 0.8164 - val_loss: 0.5649 - val_accuracy: 0.7614\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6100 - accuracy: 0.8224 - val_loss: 0.5419 - val_accuracy: 0.8352\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.6001 - accuracy: 0.8563 - val_loss: 0.5445 - val_accuracy: 0.8068\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.6050 - accuracy: 0.8543 - val_loss: 0.5436 - val_accuracy: 0.8239\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 7s 213ms/step - loss: 0.6050 - accuracy: 0.8363 - val_loss: 0.5451 - val_accuracy: 0.7955\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6072 - accuracy: 0.8443 - val_loss: 0.5486 - val_accuracy: 0.7784\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 0.5973 - accuracy: 0.8583 - val_loss: 0.5408 - val_accuracy: 0.8068\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 7s 214ms/step - loss: 0.5951 - accuracy: 0.8583 - val_loss: 0.5391 - val_accuracy: 0.8239\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.6026 - accuracy: 0.8403 - val_loss: 0.5336 - val_accuracy: 0.8466\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.5980 - accuracy: 0.8443 - val_loss: 0.5417 - val_accuracy: 0.7955\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 7s 211ms/step - loss: 0.5970 - accuracy: 0.8523 - val_loss: 0.5287 - val_accuracy: 0.8068\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.5955 - accuracy: 0.8503 - val_loss: 0.5287 - val_accuracy: 0.8523\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.5954 - accuracy: 0.8623 - val_loss: 0.5244 - val_accuracy: 0.8466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD7VUfm7PpgE",
        "colab_type": "code",
        "outputId": "5b2ed9d0-06c5-479e-97bc-0da4b98e88d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Will now try to do a fine tunning of the model\n",
        "# length of the layers \n",
        "len(resnet.layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2SiIypEXbsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tune_after = 176 -10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys_VN-2xYIx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making all the layers trainable first\n",
        "resnet.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im-2lWxMUsxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# going to fine tune the last 10 layers \n",
        "# Those that are before this point are set to not trainable\n",
        "for layer in resnet.layers[:tune_after]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kb95R-XZNtT",
        "colab_type": "code",
        "outputId": "012eb95d-f5ae-4827-d235-7e9a57015f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 3,416,576\n",
            "Non-trainable params: 20,171,136\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7udYgcQ0ZT6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making two layers that will be trainable also\n",
        "myDense_1 = Dense(1024, activation=\"relu\")\n",
        "myDense_2 = Dense(1, activation=\"sigmoid\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn-HghUEU6EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Will now rebuilt the model\n",
        "fineTunedModel = Sequential([resnet,  onlyOutPut])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofddoN2EZ1sB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now doing the compilation of the model\n",
        "fineTunedModel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4QnXtitj6NS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a callback to do early stopping\n",
        "myCallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LHk03wNUVRd",
        "colab_type": "code",
        "outputId": "47a80fc2-b9b0-4036-d0a8-f2f0649dccc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "# Training the model that has just the last 10 layers of the resnet \n",
        "# that can be trained.\n",
        "fineTunedModel.fit(train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size, \n",
        "    callbacks = [myCallback]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 8s 247ms/step - loss: 0.6648 - accuracy: 0.6228 - val_loss: 0.6192 - val_accuracy: 0.4943\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.6176 - accuracy: 0.7924 - val_loss: 0.5652 - val_accuracy: 0.8295\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.5917 - accuracy: 0.8403 - val_loss: 0.5343 - val_accuracy: 0.9261\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.5671 - accuracy: 0.8862 - val_loss: 0.5454 - val_accuracy: 0.8295\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.5756 - accuracy: 0.8703 - val_loss: 0.5248 - val_accuracy: 0.8636\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.5611 - accuracy: 0.9022 - val_loss: 0.5730 - val_accuracy: 0.7614\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.5639 - accuracy: 0.8782 - val_loss: 0.5020 - val_accuracy: 0.9318\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.5540 - accuracy: 0.9082 - val_loss: 0.5284 - val_accuracy: 0.8466\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.5553 - accuracy: 0.9002 - val_loss: 0.4969 - val_accuracy: 0.9318\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.5468 - accuracy: 0.9142 - val_loss: 0.5582 - val_accuracy: 0.8125\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.5564 - accuracy: 0.9002 - val_loss: 0.5283 - val_accuracy: 0.8750\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 7s 219ms/step - loss: 0.5494 - accuracy: 0.9102 - val_loss: 0.5194 - val_accuracy: 0.8750\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.5490 - accuracy: 0.9242 - val_loss: 0.4878 - val_accuracy: 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f63ce9a5128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5MLMRkG35OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is doing just the classification using the just the resnet model \n",
        "# with no other changes to the model\n",
        "results = resnet.predict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUcpzA6MO7nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td0Dl6RT_WL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeN0FuLra7xu",
        "colab_type": "text"
      },
      "source": [
        "# Custom CNN Model\n",
        "\n",
        "In this step, write and train your own convolutional neural network using Keras. You can use any architecture that suits you as long as it has at least one convolutional and one pooling layer at the beginning of the network - you can add more if you want. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zjB_h5gAeQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Doing some imports\n",
        "from tensorflow.keras.layers import Conv2D, Dense\n",
        "from tensorflow.keras.layers import ZeroPadding2D , BatchNormalization, GlobalAveragePooling2D, MaxPool2D, InputLayer, ReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex83Y3Y06awJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theModel = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMZvZyH6fj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theModel.add(Conv2D(64, (3,3), padding=\"same\", input_shape=(224,224,3)))\n",
        "theModel.add(BatchNormalization())\n",
        "theModel.add(ReLU())\n",
        "theModel.add(ZeroPadding2D(padding=(2,2)))\n",
        "theModel.add(MaxPool2D(pool_size=(2,2)))\n",
        "theModel.add(Conv2D(32, (3,3), padding=\"same\"))\n",
        "theModel.add(BatchNormalization())\n",
        "theModel.add(ReLU())\n",
        "theModel.add(Conv2D(32, (3,3), padding=\"same\"))\n",
        "theModel.add(BatchNormalization())\n",
        "theModel.add(ReLU())\n",
        "theModel.add(GlobalAveragePooling2D())\n",
        "theModel.add(Dense(1, activation=\"sigmoid\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkgLfoJc9jRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Doing the compilation\n",
        "theModel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGEYmsbyC3Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "6dee9784-ed94-4a44-ea15-9d6366697d4b"
      },
      "source": [
        "theModel.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "re_lu_27 (ReLU)              (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPaddi (None, 228, 228, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 114, 114, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 114, 114, 32)      18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 114, 114, 32)      128       \n",
            "_________________________________________________________________\n",
            "re_lu_28 (ReLU)              (None, 114, 114, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 114, 114, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 114, 114, 32)      128       \n",
            "_________________________________________________________________\n",
            "re_lu_29 (ReLU)              (None, 114, 114, 32)      0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 30,049\n",
            "Trainable params: 29,793\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvEtMPpc9Mi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0d7c894-ef1e-4a1c-e0b0-2130c444d46c"
      },
      "source": [
        "history = theModel.fit(train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size, \n",
        "    #callbacks = [myCallback]\n",
        "    )"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 7s 233ms/step - loss: 0.6424 - accuracy: 0.7086 - val_loss: 0.6499 - val_accuracy: 0.6080\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.6165 - accuracy: 0.8363 - val_loss: 0.6423 - val_accuracy: 0.6648\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.6032 - accuracy: 0.8603 - val_loss: 0.6590 - val_accuracy: 0.6420\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 7s 223ms/step - loss: 0.5945 - accuracy: 0.8723 - val_loss: 0.6570 - val_accuracy: 0.6477\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5927 - accuracy: 0.8962 - val_loss: 0.6642 - val_accuracy: 0.6420\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5881 - accuracy: 0.8962 - val_loss: 0.6602 - val_accuracy: 0.6477\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5911 - accuracy: 0.8922 - val_loss: 0.6557 - val_accuracy: 0.6534\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5881 - accuracy: 0.9062 - val_loss: 0.6614 - val_accuracy: 0.6477\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5788 - accuracy: 0.9042 - val_loss: 0.6615 - val_accuracy: 0.6477\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5781 - accuracy: 0.8942 - val_loss: 0.6460 - val_accuracy: 0.6648\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5752 - accuracy: 0.9202 - val_loss: 0.6614 - val_accuracy: 0.6477\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 7s 223ms/step - loss: 0.5786 - accuracy: 0.9301 - val_loss: 0.6605 - val_accuracy: 0.6477\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5755 - accuracy: 0.9242 - val_loss: 0.6349 - val_accuracy: 0.6761\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5750 - accuracy: 0.9242 - val_loss: 0.6378 - val_accuracy: 0.6705\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 7s 222ms/step - loss: 0.5769 - accuracy: 0.9281 - val_loss: 0.6589 - val_accuracy: 0.6477\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5711 - accuracy: 0.8962 - val_loss: 0.6458 - val_accuracy: 0.6591\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5737 - accuracy: 0.9222 - val_loss: 0.6428 - val_accuracy: 0.6591\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5743 - accuracy: 0.9142 - val_loss: 0.6338 - val_accuracy: 0.6648\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5723 - accuracy: 0.9316 - val_loss: 0.6477 - val_accuracy: 0.6477\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5689 - accuracy: 0.9242 - val_loss: 0.6380 - val_accuracy: 0.6648\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5703 - accuracy: 0.9182 - val_loss: 0.6115 - val_accuracy: 0.7216\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 7s 222ms/step - loss: 0.5680 - accuracy: 0.9182 - val_loss: 0.6333 - val_accuracy: 0.6591\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5669 - accuracy: 0.9301 - val_loss: 0.6277 - val_accuracy: 0.6932\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5685 - accuracy: 0.9122 - val_loss: 0.6245 - val_accuracy: 0.6989\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5688 - accuracy: 0.9258 - val_loss: 0.6213 - val_accuracy: 0.6989\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 7s 223ms/step - loss: 0.5675 - accuracy: 0.9202 - val_loss: 0.6225 - val_accuracy: 0.6818\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5635 - accuracy: 0.9301 - val_loss: 0.6146 - val_accuracy: 0.6989\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5657 - accuracy: 0.9341 - val_loss: 0.6064 - val_accuracy: 0.7159\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5664 - accuracy: 0.9301 - val_loss: 0.6183 - val_accuracy: 0.7216\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5642 - accuracy: 0.9281 - val_loss: 0.6112 - val_accuracy: 0.7045\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 7s 222ms/step - loss: 0.5668 - accuracy: 0.9162 - val_loss: 0.6124 - val_accuracy: 0.6932\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 7s 223ms/step - loss: 0.5686 - accuracy: 0.9122 - val_loss: 0.6139 - val_accuracy: 0.7102\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.5572 - accuracy: 0.9361 - val_loss: 0.6038 - val_accuracy: 0.7273\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5593 - accuracy: 0.9461 - val_loss: 0.6299 - val_accuracy: 0.6875\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 7s 225ms/step - loss: 0.5585 - accuracy: 0.9461 - val_loss: 0.6221 - val_accuracy: 0.6989\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5673 - accuracy: 0.9022 - val_loss: 0.6171 - val_accuracy: 0.6932\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 7s 223ms/step - loss: 0.5634 - accuracy: 0.9242 - val_loss: 0.6155 - val_accuracy: 0.7216\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 7s 223ms/step - loss: 0.5624 - accuracy: 0.9162 - val_loss: 0.6151 - val_accuracy: 0.7045\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5656 - accuracy: 0.9222 - val_loss: 0.6145 - val_accuracy: 0.7102\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5591 - accuracy: 0.9401 - val_loss: 0.6222 - val_accuracy: 0.7045\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5615 - accuracy: 0.9321 - val_loss: 0.6080 - val_accuracy: 0.7045\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5606 - accuracy: 0.9261 - val_loss: 0.5939 - val_accuracy: 0.7102\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5613 - accuracy: 0.9321 - val_loss: 0.6222 - val_accuracy: 0.6989\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5613 - accuracy: 0.9341 - val_loss: 0.5981 - val_accuracy: 0.7443\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5592 - accuracy: 0.9481 - val_loss: 0.6257 - val_accuracy: 0.6818\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5566 - accuracy: 0.9401 - val_loss: 0.6047 - val_accuracy: 0.7159\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5585 - accuracy: 0.9441 - val_loss: 0.6180 - val_accuracy: 0.6932\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5629 - accuracy: 0.9182 - val_loss: 0.6219 - val_accuracy: 0.6989\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.5592 - accuracy: 0.9453 - val_loss: 0.6313 - val_accuracy: 0.6875\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5594 - accuracy: 0.9301 - val_loss: 0.6071 - val_accuracy: 0.7386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ9FS2UyGE_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theModel = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Thc_Vb2Fol-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Will try the model again but add 2 Dense layers\n",
        "theModel.add(Conv2D(64, (3,3), padding=\"same\", input_shape=(224,224,3)))\n",
        "theModel.add(BatchNormalization())\n",
        "theModel.add(ReLU())\n",
        "theModel.add(ZeroPadding2D(padding=(2,2)))\n",
        "theModel.add(MaxPool2D(pool_size=(2,2)))\n",
        "theModel.add(Conv2D(32, (3,3), padding=\"same\"))\n",
        "theModel.add(BatchNormalization())\n",
        "theModel.add(ReLU())\n",
        "theModel.add(Conv2D(32, (3,3), padding=\"same\"))\n",
        "theModel.add(BatchNormalization())\n",
        "theModel.add(ReLU())\n",
        "theModel.add(GlobalAveragePooling2D())\n",
        "theModel.add(Dense(64, activation=\"relu\"))\n",
        "theModel.add(Dense(64, activation=\"relu\"))\n",
        "theModel.add(Dense(1, activation=\"sigmoid\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR93Qwhsa7xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model\n",
        "theModel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNpAT9z2a7x2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c5656be-ef56-46d8-e369-b106aed87dab"
      },
      "source": [
        "# Fit Model\n",
        "history = theModel.fit(train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size, \n",
        "    #callbacks = [myCallback]\n",
        "    )"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 8s 237ms/step - loss: 0.6951 - accuracy: 0.7944 - val_loss: 0.6447 - val_accuracy: 0.3693\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.6515 - accuracy: 0.8643 - val_loss: 0.6501 - val_accuracy: 0.6477\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.6255 - accuracy: 0.8862 - val_loss: 0.6428 - val_accuracy: 0.6591\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.6093 - accuracy: 0.8902 - val_loss: 0.6378 - val_accuracy: 0.6648\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5932 - accuracy: 0.9082 - val_loss: 0.6429 - val_accuracy: 0.6591\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 8s 239ms/step - loss: 0.5869 - accuracy: 0.9062 - val_loss: 0.6453 - val_accuracy: 0.6591\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5803 - accuracy: 0.9082 - val_loss: 0.6305 - val_accuracy: 0.6761\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5669 - accuracy: 0.9222 - val_loss: 0.6585 - val_accuracy: 0.6477\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5661 - accuracy: 0.9142 - val_loss: 0.6384 - val_accuracy: 0.6705\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5671 - accuracy: 0.9162 - val_loss: 0.6503 - val_accuracy: 0.6591\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 7s 234ms/step - loss: 0.5601 - accuracy: 0.9162 - val_loss: 0.6337 - val_accuracy: 0.6761\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5570 - accuracy: 0.9461 - val_loss: 0.6342 - val_accuracy: 0.6761\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5532 - accuracy: 0.9261 - val_loss: 0.6348 - val_accuracy: 0.6761\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.5570 - accuracy: 0.9222 - val_loss: 0.6559 - val_accuracy: 0.6534\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5474 - accuracy: 0.9501 - val_loss: 0.6394 - val_accuracy: 0.6705\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5461 - accuracy: 0.9421 - val_loss: 0.6490 - val_accuracy: 0.6591\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5429 - accuracy: 0.9381 - val_loss: 0.6684 - val_accuracy: 0.6420\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5453 - accuracy: 0.9453 - val_loss: 0.6525 - val_accuracy: 0.6591\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5390 - accuracy: 0.9481 - val_loss: 0.6603 - val_accuracy: 0.6477\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 7s 232ms/step - loss: 0.5438 - accuracy: 0.9481 - val_loss: 0.6646 - val_accuracy: 0.6477\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5417 - accuracy: 0.9521 - val_loss: 0.6498 - val_accuracy: 0.6591\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 7s 233ms/step - loss: 0.5388 - accuracy: 0.9421 - val_loss: 0.6440 - val_accuracy: 0.6591\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 8s 235ms/step - loss: 0.5419 - accuracy: 0.9381 - val_loss: 0.6102 - val_accuracy: 0.7216\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5454 - accuracy: 0.9561 - val_loss: 0.6225 - val_accuracy: 0.6875\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 0.5518 - accuracy: 0.9281 - val_loss: 0.6551 - val_accuracy: 0.6534\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 7s 233ms/step - loss: 0.5461 - accuracy: 0.9258 - val_loss: 0.6418 - val_accuracy: 0.6705\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5381 - accuracy: 0.9481 - val_loss: 0.6348 - val_accuracy: 0.6705\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5325 - accuracy: 0.9481 - val_loss: 0.6432 - val_accuracy: 0.6705\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5372 - accuracy: 0.9641 - val_loss: 0.6433 - val_accuracy: 0.6648\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5352 - accuracy: 0.9461 - val_loss: 0.6413 - val_accuracy: 0.6705\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.5302 - accuracy: 0.9531 - val_loss: 0.6589 - val_accuracy: 0.6534\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 7s 232ms/step - loss: 0.5400 - accuracy: 0.9361 - val_loss: 0.6469 - val_accuracy: 0.6591\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5419 - accuracy: 0.9461 - val_loss: 0.6544 - val_accuracy: 0.6534\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 7s 228ms/step - loss: 0.5354 - accuracy: 0.9521 - val_loss: 0.6497 - val_accuracy: 0.6591\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5365 - accuracy: 0.9501 - val_loss: 0.6272 - val_accuracy: 0.6818\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.5455 - accuracy: 0.9301 - val_loss: 0.6407 - val_accuracy: 0.6705\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5327 - accuracy: 0.9461 - val_loss: 0.6506 - val_accuracy: 0.6591\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5358 - accuracy: 0.9561 - val_loss: 0.6383 - val_accuracy: 0.6705\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.5383 - accuracy: 0.9361 - val_loss: 0.6455 - val_accuracy: 0.6591\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.5280 - accuracy: 0.9601 - val_loss: 0.6229 - val_accuracy: 0.6875\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5324 - accuracy: 0.9581 - val_loss: 0.6543 - val_accuracy: 0.6591\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5398 - accuracy: 0.9421 - val_loss: 0.6602 - val_accuracy: 0.6534\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 7s 233ms/step - loss: 0.5373 - accuracy: 0.9501 - val_loss: 0.6274 - val_accuracy: 0.6875\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5354 - accuracy: 0.9561 - val_loss: 0.6485 - val_accuracy: 0.6648\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 7s 234ms/step - loss: 0.5417 - accuracy: 0.9297 - val_loss: 0.6485 - val_accuracy: 0.6648\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 7s 232ms/step - loss: 0.5364 - accuracy: 0.9481 - val_loss: 0.6377 - val_accuracy: 0.6705\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5408 - accuracy: 0.9361 - val_loss: 0.6362 - val_accuracy: 0.6705\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 7s 230ms/step - loss: 0.5404 - accuracy: 0.9441 - val_loss: 0.6503 - val_accuracy: 0.6591\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 7s 232ms/step - loss: 0.5300 - accuracy: 0.9541 - val_loss: 0.6469 - val_accuracy: 0.6648\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 7s 231ms/step - loss: 0.5391 - accuracy: 0.9401 - val_loss: 0.6464 - val_accuracy: 0.6648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xQGz7Cya7x5",
        "colab_type": "text"
      },
      "source": [
        "# Custom CNN Model with Image Manipulations\n",
        "\n",
        "To simulate an increase in a sample of image, you can apply image manipulation techniques: cropping, rotation, stretching, etc. Luckily Keras has some handy functions for us to apply these techniques to our mountain and forest example. Simply, you should be able to modify our image generator for the problem. Check out these resources to help you get started: \n",
        "\n",
        "1. [Keras `ImageGenerator` Class](https://keras.io/preprocessing/image/#imagedatagenerator-class)\n",
        "2. [Building a powerful image classifier with very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbcLuJFxa7x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "# Resources and Stretch Goals\n",
        "\n",
        "Stretch goals\n",
        "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
        "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
        "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
        "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
        "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
        "\n",
        "Resources\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
        "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
        "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
        "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
        "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
      ]
    }
  ]
}