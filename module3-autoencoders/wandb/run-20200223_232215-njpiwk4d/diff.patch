nbdiff /tmp/0OnN86_LS_DS_431_RNN_and_LSTM_Assignment.ipynb module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb
--- /tmp/0OnN86_LS_DS_431_RNN_and_LSTM_Assignment.ipynb  2020-02-23 23:22:15.834367
+++ module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb  2020-02-20 00:00:41.903914
[34m## inserted before /cells/1:[0m
[32m+  code cell:
[32m+    execution_count: 1
[32m+    source:
[32m+      import re
[32m+      import numpy as np
[32m+      import random
[32m+      import sys
[32m+      import os
[32m+      
[32m+      from __future__ import print_function
[32m+      
[32m+      from tensorflow.keras.callbacks import LambdaCallback
[32m+      from tensorflow.keras.models import Sequential
[32m+      from tensorflow.keras.layers import Dense, LSTM
[32m+      from tensorflow.keras.optimizers import RMSprop
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stderr
[32m+        text:
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+          /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+            np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m+  code cell:
[32m+    execution_count: 2
[32m+    metadata (unknown keys):
[32m+      colab:
[32m+      colab_type: code
[32m+      id: Ltj1je1fp5rO
[32m+    source:
[32m+      # !wget https://www.gutenberg.org/files/100/100-0.txt
[32m+  code cell:
[32m+    execution_count: 32
[32m+    source:
[32m+      text = open('100-0.txt', 'r', encoding='utf-8')
[32m+      text_clean = text.read()
[32m+      
[32m+      char_scrub = ['\n','\d+', r'\W+(?!\S*[a-z])|(?<!\S)\W+','    ', '   ', '  ']
[32m+      
[32m+      for char in char_scrub:
[32m+          text_clean = re.sub(char, ' ', text_clean)
[32m+          
[32m+      end = len(text_clean)-20245
[32m+          
[32m+      text_clean = text_clean[1985:end]
[32m+      
[32m+      sonnets = text_clean[:90968]
[32m+      
[32m+      plays = text_clean[90968:]
[32m+  code cell:
[32m+    execution_count: 33
[32m+    source:
[32m+      # Create the Sequence Data for sonnets
[32m+      
[32m+      def sequence_data():
[32m+          
[32m+          chars = list(set(data))
[32m+      
[32m+          char_int = {c:i for i,c in enumerate(chars)}
[32m+          int_char = {i:c for i,c in enumerate(chars)}
[32m+      
[32m+          
[32m+          
[32m+      
[32m+          encoded = [char_int[c] for c in data]
[32m+      
[32m+          sequences = [] #each element 60 chars long
[32m+          next_chars = [] #one element for each sequence
[32m+      
[32m+          for i in range(0, len(encoded)-maxlen, step):
[32m+              sequences.append(encoded[i : i+maxlen])
[32m+              next_chars.append(encoded[i+maxlen])
[32m+      
[32m+          print(f'sequences: {len(sequences)}')
[32m+          
[32m+          x = np.zeros((len(sequences), maxlen, len(chars)), dtype = np.bool)
[32m+          y = np.zeros((len(sequences), len(chars)), dtype = np.bool)
[32m+      
[32m+          for i, sequence in enumerate(sequences):
[32m+              for t, char in enumerate(sequence):
[32m+                  x[i,t,char] = 1
[32m+      
[32m+              y[i, next_chars[i]] = 1
[32m+          
[32m+          return chars, x, y, char_int, int_char
[32m+  code cell:
[32m+    execution_count: 34
[32m+    source:
[32m+      def sample(preds, temperature=1.0):
[32m+          # helper function to sample an index from a probability array
[32m+          preds = np.asarray(preds).astype('float64')
[32m+          preds = np.log(preds) / temperature
[32m+          exp_preds = np.exp(preds)
[32m+          preds = exp_preds / np.sum(exp_preds)
[32m+          probas = np.random.multinomial(1, preds, 1)
[32m+          return np.argmax(probas)
[32m+  code cell:
[32m+    execution_count: 42
[32m+    source:
[32m+      def on_epoch_end(epoch, _):
[32m+          # Function invoked at end of each epoch. Prints generated text.
[32m+          if epoch %5 ==0:
[32m+              print()
[32m+              print('----- Generating text after Epoch: %d' % epoch)
[32m+      
[32m+              start_index = random.randint(0, len(data) - maxlen - 1)
[32m+              for diversity in [0.2, 0.5, 1.0, 1.2]:
[32m+                  print('----- diversity:', diversity)
[32m+      
[32m+                  generated = ''
[32m+                  sentence = data[start_index: start_index + maxlen]
[32m+                  generated += sentence
[32m+                  print('----- Generating with seed: "' + sentence + '"')
[32m+                  sys.stdout.write(generated)
[32m+      
[32m+                  for i in range(400):
[32m+                      x_pred = np.zeros((1, maxlen, len(chars)))
[32m+                      for t, char in enumerate(sentence):
[32m+                          x_pred[0, t, char_int[char]] = 1.
[32m+      
[32m+                      preds = model.predict(x_pred, verbose=0)[0]
[32m+                      next_index = sample(preds, diversity)
[32m+                      next_char = int_char[next_index]
[32m+      
[32m+                      sentence = sentence[1:] + next_char
[32m+      
[32m+                      sys.stdout.write(next_char)
[32m+                      sys.stdout.flush()
[32m+                  print()
[32m+              else: pass
[32m+  code cell:
[32m+    execution_count: 43
[32m+    source:
[32m+      #sonnet lstm
[32m+      
[32m+      maxlen = 100
[32m+      step = 5
[32m+      data = sonnets
[32m+      
[32m+      chars, x, y, char_int, int_char = sequence_data()
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          sequences: 18174
[32m+  code cell:
[32m+    execution_count: 44
[32m+    source:
[32m+      # build the model: a single LSTM
[32m+              
[32m+      model = Sequential()
[32m+      
[32m+      model.add(LSTM(128, input_shape=(maxlen, len(chars))))
[32m+      model.add(Dense(len(chars), activation = 'softmax')) #softmax used because multiclass 
[32m+      
[32m+      model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')
[32m+      
[32m+      print_callback = LambdaCallback(on_epoch_end=on_epoch_end)
[32m+          
[32m+      model.fit(x, y,
[32m+                batch_size=128,
[32m+                epochs=25,
[32m+                callbacks=[print_callback])
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          Epoch 1/25
[32m+          18048/18174 [============================>.] - ETA: 0s - loss: 3.0181
[32m+          ----- Generating text after Epoch: 0
[32m+          ----- diversity: 0.2
[32m+          ----- Generating with seed: "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his"
[32m+          d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his   t  e h t   t  t   o   e        t  ee    he e    a    e t  e s s  ae t   e  e   e   t he    h h  e  e  a  e  s  ee  e  oe e   o      e   h   h h e t   t    e  e       t  t h   s oe  e e    e  t o  t t    t   t e e h  r e      h     o e     e  o e  t   s h r   t    o  s   e s   t     a    t  t   t   e  t      h  t  e e ee     e    t  t    e th   t  h  e   e   e n t  o e t  e e  t  e  ot  e  s  h 
[32m+          ----- diversity: 0.5
[32m+          ----- Generating with seed: "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his"
[32m+          d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his e ea e eeos st taoae re ra ai  hoatr  eu a tune oh ant  ue e haw et  n  t   s eert htahe   hoero  or  oooo hn epc’  n n  ayeh n  ah t ts rh h t eto  s ue oehs ret  w  t yer h w    to h oeee    r h s  y oe   otonns aterhte h t e  s  t tyoote r oe o   et wml  d oe h h oe t  tse teesh tmi  oi aiot ot het n m  ties h t ai et h d twt  mh eie e eare     h  h e e s ea t aeo s n oe  u  nt  ts  rnmt m h a
[32m+          ----- diversity: 1.0
[32m+          ----- Generating with seed: "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his"
[32m+          d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from hish atg wh a w’lh mhfiod thped out sAdun aern’g ho e  Te fhcdorwcL a  pt  areInautl  su vthhr   ypnla ab rthoe h  e l sositna opunadarsaPiOdrs p f eerrk fbhes ysaa hg iticte  s oeoy amodItoeAmiaoesdlchdh uru chhth tr toysea iOd glo lffuyohrr i nvewnn Shhi ej wcldhea-s tegr mwent  le Y ohitvs es on lh d ritenetoa d oeAdlrh  l  ecs u mebe hegh Ii oPafpbMvielee ig nhhsIohhwh  n  igye  tae  drlemeshy my
[32m+          ----- diversity: 1.2
[32m+          ----- Generating with seed: "d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from his"
[32m+          d Since first I saw you fresh which yet are green Ah yet doth beauty like a dial hand Steal from hisctidhl metl   o  Bkae gee Hft-idvyracwrch iu Wn vstedvrnttsitWhatbhhvnenlsrlstwytn riTeis lu r hteahay onLla egeymoFs td m ths n vA oztNcuaiucaaYt atea ha e ow itl rs oTuwan  ercekh-ooyttn r   dnkdra te’ uIdtdpe hrn  sCt  k htouyltide hiuoB otytvE tmtcruengeg ohish eeu lhs   ftsf taeknsiuasomfosp   sgeodaaos fmsdsthwei t hedppTnootmlhd tq mheypuetaluaiEy av vhere  hnngeaalrttu t s ryyotao uFpgsyIe
[32m+          18174/18174 [==============================] - 37s 2ms/sample - loss: 3.0172
[32m+          Epoch 2/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 2.7473
[32m+          Epoch 3/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 2.5167
[32m+          Epoch 4/25
[32m+          18174/18174 [==============================] - 14s 772us/sample - loss: 2.3803
[32m+          Epoch 5/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 2.2983
[32m+          Epoch 6/25
[32m+          18048/18174 [============================>.] - ETA: 0s - loss: 2.2384
[32m+          ----- Generating text after Epoch: 5
[32m+          ----- diversity: 0.2
[32m+          ----- Generating with seed: "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l"
[32m+          gone Who all their parts of me to thee did give That due of many now is thine alone Their images I lor she the that the she the the thou shat the the that the the the that that that the the the seat the the thou the thas that the that that the the seat hat the that the than and shes the the the the se the more the the she son the that the ther sor that she the that the she the seat the that the the the the the seat tho her wime the the that that the the sin the the thas tho that the shat the she
[32m+          ----- diversity: 0.5
[32m+          ----- Generating with seed: "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l"
[32m+          gone Who all their parts of me to thee did give That due of many now is thine alone Their images I lite that thas I theve so than The thor that nin thin me firo ar the sey than she an thar ron that thee sout erath oul seat sres hou has  hou thich won wirg fore dis that ar ther thor thy that I dome thou hee thar For nor share An the thit in wor tron mis oul no seal that the than of mhin the boing sowe sor sove not thal me sor fore no thas deve rove snther on thar daat my mis ot the sing ho theat 
[32m+          ----- diversity: 1.0
[32m+          ----- Generating with seed: "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l"
[32m+          gone Who all their parts of me to thee did give That due of many now is thine alone Their images I loik ha camed Mevr npev no solalg seong ingke joute’n Ie th uh wiyl shan-tuns beer ans thaM hraislwsesed lor roras that Th seist Whan douring pno soos ay thesrinr awfregheiragdeOt gor lar ploth nere fit beirn lhent ink Braks cay wat deougthaofer an Sho foalth oor thats seogherin Fnatris dubf tnot thath mnesiclis thok ffade Af tout nyeusen Or yy palt AncwnHus ghov my wils of yovere parte ans wirmad 
[32m+          ----- diversity: 1.2
[32m+          ----- Generating with seed: "gone Who all their parts of me to thee did give That due of many now is thine alone Their images I l"
[32m+          gone Who all their parts of me to thee did give That due of many now is thine alone Their images I laclere thiod gtinge aldlg-bett he Love  in tih mla th I chouth holr tawsgut Oikinn thotheustat xhon crere sallI r ok waturgirn gear lp them Shtsev ohnvr blsin youed y ingos anst on bes in ay ’y sif il Of o llawed iftpith thind’n love Thoct fich Amkem farleptror bekfin wreass’vs thy I pnrees shoIsss loshen wovendharx phare whal twyer ind fnot th Thatutq pllcer aihs ’ls suwhou dowemt aks ortivegt Mi
[32m+          18174/18174 [==============================] - 37s 2ms/sample - loss: 2.2386
[32m+          Epoch 7/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 2.1978
[32m+          Epoch 8/25
[32m+          18174/18174 [==============================] - 14s 786us/sample - loss: 2.1523
[32m+          Epoch 9/25
[32m+          18174/18174 [==============================] - 14s 769us/sample - loss: 2.1174
[32m+          Epoch 10/25
[32m+          18174/18174 [==============================] - 14s 770us/sample - loss: 2.0815
[32m+          Epoch 11/25
[32m+          18048/18174 [============================>.] - ETA: 0s - loss: 2.0562
[32m+          ----- Generating text after Epoch: 10
[32m+          ----- diversity: 0.2
[32m+          ----- Generating with seed: "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And "
[32m+          rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And the sear the seare the seare the what the sear thou hat the will she the seed the the seath the the sear the wire the will sear so hear thou hor thee thou have Thou hat thou hin the will see the the sear thou hear the wire that me the sore the will seall not the sear that wind the that the wire the more thou hor the sear so love stoul the wore the sear the so the seer thou hath the hat the seart t
[32m+          ----- diversity: 0.5
[32m+          ----- Generating with seed: "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And "
[32m+          rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And be thou hins if the sear the seale ale thou have thee werlise so love thou hat the so live ming thiu seand shear dout wort ron the what my sill thou fald sill the forll thou hin tith thou han thou hive beall That  ar wars And dile and seathe butring tho sheat thou in the that the are that what fare Whou thie thou shand gith than forthe sool that in thou hor love in thut ohe whing and ou thy shees 
[32m+          ----- diversity: 1.0
[32m+          ----- Generating with seed: "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And "
[32m+          rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And mosf aniwh-pyetcfor besuve Why e cared so pe rave rof Siow Hale Why hibseel’s shalpitl dedscive ile hy eothled seam Th Nouf cenot For grall weery Meabesth ghitl ig toa thaun then apr I bererive Aod and All ail thae tfor cpout eak’s I Han Is ersoul to net antes of endny ais war may forniege caiurnighar ledevI ald my af-ore deerigh serle sur wool shoum suf limlle ter on sims elli’s nor roch tay sfol
[32m+          ----- diversity: 1.2
[32m+          ----- Generating with seed: "rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And "
[32m+          rongfully disgraced And strength by limping sway disabled And art made tongue-tied by authority And in bnom moneO be I ar my sisheL fnotowh thy ore frenoud heprin TereoR indhhon ssewjlr i’ phill per’se Fo pearary Glam vime ala by fonds cerarisp Ixuunl for lise Tolj asthor Formy faserild Svettartand Wor Ar’ losmy’s fea cert sfor Olae the meter Tiwher Dinus inwnechzen iq wom wiye wrise hhou lliowis mo el womk what lin peith eest’pe tro hece Whemill halmaSt ond forprer-Loto s earpouratrof oo soavpi
[32m+          18174/18174 [==============================] - 37s 2ms/sample - loss: 2.0547
[32m+          Epoch 12/25
[32m+          18174/18174 [==============================] - 14s 774us/sample - loss: 2.0322
[32m+          Epoch 13/25
[32m+          18174/18174 [==============================] - 14s 779us/sample - loss: 2.0034
[32m+          Epoch 14/25
[32m+          18174/18174 [==============================] - 14s 770us/sample - loss: 1.9818
[32m+          Epoch 15/25
[32m+          18174/18174 [==============================] - 14s 774us/sample - loss: 1.9623
[32m+          Epoch 16/25
[32m+          18048/18174 [============================>.] - ETA: 0s - loss: 1.9405
[32m+          ----- Generating text after Epoch: 15
[32m+          ----- diversity: 0.2
[32m+          ----- Generating with seed: "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov"
[32m+          which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my love The what the seat the thou hath the the thou hare the what the wher what the worl whee the seat the that hin the seath the she the the me the seath the seald the shang the seat the bear she the wher the the so the what the sow the singe the seat the seat the sean the see the wore the seath the seant the seal The the seat the seal The shath be the shath the seat of the sowe the will The what the 
[32m+          ----- diversity: 0.5
[32m+          ----- Generating with seed: "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov"
[32m+          which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my love so hor deat as my live my sull doth the to the shen the for that my ereath that thee But my seart And bith and mo not the wirl and pela the not with buth thee in the love Thou hand And thy shath deart for the him that thou that thee worth do then thee To deare shat loth my see the hear And hes the so thee whing the mant in my seat What tham me To thy stat thou that farl in me dath you thy for he
[32m+          ----- diversity: 1.0
[32m+          ----- Generating with seed: "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov"
[32m+          which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my loved that wiot Af thy theur fwicr wils ding And wheid ofster ow pryat wild thas showneus arn ewtir ald with ard Ths cupe dumeinl to trees afa hime wollls fod thes be oss whe thy priek on though Mirm wat theur -wind I futh will An thee to to the ceerwovy and moms fayer mughain and mn gothing hoo to be my boulfichingse I and for the dovgled me windy und berume porpand Anped breime ating shangh’st be t
[32m+          ----- diversity: 1.2
[32m+          ----- Generating with seed: "which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my lov"
[32m+          which doth preserve the ill Th uncertain sickly appetite to please My reason the physician to my love dessool yeagh PEt iHy hing comisg an fwill wide nind ne waur I aft cto fouthth lich mmyey ws mpanst showjy prymise hacr daswolis in you world poum of thys wathO thyung somind Nupe andess in thou youfutrfest desy purGd mpathe thim Nslind Fre cdraccesoth wereds swers mabit nMe ant prich hive oon not lovamgmastest silqut shaut Nonnpiqklact in when I what miisen thine thas muse be Tome seshels rajen
[32m+          18174/18174 [==============================] - 37s 2ms/sample - loss: 1.9395
[32m+          Epoch 17/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 1.9220
[32m+          Epoch 18/25
[32m+          18174/18174 [==============================] - 14s 771us/sample - loss: 1.9048
[32m+          Epoch 19/25
[32m+          18174/18174 [==============================] - 14s 774us/sample - loss: 1.8874
[32m+          Epoch 20/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 1.8679
[32m+          Epoch 21/25
[32m+          18048/18174 [============================>.] - ETA: 0s - loss: 1.8549
[32m+          ----- Generating text after Epoch: 20
[32m+          ----- diversity: 0.2
[32m+          ----- Generating with seed: "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star"
[32m+          m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling stare see the seat the sear steer stoul stere the sear do doth the seat the the fored that the seat my sear the seat the sear stoul see the seed the seart the seat of the sear ded the sear seart the seast the seal sear of the sear stees The hand that the sear steer the sear the mese the sear steed the some that me see the sear the dost the see the sean the sear stand steer that the seat to the sear st
[32m+          ----- diversity: 0.5
[32m+          ----- Generating with seed: "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star"
[32m+          m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling stare se frow in the and sean she the then pore For sheal s of thee the sail my not me bear of when thee for not bey the rowhed my see ned The doth Thou hand mo hase the seaut And my sear of thy sheer dseat my lost though sume the shange to thy sealt That me ere for which thine Non in kere I so for the thing of the me and and all seen my some The foret thee O love I so fer And the wert When sise the s
[32m+          ----- diversity: 1.0
[32m+          ----- Generating with seed: "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star"
[32m+          m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling stared er arce the redse ceiknor famew deds O lfon of my Is cowkes And sheagll spandsefedumugnd wollds zeast’or youlf can cands Long taper efar the mist prout To not whert end size def thein nemind omk Nor fake the ferling will Bat wave keof at dy to bkencu pearmen light and that to cond sear ofline Aratry seen Whend Songhr no my sead endse porinn go kilnge As the farec to yeren sing Is in thy loveee 
[32m+          ----- diversity: 1.2
[32m+          ----- Generating with seed: "m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star"
[32m+          m grace when clouds do blot the heaven So flatter I the swart-complexioned night When sparkling star dowess mads a to lavpnegh to beact Arm avs mant thee spact at mee wy gideteb-dowaPt uil my alasue houlqueaseS eirnts the galme’s piling time trint scen of h of Hnot Thou hase I Pald have so Lot fute ead dunuI theule alls post leako ben so p’nbe And end Why siglt youst O my heavtis Miys geare it one sake yacp andoy nonged ripgect fer fol byesed glys’nt bime te vemauves sane nem Whis ov’s wlof fbur
[32m+          18174/18174 [==============================] - 37s 2ms/sample - loss: 1.8545
[32m+          Epoch 22/25
[32m+          18174/18174 [==============================] - 14s 773us/sample - loss: 1.8370
[32m+          Epoch 23/25
[32m+          18174/18174 [==============================] - 14s 779us/sample - loss: 1.8233
[32m+          Epoch 24/25
[32m+          18174/18174 [==============================] - 14s 772us/sample - loss: 1.8057
[32m+          Epoch 25/25
[32m+          18174/18174 [==============================] - 14s 780us/sample - loss: 1.7868
[32m+      output 1:
[32m+        output_type: execute_result
[32m+        execution_count: 44
[32m+        data:
[32m+          text/plain: <tensorflow.python.keras.callbacks.History at 0x7f3ff96c2d30>
[32m+  code cell:

[0m[34m## deleted /cells/1:[0m
[31m-  code cell:
[31m-    metadata (unknown keys):
[31m-      colab:
[31m-      colab_type: code
[31m-      id: Ltj1je1fp5rO
[31m-    source:
[31m-      # TODO - Words, words, mere words, no matter from the heart.

[0m[34m## modified /metadata/kernelspec/display_name:[0m
[31m-  U4-S3-DNN (Python 3.7)
[32m+  conda_amazonei_tensorflow_p36

[0m[34m## modified /metadata/kernelspec/name:[0m
[31m-  u4-s3-dnn
[32m+  conda_amazonei_tensorflow_p36

[0m[34m## modified /metadata/language_info/version:[0m
[31m-  3.7.3
[32m+  3.6.5

[0m[34m## replaced /nbformat_minor:[0m
[31m-  2
[32m+  4

[0mnbdiff /tmp/PLUVZj_LS_DS_431_RNN_and_LSTM_Lecture.ipynb module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb
--- /tmp/PLUVZj_LS_DS_431_RNN_and_LSTM_Lecture.ipynb  2020-02-23 23:22:16.142368
+++ module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb  2020-02-19 03:59:32.555444
[34m## replaced /cells/3/execution_count:[0m
[31m-  37
[32m+  1

[0m[34m## inserted before /cells/3/outputs/0:[0m
[32m+  output:
[32m+    output_type: stream
[32m+    name: stderr
[32m+    text:
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m+  output:
[32m+    output_type: stream
[32m+    name: stdout
[32m+    text:
[32m+      Loading data...
[32m+      Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
[32m+      17465344/17464789 [==============================] - 0s 0us/step
[32m+      25000 train sequences
[32m+      25000 test sequences

[0m[34m## deleted /cells/3/outputs/0:[0m
[31m-  output:
[31m-    output_type: stream
[31m-    name: stdout
[31m-    text:
[31m-      Loading data...
[31m-      25000 train sequences
[31m-      25000 test sequences

[0m[34m## replaced /cells/4/execution_count:[0m
[31m-  40
[32m+  2

[0m[34m## replaced /cells/4/outputs/0/execution_count:[0m
[31m-  40
[32m+  2

[0m[34m## replaced /cells/5/execution_count:[0m
[31m-  41
[32m+  3

[0m[34m## replaced /cells/6/execution_count:[0m
[31m-  43
[32m+  4

[0m[34m## replaced /cells/6/outputs/0/execution_count:[0m
[31m-  43
[32m+  4

[0m[34m## replaced /cells/7/execution_count:[0m
[31m-  36
[32m+  5

[0m[34m## inserted before /cells/7/outputs/0:[0m
[32m+  output:
[32m+    output_type: stream
[32m+    name: stdout
[32m+    text:
[32m+      Build model...
[32m+      WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
[32m+      Instructions for updating:
[32m+      Call initializer instance with the dtype argument instead of passing it to the constructor
[32m+      WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
[32m+      Instructions for updating:
[32m+      Call initializer instance with the dtype argument instead of passing it to the constructor
[32m+      WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[32m+      Instructions for updating:
[32m+      Use tf.where in 2.0, which has the same broadcast rule as np.where
[32m+      Train...
[32m+      Train on 25000 samples, validate on 25000 samples
[32m+      Epoch 1/15
[32m+      25000/25000 [==============================] - 137s 5ms/sample - loss: 0.4682 - acc: 0.7745 - val_loss: 0.4181 - val_acc: 0.8114
[32m+      Epoch 2/15
[32m+      24992/25000 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.8802
[32m+  output:
[32m+    output_type: error
[32m+    ename: KeyboardInterrupt
[32m+    traceback:
[32m+      item[0]: [0;31m---------------------------------------------------------------------------[0m
[32m+      item[1]: [0;31mKeyboardInterrupt[0m                         Traceback (most recent call last)
[32m+      item[2]:
[32m+        [0;32m<ipython-input-5-1960e5254f1a>[0m in [0;36m<module>[0;34m()[0m
[32m+        [1;32m     14[0m           [0mbatch_size[0m[0;34m=[0m[0mbatch_size[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [1;32m     15[0m           [0mepochs[0m[0;34m=[0m[0;36m15[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [0;32m---> 16[0;31m           validation_data=(x_test, y_test))
[32m+        [0m[1;32m     17[0m score, acc = model.evaluate(x_test, y_test,
[32m+        [1;32m     18[0m                             batch_size=batch_size)
[32m+      item[3]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py[0m in [0;36mfit[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)[0m
[32m+        [1;32m    778[0m           [0mvalidation_steps[0m[0;34m=[0m[0mvalidation_steps[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [1;32m    779[0m           [0mvalidation_freq[0m[0;34m=[0m[0mvalidation_freq[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [0;32m--> 780[0;31m           steps_name='steps_per_epoch')
[32m+        [0m[1;32m    781[0m [0;34m[0m[0m
[32m+        [1;32m    782[0m   def evaluate(self,
[32m+      item[4]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py[0m in [0;36mmodel_iteration[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)[0m
[32m+        [1;32m    407[0m           [0mvalidation_in_fit[0m[0;34m=[0m[0;32mTrue[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [1;32m    408[0m           [0mprepared_feed_values_from_dataset[0m[0;34m=[0m[0;34m([0m[0mval_iterator[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m)[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [0;32m--> 409[0;31m           steps_name='validation_steps')
[32m+        [0m[1;32m    410[0m       [0;32mif[0m [0;32mnot[0m [0misinstance[0m[0;34m([0m[0mval_results[0m[0;34m,[0m [0mlist[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0m
[32m+        [1;32m    411[0m         [0mval_results[0m [0;34m=[0m [0;34m[[0m[0mval_results[0m[0;34m][0m[0;34m[0m[0m
[32m+      item[5]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py[0m in [0;36mmodel_iteration[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)[0m
[32m+        [1;32m    361[0m [0;34m[0m[0m
[32m+        [1;32m    362[0m         [0;31m# Get outputs.[0m[0;34m[0m[0;34m[0m[0m
[32m+        [0;32m--> 363[0;31m         [0mbatch_outs[0m [0;34m=[0m [0mf[0m[0;34m([0m[0mins_batch[0m[0;34m)[0m[0;34m[0m[0m
[32m+        [0m[1;32m    364[0m         [0;32mif[0m [0;32mnot[0m [0misinstance[0m[0;34m([0m[0mbatch_outs[0m[0;34m,[0m [0mlist[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0m
[32m+        [1;32m    365[0m           [0mbatch_outs[0m [0;34m=[0m [0;34m[[0m[0mbatch_outs[0m[0;34m][0m[0;34m[0m[0m
[32m+      item[6]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py[0m in [0;36m__call__[0;34m(self, inputs)[0m
[32m+        [1;32m   3290[0m [0;34m[0m[0m
[32m+        [1;32m   3291[0m     fetched = self._callable_fn(*array_vals,
[32m+        [0;32m-> 3292[0;31m                                 run_metadata=self.run_metadata)
[32m+        [0m[1;32m   3293[0m     [0mself[0m[0;34m.[0m[0m_call_fetch_callbacks[0m[0;34m([0m[0mfetched[0m[0;34m[[0m[0;34m-[0m[0mlen[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_fetches[0m[0;34m)[0m[0;34m:[0m[0;34m][0m[0;34m)[0m[0;34m[0m[0m
[32m+        [1;32m   3294[0m     output_structure = nest.pack_sequence_as(
[32m+      item[7]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py[0m in [0;36m__call__[0;34m(self, *args, **kwargs)[0m
[32m+        [1;32m   1456[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,
[32m+        [1;32m   1457[0m                                                [0mself[0m[0;34m.[0m[0m_handle[0m[0;34m,[0m [0margs[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [0;32m-> 1458[0;31m                                                run_metadata_ptr)
[32m+        [0m[1;32m   1459[0m         [0;32mif[0m [0mrun_metadata[0m[0;34m:[0m[0;34m[0m[0m
[32m+        [1;32m   1460[0m           [0mproto_data[0m [0;34m=[0m [0mtf_session[0m[0;34m.[0m[0mTF_GetBuffer[0m[0;34m([0m[0mrun_metadata_ptr[0m[0;34m)[0m[0;34m[0m[0m
[32m+      item[8]: [0;31mKeyboardInterrupt[0m: 

[0m[34m## deleted /cells/7/outputs/0-3:[0m
[31m-  output:
[31m-    output_type: stream
[31m-    name: stdout
[31m-    text:
[31m-      Loading data...
[31m-      25000 train sequences
[31m-      25000 test sequences
[31m-      Pad sequences (samples x time)
[31m-      x_train shape: (25000, 80)
[31m-      x_test shape: (25000, 80)
[31m-      Build model...
[31m-  output:
[31m-    output_type: stream
[31m-    name: stderr
[31m-    text:
[31m-      WARNING: Logging before flag parsing goes to stderr.
[31m-      W1014 11:43:31.987977 4548709696 deprecation.py:323] From /Users/jonathansokoll/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[31m-      Instructions for updating:
[31m-      Use tf.where in 2.0, which has the same broadcast rule as np.where
[31m-  output:
[31m-    output_type: stream
[31m-    name: stdout
[31m-    text:
[31m-      Train...
[31m-      Train on 25000 samples, validate on 25000 samples
[31m-      Epoch 1/15
[31m-      25000/25000 [==============================] - 71s 3ms/sample - loss: 0.4647 - accuracy: 0.7784 - val_loss: 0.4007 - val_accuracy: 0.8196
[31m-      Epoch 2/15
[31m-      25000/25000 [==============================] - 80s 3ms/sample - loss: 0.2986 - accuracy: 0.8782 - val_loss: 0.3983 - val_accuracy: 0.8201
[31m-      Epoch 3/15
[31m-      19744/25000 [======================>.......] - ETA: 11s - loss: 0.2096 - accuracy: 0.9204
[31m-  output:
[31m-    output_type: error
[31m-    ename: KeyboardInterrupt
[31m-    traceback:
[31m-      item[0]: [0;31m---------------------------------------------------------------------------[0m
[31m-      item[1]: [0;31mKeyboardInterrupt[0m                         Traceback (most recent call last)
[31m-      item[2]:
[31m-        [0;32m<ipython-input-36-410d5d21a41b>[0m in [0;36m<module>[0;34m[0m
[31m-        [1;32m     49[0m           [0mbatch_size[0m[0;34m=[0m[0mbatch_size[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m     50[0m           [0mepochs[0m[0;34m=[0m[0;36m15[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m---> 51[0;31m           validation_data=(x_test, y_test))
[31m-        [0m[1;32m     52[0m score, acc = model.evaluate(x_test, y_test,
[31m-        [1;32m     53[0m                             batch_size=batch_size)
[31m-      item[3]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py[0m in [0;36mfit[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)[0m
[31m-        [1;32m    641[0m         [0mmax_queue_size[0m[0;34m=[0m[0mmax_queue_size[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m    642[0m         [0mworkers[0m[0;34m=[0m[0mworkers[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m--> 643[0;31m         use_multiprocessing=use_multiprocessing)
[31m-        [0m[1;32m    644[0m [0;34m[0m[0m
[31m-        [1;32m    645[0m   def evaluate(self,
[31m-      item[4]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py[0m in [0;36mfit[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)[0m
[31m-        [1;32m    662[0m         [0mvalidation_steps[0m[0;34m=[0m[0mvalidation_steps[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m    663[0m         [0mvalidation_freq[0m[0;34m=[0m[0mvalidation_freq[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m--> 664[0;31m         steps_name='steps_per_epoch')
[31m-        [0m[1;32m    665[0m [0;34m[0m[0m
[31m-        [1;32m    666[0m   def evaluate(self,
[31m-      item[5]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py[0m in [0;36mmodel_iteration[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)[0m
[31m-        [1;32m    381[0m [0;34m[0m[0m
[31m-        [1;32m    382[0m         [0;31m# Get outputs.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m--> 383[0;31m         [0mbatch_outs[0m [0;34m=[0m [0mf[0m[0;34m([0m[0mins_batch[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0m[1;32m    384[0m         [0;32mif[0m [0;32mnot[0m [0misinstance[0m[0;34m([0m[0mbatch_outs[0m[0;34m,[0m [0mlist[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m    385[0m           [0mbatch_outs[0m [0;34m=[0m [0;34m[[0m[0mbatch_outs[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[31m-      item[6]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/keras/backend.py[0m in [0;36m__call__[0;34m(self, inputs)[0m
[31m-        [1;32m   3508[0m         [0mvalue[0m [0;34m=[0m [0mmath_ops[0m[0;34m.[0m[0mcast[0m[0;34m([0m[0mvalue[0m[0;34m,[0m [0mtensor[0m[0;34m.[0m[0mdtype[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m   3509[0m       [0mconverted_inputs[0m[0;34m.[0m[0mappend[0m[0;34m([0m[0mvalue[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m-> 3510[0;31m     [0moutputs[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_graph_fn[0m[0;34m([0m[0;34m*[0m[0mconverted_inputs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0m[1;32m   3511[0m [0;34m[0m[0m
[31m-        [1;32m   3512[0m     [0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[31m-      item[7]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/eager/function.py[0m in [0;36m__call__[0;34m(self, *args, **kwargs)[0m
[31m-        [1;32m    570[0m       raise TypeError("Keyword arguments {} unknown. Expected {}.".format(
[31m-        [1;32m    571[0m           list(kwargs.keys()), list(self._arg_keywords)))
[31m-        [0;32m--> 572[0;31m     [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_call_flat[0m[0;34m([0m[0margs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0m[1;32m    573[0m [0;34m[0m[0m
[31m-        [1;32m    574[0m   [0;32mdef[0m [0m_filtered_call[0m[0;34m([0m[0mself[0m[0;34m,[0m [0margs[0m[0;34m,[0m [0mkwargs[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[31m-      item[8]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/eager/function.py[0m in [0;36m_call_flat[0;34m(self, args)[0m
[31m-        [1;32m    669[0m     [0;31m# Only need to override the gradient in graph mode and when we have outputs.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m    670[0m     [0;32mif[0m [0mcontext[0m[0;34m.[0m[0mexecuting_eagerly[0m[0;34m([0m[0;34m)[0m [0;32mor[0m [0;32mnot[0m [0mself[0m[0;34m.[0m[0moutputs[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m--> 671[0;31m       [0moutputs[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0m_inference_function[0m[0;34m.[0m[0mcall[0m[0;34m([0m[0mctx[0m[0;34m,[0m [0margs[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0m[1;32m    672[0m     [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m    673[0m       [0mself[0m[0;34m.[0m[0m_register_gradient[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[31m-      item[9]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/eager/function.py[0m in [0;36mcall[0;34m(self, ctx, args)[0m
[31m-        [1;32m    443[0m             attrs=("executor_type", executor_type,
[31m-        [1;32m    444[0m                    "config_proto", config),
[31m-        [0;32m--> 445[0;31m             ctx=ctx)
[31m-        [0m[1;32m    446[0m       [0;31m# Replace empty list with None[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m    447[0m       [0moutputs[0m [0;34m=[0m [0moutputs[0m [0;32mor[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[31m-      item[10]:
[31m-        [0;32m~/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/tensorflow/python/eager/execute.py[0m in [0;36mquick_execute[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)[0m
[31m-        [1;32m     59[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,
[31m-        [1;32m     60[0m                                                [0mop_name[0m[0;34m,[0m [0minputs[0m[0;34m,[0m [0mattrs[0m[0;34m,[0m[0;34m[0m[0;34m[0m[0m
[31m-        [0;32m---> 61[0;31m                                                num_outputs)
[31m-        [0m[1;32m     62[0m   [0;32mexcept[0m [0mcore[0m[0;34m.[0m[0m_NotOkStatusException[0m [0;32mas[0m [0me[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[31m-        [1;32m     63[0m     [0;32mif[0m [0mname[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[31m-      item[11]: [0;31mKeyboardInterrupt[0m: 

[0m[34m## replaced /cells/9/execution_count:[0m
[31m-  16
[32m+  1

[0m[34m## inserted before /cells/9/outputs/0:[0m
[32m+  output:
[32m+    output_type: stream
[32m+    name: stderr
[32m+    text:
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        np_resource = np.dtype([("resource", np.ubyte, 1)])

[0m[34m## replaced /cells/10/execution_count:[0m
[31m-  5
[32m+  2

[0m[34m## inserted before /cells/11:[0m
[32m+  code cell:
[32m+    execution_count: 3
[32m+    source:
[32m+      # Read in Data
[32m+      
[32m+      data = []
[32m+      
[32m+      for file in data_files:
[32m+          if file[-3:] == 'txt':
[32m+              with open(f'./articles/{file}', 'r') as f:
[32m+                  data.append(f.read())
[32m+  code cell:
[32m+    execution_count: 4
[32m+    source:
[32m+      len(data)
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 4
[32m+        data:
[32m+          text/plain: 136
[32m+  code cell:
[32m+    execution_count: 5
[32m+    source:
[32m+      # Encode Data as Chars
[32m+      
[32m+      text = " ".join(data)
[32m+      
[32m+      chars = list(set(text))
[32m+      
[32m+      char_int = {c:i for i,c in enumerate(chars)}
[32m+      int_char = {i:c for i,c in enumerate(chars)}
[32m+  code cell:
[32m+    execution_count: 6
[32m+    source:
[32m+      len(chars)
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 6
[32m+        data:
[32m+          text/plain: 121
[32m+  code cell:
[32m+    execution_count: 7
[32m+    source:
[32m+      # Create the Sequence Data
[32m+      
[32m+      maxlen = 40
[32m+      step = 5
[32m+      
[32m+      encoded = [char_int[c] for c in text]
[32m+      
[32m+      sequences = [] #each element 40 chars long
[32m+      next_chars = [] #one element for each sequence
[32m+      
[32m+      for i in range(0, len(encoded)-maxlen, step):
[32m+          sequences.append(encoded[i : i+maxlen])
[32m+          next_chars.append(encoded[i+maxlen])
[32m+          
[32m+      print(f'sequences: {len(sequences)}')
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          sequences: 178374
[32m+  code cell:
[32m+    execution_count: 8
[32m+    source:
[32m+      # Specify x & y
[32m+      
[32m+      x = np.zeros((len(sequences), maxlen, len(chars)), dtype = np.bool)
[32m+      y = np.zeros((len(sequences), len(chars)), dtype = np.bool)
[32m+      
[32m+      for i, sequence in enumerate(sequences):
[32m+          for t, char in enumerate(sequence):
[32m+              x[i,t,char] = 1
[32m+              
[32m+          y[i, next_chars[i]] = 1
[32m+  code cell:
[32m+    execution_count: 9
[32m+    source:
[32m+      x.shape
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 9
[32m+        data:
[32m+          text/plain: (178374, 40, 121)
[32m+  code cell:
[32m+    execution_count: 10
[32m+    source:
[32m+      y.shape
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 10
[32m+        data:
[32m+          text/plain: (178374, 121)
[32m+  code cell:
[32m+    execution_count: 11
[32m+    source:
[32m+      # build the model: a single LSTM
[32m+      
[32m+      model = Sequential()
[32m+      
[32m+      model.add(LSTM(128, input_shape=(maxlen, len(chars))))
[32m+      model.add(Dense(len(chars), activation = 'softmax')) #softmax used because multiclass 
[32m+      
[32m+      model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
[32m+          Instructions for updating:
[32m+          Call initializer instance with the dtype argument instead of passing it to the constructor

[0m[34m## deleted /cells/11-15:[0m
[31m-  code cell:
[31m-    execution_count: 18
[31m-    source:
[31m-      # Read in Data
[31m-  code cell:
[31m-    execution_count: 19
[31m-    source:
[31m-      # Encode Data as Chars
[31m-      
[31m-  code cell:
[31m-    execution_count: 20
[31m-    source:
[31m-      # Create the Sequence Data
[31m-  code cell:
[31m-    execution_count: 11
[31m-    source:
[31m-      # Specify x & y
[31m-  code cell:
[31m-    execution_count: 12
[31m-    source:
[31m-      # build the model: a single LSTM
[31m-    outputs:
[31m-      output 0:
[31m-        output_type: stream
[31m-        name: stdout
[31m-        text:
[31m-          Build model...

[0m[34m## replaced /cells/16/execution_count:[0m
[31m-  13
[32m+  12

[0m[34m## replaced /cells/17/execution_count:[0m
[31m-  14
[32m+  13

[0m[34m## replaced /cells/18/execution_count:[0m
[31m-  17
[32m+  14

[0m[34m## inserted before /cells/18/outputs/0:[0m
[32m+  output:
[32m+    output_type: stream
[32m+    name: stdout
[32m+    text:
[32m+      WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[32m+      Instructions for updating:
[32m+      Use tf.where in 2.0, which has the same broadcast rule as np.where
[32m+      Epoch 1/5
[32m+      178304/178374 [============================>.] - ETA: 0s - loss: 2.8112
[32m+      ----- Generating text after Epoch: 0
[32m+      ----- diversity: 0.2
[32m+      ----- Generating with seed: "a tiny taco whose dark filling, hidden b"
[32m+      a tiny taco whose dark filling, hidden b
[32m+  output:
[32m+    output_type: error
[32m+    ename: NameError
[32m+    evalue: name 'char_indices' is not defined
[32m+    traceback:
[32m+      item[0]: [0;31m---------------------------------------------------------------------------[0m
[32m+      item[1]: [0;31mNameError[0m                                 Traceback (most recent call last)
[32m+      item[2]:
[32m+        [0;32m<ipython-input-14-d5794c81093e>[0m in [0;36m<module>[0;34m()[0m
[32m+        [1;32m      2[0m           [0mbatch_size[0m[0;34m=[0m[0;36m128[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [1;32m      3[0m           [0mepochs[0m[0;34m=[0m[0;36m5[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [0;32m----> 4[0;31m           callbacks=[print_callback])
[32m+        [0m
[32m+      item[3]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py[0m in [0;36mfit[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)[0m
[32m+        [1;32m    778[0m           [0mvalidation_steps[0m[0;34m=[0m[0mvalidation_steps[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [1;32m    779[0m           [0mvalidation_freq[0m[0;34m=[0m[0mvalidation_freq[0m[0;34m,[0m[0;34m[0m[0m
[32m+        [0;32m--> 780[0;31m           steps_name='steps_per_epoch')
[32m+        [0m[1;32m    781[0m [0;34m[0m[0m
[32m+        [1;32m    782[0m   def evaluate(self,
[32m+      item[4]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py[0m in [0;36mmodel_iteration[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)[0m
[32m+        [1;32m    417[0m     [0;32mif[0m [0mmode[0m [0;34m==[0m [0mModeKeys[0m[0;34m.[0m[0mTRAIN[0m[0;34m:[0m[0;34m[0m[0m
[32m+        [1;32m    418[0m       [0;31m# Epochs only apply to `fit`.[0m[0;34m[0m[0;34m[0m[0m
[32m+        [0;32m--> 419[0;31m       [0mcallbacks[0m[0;34m.[0m[0mon_epoch_end[0m[0;34m([0m[0mepoch[0m[0;34m,[0m [0mepoch_logs[0m[0;34m)[0m[0;34m[0m[0m
[32m+        [0m[1;32m    420[0m     [0mprogbar[0m[0;34m.[0m[0mon_epoch_end[0m[0;34m([0m[0mepoch[0m[0;34m,[0m [0mepoch_logs[0m[0;34m)[0m[0;34m[0m[0m
[32m+        [1;32m    421[0m [0;34m[0m[0m
[32m+      item[5]:
[32m+        [0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py[0m in [0;36mon_epoch_end[0;34m(self, epoch, logs)[0m
[32m+        [1;32m    309[0m     [0mlogs[0m [0;34m=[0m [0mlogs[0m [0;32mor[0m [0;34m{[0m[0;34m}[0m[0;34m[0m[0m
[32m+        [1;32m    310[0m     [0;32mfor[0m [0mcallback[0m [0;32min[0m [0mself[0m[0;34m.[0m[0mcallbacks[0m[0;34m:[0m[0;34m[0m[0m
[32m+        [0;32m--> 311[0;31m       [0mcallback[0m[0;34m.[0m[0mon_epoch_end[0m[0;34m([0m[0mepoch[0m[0;34m,[0m [0mlogs[0m[0;34m)[0m[0;34m[0m[0m
[32m+        [0m[1;32m    312[0m [0;34m[0m[0m
[32m+        [1;32m    313[0m   [0;32mdef[0m [0mon_train_batch_begin[0m[0;34m([0m[0mself[0m[0;34m,[0m [0mbatch[0m[0;34m,[0m [0mlogs[0m[0;34m=[0m[0;32mNone[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0m
[32m+      item[6]:
[32m+        [0;32m<ipython-input-13-b287e9a13794>[0m in [0;36mon_epoch_end[0;34m(epoch, _)[0m
[32m+        [1;32m     17[0m             [0mx_pred[0m [0;34m=[0m [0mnp[0m[0;34m.[0m[0mzeros[0m[0;34m([0m[0;34m([0m[0;36m1[0m[0;34m,[0m [0mmaxlen[0m[0;34m,[0m [0mlen[0m[0;34m([0m[0mchars[0m[0;34m)[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0m
[32m+        [1;32m     18[0m             [0;32mfor[0m [0mt[0m[0;34m,[0m [0mchar[0m [0;32min[0m [0menumerate[0m[0;34m([0m[0msentence[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0m
[32m+        [0;32m---> 19[0;31m                 [0mx_pred[0m[0;34m[[0m[0;36m0[0m[0;34m,[0m [0mt[0m[0;34m,[0m [0mchar_indices[0m[0;34m[[0m[0mchar[0m[0;34m][0m[0;34m][0m [0;34m=[0m [0;36m1.[0m[0;34m[0m[0m
[32m+        [0m[1;32m     20[0m [0;34m[0m[0m
[32m+        [1;32m     21[0m             [0mpreds[0m [0;34m=[0m [0mmodel[0m[0;34m.[0m[0mpredict[0m[0;34m([0m[0mx_pred[0m[0;34m,[0m [0mverbose[0m[0;34m=[0m[0;36m0[0m[0;34m)[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[0m[0m
[32m+      item[7]: [0;31mNameError[0m: name 'char_indices' is not defined

[0m[34m## deleted /cells/18/outputs/0-1:[0m
[31m-  output:
[31m-    output_type: stream
[31m-    name: stdout
[31m-    text:
[31m-      Train on 304211 samples
[31m-      Epoch 1/5
[31m-      304128/304211 [============================>.] - ETA: 0s - loss: 1.7593
[31m-      ----- Generating text after Epoch: 0
[31m-      ----- diversity: 0.2
[31m-      ----- Generating with seed: "e to follow and be bound by the Terms, w"
[31m-      e to follow and be bound by the Terms, which he was the content that the completion and the same that the contents of the prosecution to the complence and the promotical and the group that white he said that the provided that the prosecution in the complence and the content to the propess and the prosecal that the trans and the prosecutions and the prosecutive that the provide that the complence that the content to the committion. They 
[31m-      ----- diversity: 0.5
[31m-      ----- Generating with seed: "e to follow and be bound by the Terms, w"
[31m-      e to follow and be bound by the Terms, with entemes which said that the changed and he takges and the similar of complence program of the provens see adminisions that they with the completing the world to collages that the promal with the sold that the ball ell with the bolls, for side has be that the charge for croliting it was a more consider from the line with the State of the Steylance in the some community.
[31m-      
[31m-      A expective that like t
[31m-      ----- diversity: 1.0
[31m-      ----- Generating with seed: "e to follow and be bound by the Terms, w"
[31m-      e to follow and be bound by the Terms, with i warss corchogience this prodecting hom she idestral rocusion avo whene with Euract. That guy speak of to abfed. They sepoot crap fasted that than -novemy ofuel last a thanktrohong will signom elocolts, the extorting mo videnched with the Yecksy, glome for taksen nrovely will maying with coquined egeatison for any thats sidsthou sign. Frothernam 8, which sim lokily from sface or thank thinds 
[31m-      ----- diversity: 1.2
[31m-      ----- Generating with seed: "e to follow and be bound by the Terms, w"
[31m-      e to follow and be bound by the Terms, was their gno to boising remended to — son of the old extrical boy signed alte win amprovess) invest alled to chaig of Weitbeal  dritcvery supportablien.
[31m-      
[31m-      Kok Ditmas, Spaskes shouts reecredise imseard: We Yain of Surday Ocens on Ihours”, 20th1B1o formally, A back Leb Deword SyBry )comed-comp to medicancizencate back to droes out neptic, Presader and Ang Coupties, is shille S Brrack as avold and MiC
[31m-      304211/304211 [==============================] - 105s 345us/sample - loss: 1.7593
[31m-      Epoch 2/5
[31m-      304128/304211 [============================>.] - ETA: 0s - loss: 1.6764
[31m-      ----- Generating text after Epoch: 1
[31m-      ----- diversity: 0.2
[31m-      ----- Generating with seed: "tightrope walk — that jaunty display of "
[31m-      tightrope walk — that jaunty display of the strang and the strange of the Services. The start and the Trump and the start of the strang and the start and the starts in the start and a stratter of the strang the first a strang the string the said the entrys of the states of the consider in the starts and the state of the strang in the said the Services. The president and the string the strange of the starts and the state of the string a 
[31m-      ----- diversity: 0.5
[31m-      ----- Generating with seed: "tightrope walk — that jaunty display of "
[31m-      tightrope walk — that jaunty display of the change to the concay with transcredition of his strans decided to the agent to the interested in the Actor and Court said the extended in one for the over the Turkish and Subscripes and the string students and in a president of the right to dead on the are with a add to the state of the Trump had forthing a is services and the Washington soon a power goal of the Services of the administon for 
[31m-      ----- diversity: 1.0
[31m-      ----- Generating with seed: "tightrope walk — that jaunty display of "
[31m-      tightrope walk — that jaunty display of importation  after in the Flach 2His Hod Turnoush pricess:
[31m-      
[31m-      “Oster, Enday said any Gearing here and videle have twory has ofinged tued to actid caim.”, and overage.
[31m-      
[31m-      AD
[31m-      
[31m-      The emarement, if a dir he townes soon Hister.
[31m-      
[31m-      “The Trump’s gly these I’m teem to caller see usistratily those of the wresching Lambde bustazhps. A toS. But your Washington Easually Height, the Selvizes after officers with a can 
[31m-      ----- diversity: 1.2
[31m-      ----- Generating with seed: "tightrope walk — that jaunty display of "
[31m-      tightrope walk — that jaunty display of the worke searldingly of the been edered DchyPL so fallesged their lcual Baphrels: W’t Sible other popararal impeoanal sep ce contria remains all orday radent to photocrimemeq, easures, ploff of their with ceptay oun furins withey fighter. The trer, Fod-called opened aner Fr’n Lean and Inamile or see treat neadly d5o eccounted review” hoblized to mavie Hying. With useral med “Twowinder ons, ruchar
[31m-      304211/304211 [==============================] - 114s 373us/sample - loss: 1.6764
[31m-      Epoch 3/5
[31m-      304000/304211 [============================>.] - ETA: 0s - loss: 1.6290
[31m-      ----- Generating text after Epoch: 2
[31m-      ----- diversity: 0.2
[31m-      ----- Generating with seed: "early half-century political career. A s"
[31m-      early half-century political career. A said that the said the president will be a seep the president and an and the contance of the state and the and and state of the state and the and and in the account and the Services and the can be a care and the contact and the said the can be the president has subscribe the candidation in the contain to a president to the said of the can be the that and and the and and the and the state of the pro
[31m-      ----- diversity: 0.5
[31m-      ----- Generating with seed: "early half-century political career. A s"
[31m-      early half-century political career. A school do a provided to the say to the some has general and the a so a calling the rack in the same this cap the any one the stature to one. In a brow when a counding that a first and in your promasional family and the state internations that is an and the and many to the president and a submission in the students of the Washington Post could be claims that worked to a part of a reasonal interaigue
[31m-      ----- diversity: 1.0
[31m-      ----- Generating with seed: "early half-century political career. A s"
[31m-      early half-century political career. A stay said. For Synda Nevaturolar, but may finable on go of not seep the was phinablite.
[31m-      
[31m-      Already webing work to the singleborat head and childred, the Israppe after employes on senchire buble,” a Kunday, white Mosu wore-face) of someto, pooB egine bshin at militured and killed with publishing, lawkless helpes it laisuage.” Of one-workwhil are ho-banf imptasing he was repleficturanority grapned this
[31m-      ----- diversity: 1.2
[31m-      ----- Generating with seed: "early half-century political career. A s"
[31m-      early half-century political career. A sanignn any eachupt Trughits should littance chief in
[31m-      Cod and “AndC on.
[31m-      
[31m-      If Iabusile ifmitality. a adout you detaurts,” anyone who were their Facebia tcalgenctions cannoternly camhused sufocclial. he willings..”
[31m-      
[31m-      Evail  Ukrainh,” SantCrep. Giergohin un, brasadation gie ’roriaNTrump hassafiglAbilial killes. I an Nuyter and out of Fu2z Tetwhil.
[31m-      
[31m-      This private, discrod anywime plased ritces the schudbe
[31m-      304211/304211 [==============================] - 119s 391us/sample - loss: 1.6291
[31m-      Epoch 4/5
[31m-      304128/304211 [============================>.] - ETA: 0s - loss: 1.5966
[31m-      ----- Generating text after Epoch: 3
[31m-      ----- diversity: 0.2
[31m-      ----- Generating with seed: "a matter of perspective.The $60,000 medi"
[31m-      a matter of perspective.The $60,000 media the said the part of the state and the the the police and the state of the players and the finally being state of the process that he said the controre the content and the part of the and and the said the process and the and and state to the process that was the the process of the content to an and the for the players of the posts that the for the state with the players and the the the the part 
[31m-      ----- diversity: 0.5
[31m-      ----- Generating with seed: "a matter of perspective.The $60,000 medi"
[31m-      a matter of perspective.The $60,000 media the time and the a on the comminice the depists. The content to the get pains and entimations with the account, as the communicate the police community disable to nears a forces in a state and the find such as million with the sentiment and internet being not engulate the for the forces in the post. The colleague to construnts and with his worr in the the will an trade. The new, and the process 
[31m-      ----- diversity: 1.0
[31m-      ----- Generating with seed: "a matter of perspective.The $60,000 medi"
[31m-      a matter of perspective.The $60,000 medicar how the doing many — would killing whe law threath of excluded back Morreder programs in the area first a group of cofperzed for third Allingy mland, the rackene least Paroll poill with a putatter, the Turkey and countryber. It, a follow, for the acting an the access to the removes” reasonates any borned, authoried malles and Busine’s ores read anothe shows to the said this remainsions into th
[31m-      ----- diversity: 1.2
[31m-      ----- Generating with seed: "a matter of perspective.The $60,000 medi"
[31m-      a matter of perspective.The $60,000 media mepial using cearfulfs are schefu to your rusinaKkly Changeh internatoreK. 9ue.
[31m-      
[31m-      So away in. Arb going on the vocal regreetur has cookie,” recorning thatbet, 201, a befonereas cororices ’s sear a manuaased rub relogrews at Fownoc Foo Pulhonic coun basate.
[31m-      
[31m-      If the city Wirday lang the MeC a’d people afrreduced beyorged goove jePtop,/2.M
[31m-      Bath we’l . Subscript, foocart, the leggetweteelors swops fa
[31m-      304211/304211 [==============================] - 124s 406us/sample - loss: 1.5965
[31m-      Epoch 5/5
[31m-      304128/304211 [============================>.] - ETA: 0s - loss: 1.5750
[31m-      ----- Generating text after Epoch: 4
[31m-      ----- diversity: 0.2
[31m-      ----- Generating with seed: "Cave in Hocking Hills State Park in Loga"
[31m-      Cave in Hocking Hills State Park in Logan and the and and said the support the states and a states that a said they was statement to the the that they was they were such as a support they have to the the and the promotion and sentence and and and a ward to the states and the many to be the and the the and and as a day and first and the the content and said they was and the the trial that and in a states and the that and the content that
[31m-      ----- diversity: 0.5
[31m-      ----- Generating with seed: "Cave in Hocking Hills State Park in Loga"
[31m-      Cave in Hocking Hills State Park in Logan, the him in the candle of the song up to a websited the conferences to the sugar that that president to the track attacked then have been the president that a supporters for the promotion on a reporters in July Citaral and Policis and the truch and statement was in 201o in a card and promoted in a services, that and the over many situation in a activily and something of the websites the services
[31m-      ----- diversity: 1.0
[31m-      ----- Generating with seed: "Cave in Hocking Hills State Park in Loga"
[31m-      Cave in Hocking Hills State Park in Logan.
[31m-      
[31m-      that officials and black is unsloged.
[31m-      
[31m-      Lisis is shy resutks, troops be reay in one since they’le agree, a disiting to fa
[31m-      
[31m-      shaxil sit dacial tes space count or indesta. Infeests or imays had itnvesy caulaugh to westers from tablet .itmetings: 2014, Trump’s primated on TwoBtust in New Washingtong prone defense least sface prepent and beaderal (told handed him.”
[31m-      
[31m-      One wtents that he line decaps as
[31m-      ----- diversity: 1.2
[31m-      ----- Generating with seed: "Cave in Hocking Hills State Park in Loga"
[31m-      Cave in Hocking Hills State Park in Logan, Lapacalow were parent.
[31m-      
[31m-      comments, aid on-Tlumnio profed no mefridiLo/t.
[31m-      
[31m-      Buschropp fur, and aparity susyended.
[31m-      
[31m-      Ceven and a datablinouthister cama worlder has plan mealled — to way ”a vs Fail Eftory. 1retri.a1HBessaupHowd, crubs, applicard.”
[31m-      
[31m-      mittplai attenlid, for ti-less larging law Jozen.
[31m-      
[31m-      Sa ecdowble, when Tmebumsa Fi”:BKanda.w.) wdlving widking sought reviews white authorogory key.
[31m-      
[31m-      Addres
[31m-      304211/304211 [==============================] - 122s 402us/sample - loss: 1.5751
[31m-  output:
[31m-    output_type: execute_result
[31m-    execution_count: 17
[31m-    data:
[31m-      text/plain: <tensorflow.python.keras.callbacks.History at 0x7fee10a220b8>

[0m[34m## inserted before /cells/19:[0m
[32m+  code cell:

[0m[34m## modified /metadata/kernelspec/display_name:[0m
[31m-  U4-S3-DNN (Python 3.7)
[32m+  conda_amazonei_tensorflow_p36

[0m[34m## modified /metadata/kernelspec/name:[0m
[31m-  u4-s3-dnn
[32m+  conda_amazonei_tensorflow_p36

[0m[34m## modified /metadata/language_info/version:[0m
[31m-  3.7.3
[32m+  3.6.5

[0mnbdiff /tmp/lWZZrK_LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb module2-convolutional-neural-networks/LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb
--- /tmp/lWZZrK_LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb  2020-02-23 23:22:16.510369
+++ module2-convolutional-neural-networks/LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb  2020-02-21 21:51:09.317314
[34m## inserted before /cells/4:[0m
[32m+  code cell:
[32m+    execution_count: 1
[32m+    source:
[32m+      !pip install --upgrade scikit-image
[32m+      !pip install --upgrade numpy
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          Collecting scikit-image
[32m+          [?25l  Downloading https://files.pythonhosted.org/packages/c8/bb/771800366f41d66eef51e4b80515f8ef7edab234a3f244fdce3bafe89b39/scikit_image-0.16.2-cp36-cp36m-manylinux1_x86_64.whl (26.5MB)
[32m+          [K     |████████████████████████████████| 26.5MB 278kB/s eta 0:00:01
[32m+          [?25hRequirement already satisfied, skipping upgrade: pillow>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (5.2.0)
[32m+          Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (0.5.2)
[32m+          Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (1.3.1)
[32m+          Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (2.3.0)
[32m+          Requirement already satisfied, skipping upgrade: networkx>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (2.1)
[32m+          Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (3.0.3)
[32m+          Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from PyWavelets>=0.4.0->scikit-image) (1.16.4)
[32m+          Requirement already satisfied, skipping upgrade: decorator>=4.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.3.0)
[32m+          Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)
[32m+          Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.7.3)
[32m+          Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.2.0)
[32m+          Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.0.1)
[32m+          Requirement already satisfied, skipping upgrade: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.11.0)
[32m+          Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (41.6.0)
[32m+          Installing collected packages: scikit-image
[32m+            Found existing installation: scikit-image 0.13.1
[32m+              Uninstalling scikit-image-0.13.1:
[32m+                Successfully uninstalled scikit-image-0.13.1
[32m+          Successfully installed scikit-image-0.16.2
[32m+          [33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.
[32m+          You should consider upgrading via the 'pip install --upgrade pip' command.[0m
[32m+          Collecting numpy
[32m+          [?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)
[32m+          [K     |████████████████████████████████| 20.2MB 3.2MB/s eta 0:00:01
[32m+          [?25hInstalling collected packages: numpy
[32m+            Found existing installation: numpy 1.16.4
[32m+              Uninstalling numpy-1.16.4:
[32m+                Successfully uninstalled numpy-1.16.4
[32m+          Successfully installed numpy-1.18.1
[32m+          [33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.
[32m+          You should consider upgrading via the 'pip install --upgrade pip' command.[0m
[32m+  code cell:
[32m+    execution_count: 45
[32m+    source:
[32m+      import numpy as np
[32m+      import matplotlib.pyplot as plt
[32m+      import os, re
[32m+      
[32m+      from skimage import data, io, filters
[32m+      from sklearn.model_selection import train_test_split
[32m+      from tensorflow.keras.applications.resnet50 import ResNet50
[32m+      from tensorflow.keras.preprocessing import image
[32m+      from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
[32m+      from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
[32m+      from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, AveragePooling2D
[32m+      from tensorflow.keras.models import Model, Sequential, load_model
[32m+      from keras import backend as K 
[32m+      
[32m+      from IPython.display import display
[32m+      from IPython.display import Image as _Imgdis
[32m+      from PIL import Image
[32m+  code cell:
[32m+    execution_count: 3
[32m+    source:
[32m+      resnet = ResNet50(weights='imagenet', include_top=False)
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[32m+          Instructions for updating:
[32m+          If using Keras pass *_constraint arguments to layers.
[32m+          Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5
[32m+          94773248/94765736 [==============================] - 2s 0us/step
[32m+          WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[32m+  code cell:
[32m+    execution_count: 4
[32m+    source:
[32m+      for layer in resnet.layers:
[32m+          layer.trainable = False
[32m+  code cell:
[32m+    execution_count: 5
[32m+    source:
[32m+      mountain_dir = "./data/mountain/"
[32m+      forest_dir = "./data/forest/"
[32m+      
[32m+      mountain_files = [image.load_img(mountain_dir+f) for f in os.listdir(mountain_dir) if re.search('.jpg', f)]
[32m+      forest_files = [image.load_img(forest_dir+f) for f in os.listdir(forest_dir) if re.search('.jpg',f)]
[32m+  code cell:
[32m+    execution_count: 6
[32m+    source:
[32m+      mountain_array = [image.img_to_array(mountain_files[ii])for ii in range(len(mountain_files))]
[32m+      forest_array = [image.img_to_array(forest_files[ii])for ii in range(len(forest_files))]
[32m+      mountain_label = [[1] for _ in range(len(mountain_array))]
[32m+      forest_label = [[0] for _ in range(len(forest_files))]
[32m+  code cell:
[32m+    execution_count: 7
[32m+    source:
[32m+      df = np.asarray(mountain_array+forest_array)
[32m+      label = np.asarray(mountain_label+forest_label)
[32m+  code cell:
[32m+    execution_count: 8
[32m+    source:
[32m+      X_train, X_test, y_train, y_test = train_test_split(df, label, test_size = 0.2, stratify = label)
[32m+  code cell:
[32m+    execution_count: 9
[32m+    source:
[32m+      X_train.shape, y_train.shape, X_test.shape, y_test.shape
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 9
[32m+        data:
[32m+          text/plain: ((561, 256, 256, 3), (561, 1), (141, 256, 256, 3), (141, 1))
[32m+  code cell:
[32m+    execution_count: 10
[32m+    source:
[32m+      X_train, X_test = X_train / 255.0, X_test / 255.0 #normalize pixel value
[32m+  code cell:
[32m+    execution_count: 11
[32m+    source:
[32m+      class_names = {1:'Mountain', 0:'Forest'}
[32m+      
[32m+      plt.figure(figsize=(10,10))
[32m+      for i in range(25):
[32m+          plt.subplot(5,5,i+1)
[32m+          plt.xticks([])
[32m+          plt.yticks([])
[32m+          plt.grid(False)
[32m+          plt.imshow(X_train[i], cmap=plt.cm.binary)
[32m+          # The CIFAR labels happen to be arrays, 
[32m+          # which is why you need the extra index
[32m+          plt.xlabel(class_names[y_train[i][0]])
[32m+      plt.show()
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: display_data
[32m+        data:
[32m+          image/png: iVBORw0K...<snip base64, md5=4c685ba4332f4af5...>
[32m+          text/plain: <Figure size 720x720 with 25 Axes>

[0m[34m## deleted /cells/4:[0m
[31m-  code cell:
[31m-    execution_count: 77

[0m[34m## inserted before /cells/6:[0m
[32m+  code cell:
[32m+    execution_count: 12
[32m+    source:
[32m+      x = resnet.output
[32m+      x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten
[32m+      x = Dense(1024, activation='relu')(x)
[32m+      predictions = Dense(1, activation='sigmoid')(x)
[32m+      model = Model(resnet.input, predictions)
[32m+  code cell:
[32m+    execution_count: 13
[32m+    source:
[32m+      model.compile(optimizer='rmsprop',
[32m+                    loss='binary_crossentropy',
[32m+                    metrics=['accuracy'])
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[32m+          Instructions for updating:
[32m+          Use tf.where in 2.0, which has the same broadcast rule as np.where

[0m[34m## deleted /cells/6:[0m
[31m-  code cell:
[31m-    execution_count: 1
[31m-    outputs:
[31m-      output 0:
[31m-        output_type: stream
[31m-        name: stderr
[31m-        text:
[31m-          /Users/jonathansokoll/anaconda3/envs/U4-S3-DNN/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.
[31m-            warnings.warn('The output shape of `ResNet50(include_top=False)` '

[0m[34m## inserted before /cells/8:[0m
[32m+  code cell:
[32m+    execution_count: 14
[32m+    source:
[32m+      model.fit(X_train, 
[32m+                y_train, 
[32m+                epochs=10, 
[32m+                validation_data=(X_test, y_test))
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          Train on 561 samples, validate on 141 samples
[32m+          Epoch 1/10
[32m+          561/561 [==============================] - 145s 259ms/sample - loss: 1.2634 - acc: 0.8645 - val_loss: 1.0239 - val_acc: 0.4681
[32m+          Epoch 2/10
[32m+          561/561 [==============================] - 138s 245ms/sample - loss: 0.4812 - acc: 0.8984 - val_loss: 0.9088 - val_acc: 0.4681
[32m+          Epoch 3/10
[32m+          561/561 [==============================] - 138s 246ms/sample - loss: 0.0328 - acc: 0.9875 - val_loss: 1.4657 - val_acc: 0.4681
[32m+          Epoch 4/10
[32m+          561/561 [==============================] - 136s 242ms/sample - loss: 0.0365 - acc: 0.9857 - val_loss: 0.6846 - val_acc: 0.5106
[32m+          Epoch 5/10
[32m+          561/561 [==============================] - 137s 245ms/sample - loss: 0.2307 - acc: 0.9465 - val_loss: 0.8952 - val_acc: 0.4752
[32m+          Epoch 6/10
[32m+          561/561 [==============================] - 138s 246ms/sample - loss: 0.0232 - acc: 0.9875 - val_loss: 0.6921 - val_acc: 0.5319
[32m+          Epoch 7/10
[32m+          561/561 [==============================] - 138s 246ms/sample - loss: 0.1354 - acc: 0.9679 - val_loss: 0.8716 - val_acc: 0.5319
[32m+          Epoch 8/10
[32m+          561/561 [==============================] - 136s 243ms/sample - loss: 0.0075 - acc: 0.9964 - val_loss: 0.6657 - val_acc: 0.5532
[32m+          Epoch 9/10
[32m+          561/561 [==============================] - 138s 246ms/sample - loss: 0.0605 - acc: 0.9804 - val_loss: 1.1168 - val_acc: 0.4681
[32m+          Epoch 10/10
[32m+          561/561 [==============================] - 138s 246ms/sample - loss: 0.0316 - acc: 0.9893 - val_loss: 0.6584 - val_acc: 0.5745
[32m+      output 1:
[32m+        output_type: execute_result
[32m+        execution_count: 14
[32m+        data:
[32m+          text/plain: <tensorflow.python.keras.callbacks.History at 0x7f7dc6e59e10>
[32m+  code cell:
[32m+    execution_count: 15
[32m+    source:
[32m+      test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          141/141 - 26s - loss: 0.6584 - acc: 0.5745

[0m[34m## deleted /cells/8:[0m
[31m-  code cell:
[31m-    execution_count: 110
[31m-    outputs:
[31m-      output 0:
[31m-        output_type: stream
[31m-        name: stdout
[31m-        text:
[31m-          Train on 561 samples, validate on 141 samples
[31m-          Epoch 1/5
[31m-          561/561 [==============================] - 39s 69ms/sample - loss: 0.1216 - accuracy: 0.9715 - val_loss: 1.4221 - val_accuracy: 0.0000e+00
[31m-          Epoch 2/5
[31m-          561/561 [==============================] - 35s 62ms/sample - loss: 0.0410 - accuracy: 0.9875 - val_loss: 2.9222 - val_accuracy: 0.0000e+00
[31m-          Epoch 3/5
[31m-          561/561 [==============================] - 35s 62ms/sample - loss: 0.0646 - accuracy: 0.9697 - val_loss: 0.9962 - val_accuracy: 0.0000e+00
[31m-          Epoch 4/5
[31m-          561/561 [==============================] - 39s 70ms/sample - loss: 0.0723 - accuracy: 0.9733 - val_loss: 0.2627 - val_accuracy: 1.0000
[31m-          Epoch 5/5
[31m-          561/561 [==============================] - 38s 68ms/sample - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.4859 - val_accuracy: 1.0000
[31m-      output 1:
[31m-        output_type: execute_result
[31m-        execution_count: 110
[31m-        data:
[31m-          text/plain: <tensorflow.python.keras.callbacks.History at 0x7f980e9c6f60>

[0m[34m## inserted before /cells/10:[0m
[32m+  code cell:
[32m+    execution_count: 16
[32m+    source:
[32m+      X_train.shape[0]
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 16
[32m+        data:
[32m+          text/plain: 561
[32m+  code cell:
[32m+    execution_count: 25
[32m+    source:
[32m+      # Setup Architecture
[32m+      
[32m+      custom_model = Sequential()
[32m+      
[32m+      custom_model.add(Conv2D(32, (2,2), activation='relu', input_shape=(256,256,3)))
[32m+      custom_model.add(AveragePooling2D((2,2)))
[32m+      
[32m+      custom_model.add(Conv2D(64, (2,2), activation='relu'))
[32m+      custom_model.add(Dropout(0.2))
[32m+      custom_model.add(AveragePooling2D((2,2)))
[32m+      
[32m+      custom_model.add(Conv2D(64, (2,2), activation='relu'))
[32m+      custom_model.add(MaxPooling2D((2,2)))
[32m+      
[32m+      custom_model.add(Flatten())
[32m+      custom_model.add(Dense(64, activation='relu'))
[32m+      custom_model.add(Dropout(0.3))
[32m+      custom_model.add(Dense(1, activation='sigmoid'))
[32m+      
[32m+      custom_model.summary()
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          Model: "sequential_3"
[32m+          _________________________________________________________________
[32m+          Layer (type)                 Output Shape              Param #   
[32m+          =================================================================
[32m+          conv2d_9 (Conv2D)            (None, 255, 255, 32)      416       
[32m+          _________________________________________________________________
[32m+          average_pooling2d (AveragePo (None, 127, 127, 32)      0         
[32m+          _________________________________________________________________
[32m+          conv2d_10 (Conv2D)           (None, 126, 126, 64)      8256      
[32m+          _________________________________________________________________
[32m+          dropout_1 (Dropout)          (None, 126, 126, 64)      0         
[32m+          _________________________________________________________________
[32m+          average_pooling2d_1 (Average (None, 63, 63, 64)        0         
[32m+          _________________________________________________________________
[32m+          conv2d_11 (Conv2D)           (None, 62, 62, 64)        16448     
[32m+          _________________________________________________________________
[32m+          max_pooling2d_9 (MaxPooling2 (None, 31, 31, 64)        0         
[32m+          _________________________________________________________________
[32m+          flatten_3 (Flatten)          (None, 61504)             0         
[32m+          _________________________________________________________________
[32m+          dense_6 (Dense)              (None, 64)                3936320   
[32m+          _________________________________________________________________
[32m+          dropout_2 (Dropout)          (None, 64)                0         
[32m+          _________________________________________________________________
[32m+          dense_7 (Dense)              (None, 1)                 65        
[32m+          =================================================================
[32m+          Total params: 3,961,505
[32m+          Trainable params: 3,961,505
[32m+          Non-trainable params: 0
[32m+          _________________________________________________________________
[32m+  code cell:
[32m+    execution_count: 26
[32m+    source:
[32m+      # Compile Model
[32m+      custom_model.compile(optimizer='rmsprop',
[32m+                    loss='binary_crossentropy',
[32m+                    metrics=['accuracy'])
[32m+  code cell:
[32m+    execution_count: 27
[32m+    source:
[32m+      # Fit Model
[32m+      custom_model.fit(X_train, 
[32m+                y_train, 
[32m+                epochs=10, 
[32m+                validation_data=(X_test, y_test))
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          Train on 561 samples, validate on 141 samples
[32m+          Epoch 1/10
[32m+          561/561 [==============================] - 25s 45ms/sample - loss: 1.4571 - acc: 0.6417 - val_loss: 0.4437 - val_acc: 0.8298
[32m+          Epoch 2/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.4944 - acc: 0.7665 - val_loss: 0.4046 - val_acc: 0.8582
[32m+          Epoch 3/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.3490 - acc: 0.8449 - val_loss: 0.2385 - val_acc: 0.8936
[32m+          Epoch 4/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.4469 - acc: 0.8271 - val_loss: 0.2440 - val_acc: 0.9007
[32m+          Epoch 5/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.2245 - acc: 0.9216 - val_loss: 0.3044 - val_acc: 0.8794
[32m+          Epoch 6/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.3469 - acc: 0.8681 - val_loss: 0.2391 - val_acc: 0.9078
[32m+          Epoch 7/10
[32m+          561/561 [==============================] - 25s 45ms/sample - loss: 0.2546 - acc: 0.9162 - val_loss: 0.2116 - val_acc: 0.8936
[32m+          Epoch 8/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.2187 - acc: 0.9091 - val_loss: 0.1562 - val_acc: 0.9645
[32m+          Epoch 9/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.2437 - acc: 0.9216 - val_loss: 0.1502 - val_acc: 0.9007
[32m+          Epoch 10/10
[32m+          561/561 [==============================] - 24s 42ms/sample - loss: 0.2240 - acc: 0.9037 - val_loss: 0.1840 - val_acc: 0.9504
[32m+      output 1:
[32m+        output_type: execute_result
[32m+        execution_count: 27
[32m+        data:
[32m+          text/plain: <tensorflow.python.keras.callbacks.History at 0x7f7d57137f98>
[32m+  code cell:
[32m+    execution_count: 28
[32m+    source:
[32m+      test_loss_custom, test_acc_custom = custom_model.evaluate(X_test, y_test, verbose=2)
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          141/141 - 1s - loss: 0.1840 - acc: 0.9504
[32m+  code cell:
[32m+    execution_count: 62
[32m+    source:
[32m+      # !wget https://cdn.mos.cms.futurecdn.net/ntFmJUZ8tw3ULD3tkBaAtf-650-80.jpg #random internet photo
[32m+      # !wget https://www.nps.gov/piro/learn/nature/images/DeepForest_1.JPG
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          --2020-02-21 21:40:12--  https://www.nps.gov/piro/learn/nature/images/DeepForest_1.JPG
[32m+          Resolving www.nps.gov (www.nps.gov)... 23.13.171.207, 2600:1408:8400:5a3::20ce, 2600:1408:8400:598::20ce
[32m+          Connecting to www.nps.gov (www.nps.gov)|23.13.171.207|:443... connected.
[32m+          HTTP request sent, awaiting response... 200 OK
[32m+          Length: unspecified [image/jpeg]
[32m+          Saving to: ‘DeepForest_1.JPG’
[32m+          
[32m+          DeepForest_1.JPG        [  <=>               ]   2.07M  6.44MB/s    in 0.3s    
[32m+          
[32m+          2020-02-21 21:40:13 (6.44 MB/s) - ‘DeepForest_1.JPG’ saved [2173277]
[32m+          
[32m+  code cell:
[32m+    execution_count: 66
[32m+    source:
[32m+      img = Image.open('ntFmJUZ8tw3ULD3tkBaAtf-650-80.jpg')
[32m+      img = [img.resize((256, 256), Image.ANTIALIAS)]
[32m+      
[32m+      test_image = np.asarray([image.img_to_array(img[0])])
[32m+      
[32m+      prediction = custom_model.predict(test_image)
[32m+      print(f'The model predicts the image is a {class_names[int(prediction[0][0])]}')
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          The model predicts the image is a Mountain
[32m+  code cell:
[32m+    execution_count: 68
[32m+    source:
[32m+      img_f = Image.open('DeepForest_1.JPG')
[32m+      img_f = [img_f.resize((256, 256), Image.ANTIALIAS)]
[32m+      
[32m+      test_image_2 = np.asarray([image.img_to_array(img_f[0])])
[32m+      
[32m+      prediction_2 = custom_model.predict(test_image_2)
[32m+      print(f'The model predicts the image is a {class_names[int(prediction_2[0][0])]}')
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          The model predicts the image is a Mountain
[32m+  code cell:
[32m+    execution_count: 72
[32m+    source:
[32m+      img_f[0]
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 72
[32m+        data:
[32m+          image/png: iVBORw0K...<snip base64, md5=40ba46f032d68f36...>
[32m+          text/plain: <PIL.Image.Image image mode=RGB size=256x256 at 0x7F7D50D73438>

[0m[34m## deleted /cells/10-12:[0m
[31m-  code cell:
[31m-    execution_count: 95
[31m-    outputs:
[31m-      output 0:
[31m-        output_type: stream
[31m-        name: stdout
[31m-        text:
[31m-          Model: "sequential_8"
[31m-          _________________________________________________________________
[31m-          Layer (type)                 Output Shape              Param #   
[31m-          =================================================================
[31m-          conv2d_7 (Conv2D)            (None, 215, 215, 32)      9632      
[31m-          _________________________________________________________________
[31m-          max_pooling2d_15 (MaxPooling (None, 43, 43, 32)        0         
[31m-          _________________________________________________________________
[31m-          conv2d_8 (Conv2D)            (None, 39, 39, 64)        51264     
[31m-          _________________________________________________________________
[31m-          max_pooling2d_16 (MaxPooling (None, 13, 13, 64)        0         
[31m-          _________________________________________________________________
[31m-          conv2d_9 (Conv2D)            (None, 9, 9, 64)          102464    
[31m-          _________________________________________________________________
[31m-          flatten_1 (Flatten)          (None, 5184)              0         
[31m-          _________________________________________________________________
[31m-          dense_15 (Dense)             (None, 64)                331840    
[31m-          _________________________________________________________________
[31m-          dense_16 (Dense)             (None, 1)                 65        
[31m-          =================================================================
[31m-          Total params: 495,265
[31m-          Trainable params: 495,265
[31m-          Non-trainable params: 0
[31m-          _________________________________________________________________
[31m-  code cell:
[31m-    execution_count: 96
[31m-    source:
[31m-      # Compile Model
[31m-  code cell:
[31m-    execution_count: 99
[31m-    source:
[31m-      # Fit Model
[31m-    outputs:
[31m-      output 0:
[31m-        output_type: stream
[31m-        name: stdout
[31m-        text:
[31m-          Train on 561 samples, validate on 141 samples
[31m-          Epoch 1/5
[31m-          561/561 [==============================] - 18s 32ms/sample - loss: 0.2667 - accuracy: 0.9073 - val_loss: 0.1186 - val_accuracy: 0.9858
[31m-          Epoch 2/5
[31m-          561/561 [==============================] - 18s 32ms/sample - loss: 0.2046 - accuracy: 0.9073 - val_loss: 0.3342 - val_accuracy: 0.8511
[31m-          Epoch 3/5
[31m-          561/561 [==============================] - 18s 32ms/sample - loss: 0.1778 - accuracy: 0.9287 - val_loss: 0.2746 - val_accuracy: 0.8723
[31m-          Epoch 4/5
[31m-          561/561 [==============================] - 18s 32ms/sample - loss: 0.1681 - accuracy: 0.9323 - val_loss: 0.8487 - val_accuracy: 0.5957
[31m-          Epoch 5/5
[31m-          561/561 [==============================] - 18s 32ms/sample - loss: 0.1606 - accuracy: 0.9394 - val_loss: 0.3903 - val_accuracy: 0.8582
[31m-      output 1:
[31m-        output_type: execute_result
[31m-        execution_count: 99
[31m-        data:
[31m-          text/plain: <tensorflow.python.keras.callbacks.History at 0x7f97388777f0>

[0mnbdiff /tmp/jNF75e_LS_DS_432_Convolutional_Neural_Networks_Lecture.ipynb module2-convolutional-neural-networks/LS_DS_432_Convolutional_Neural_Networks_Lecture.ipynb
--- /tmp/jNF75e_LS_DS_432_Convolutional_Neural_Networks_Lecture.ipynb  2020-02-23 23:22:16.918370
+++ module2-convolutional-neural-networks/LS_DS_432_Convolutional_Neural_Networks_Lecture.ipynb  2020-02-21 18:17:07.773278
[34m## modified /cells/3/outputs/0/data/text/plain:[0m
[31m-  <IPython.lib.display.YouTubeVideo at 0x7fdae8835b00>
[32m+  <IPython.lib.display.YouTubeVideo at 0x7f379431efd0>

[0m[34m## modified /cells/6/outputs/0/data/text/plain:[0m
[31m-  <IPython.lib.display.YouTubeVideo at 0x7fdb0833c1d0>
[32m+  <IPython.lib.display.YouTubeVideo at 0x7f3796ff85f8>

[0m[34m## inserted before /cells/9:[0m
[32m+  code cell:
[32m+    execution_count: 11
[32m+    metadata (unknown keys):
[32m+      colab:
[32m+        base_uri: https://localhost:8080/
[32m+        height: 243
[32m+      colab_type: code
[32m+      id: OsAcbKvoeaqU
[32m+      outputId: dbb28705-36c7-4691-f7df-e9f82e3ee91e
[32m+    source:
[32m+      # !pip install --upgrade scikit-image
[32m+      # !pip install --upgrade numpy
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: stream
[32m+        name: stdout
[32m+        text:
[32m+          Collecting scikit-image
[32m+            Downloading scikit_image-0.16.2-cp36-cp36m-manylinux1_x86_64.whl (26.5 MB)
[32m+          [K     |████████████████████████████████| 26.5 MB 3.3 MB/s eta 0:00:01
[32m+          [?25hRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (2.3.0)
[32m+          Requirement already satisfied, skipping upgrade: networkx>=2.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (2.1)
[32m+          Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (0.5.2)
[32m+          Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (3.0.3)
[32m+          Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (5.2.0)
[32m+          Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from scikit-image) (1.1.0)
[32m+          Requirement already satisfied, skipping upgrade: decorator>=4.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.3.0)
[32m+          Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from PyWavelets>=0.4.0->scikit-image) (1.15.0)
[32m+          Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.0.1)
[32m+          Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.2.0)
[32m+          Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.7.3)
[32m+          Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)
[32m+          Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (41.6.0)
[32m+          Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.11.0)
[32m+          Installing collected packages: scikit-image
[32m+            Attempting uninstall: scikit-image
[32m+              Found existing installation: scikit-image 0.14.2
[32m+              Uninstalling scikit-image-0.14.2:
[32m+                Successfully uninstalled scikit-image-0.14.2
[32m+          Successfully installed scikit-image-0.16.2
[32m+          Collecting numpy
[32m+            Downloading numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)
[32m+          [K     |████████████████████████████████| 20.1 MB 3.1 MB/s eta 0:00:01     |███████████████████████████▉    | 17.5 MB 3.1 MB/s eta 0:00:01
[32m+          [?25hInstalling collected packages: numpy
[32m+            Attempting uninstall: numpy
[32m+              Found existing installation: numpy 1.15.0
[32m+              Uninstalling numpy-1.15.0:
[32m+                Successfully uninstalled numpy-1.15.0
[32m+          Successfully installed numpy-1.18.1

[0m[34m## replaced /cells/9/execution_count:[0m
[31m-  29
[32m+  1

[0m[34m## replaced /cells/9/outputs/0/execution_count:[0m
[31m-  29
[32m+  1

[0m[34m## replaced /cells/10/execution_count:[0m
[31m-  31
[32m+  2

[0m[34m## inserted before /cells/10/outputs/0:[0m
[32m+  output:
[32m+    output_type: display_data
[32m+    data:
[32m+      image/png: iVBORw0K...<snip base64, md5=35511bc22cb4899c...>
[32m+      text/plain: <Figure size 432x288 with 1 Axes>

[0m[34m## deleted /cells/10/outputs/0:[0m
[31m-  output:
[31m-    output_type: display_data
[31m-    data:
[31m-      image/png: iVBORw0K...<snip base64, md5=e7aa49b6269bc434...>
[31m-      text/plain: <Figure size 432x288 with 1 Axes>
[31m-    metadata (unknown keys):
[31m-      needs_background: light

[0m[34m## replaced /cells/11/execution_count:[0m
[31m-  36
[32m+  3

[0m[34m## replaced /cells/11/outputs/0/execution_count:[0m
[31m-  36
[32m+  3

[0m[34m## replaced /cells/12/execution_count:[0m
[31m-  38
[32m+  4

[0m[34m## replaced /cells/12/outputs/0/execution_count:[0m
[31m-  38
[32m+  4

[0m[34m## replaced /cells/13/execution_count:[0m
[31m-  39
[32m+  5

[0m[34m## inserted before /cells/13/outputs/0:[0m
[32m+  output:
[32m+    output_type: display_data
[32m+    data:
[32m+      image/png: iVBORw0K...<snip base64, md5=b31e3ad78552dbce...>
[32m+      text/plain: <Figure size 432x288 with 1 Axes>

[0m[34m## deleted /cells/13/outputs/0:[0m
[31m-  output:
[31m-    output_type: display_data
[31m-    data:
[31m-      image/png: iVBORw0K...<snip base64, md5=4651029ca7d57b7e...>
[31m-      text/plain: <Figure size 432x288 with 1 Axes>
[31m-    metadata (unknown keys):
[31m-      needs_background: light

[0m[34m## replaced /cells/19/execution_count:[0m
[31m-  40
[32m+  6

[0m[34m## inserted before /cells/19/outputs/0:[0m
[32m+  output:
[32m+    output_type: stream
[32m+    name: stderr
[32m+    text:
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[32m+      /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[32m+        np_resource = np.dtype([("resource", np.ubyte, 1)])

[0m[34m## replaced /cells/20/execution_count:[0m
[31m-  41
[32m+  21

[0m[34m## inserted before /cells/21:[0m
[32m+  code cell:
[32m+    execution_count: 26
[32m+    source:
[32m+      train_labels.shape
[32m+    outputs:
[32m+      output 0:
[32m+        output_type: execute_result
[32m+        execution_count: 26
[32m+        data:
[32m+          text/plain: (50000, 1)

[0m[34m## replaced /cells/21/execution_count:[0m
[31m-  42
[32m+  8

[0m[34m## inserted before /cells/21/outputs/0:[0m
[32m+  output:
[32m+    output_type: display_data
[32m+    data:
[32m+      image/png: iVBORw0K...<snip base64, md5=1d83cc4d02419e77...>
[32m+      text/plain: <Figure size 720x720 with 25 Axes>

[0m[34m## deleted /cells/21/outputs/0:[0m
[31m-  output:
[31m-    output_type: display_data
[31m-    data:
[31m-      image/png: iVBORw0K...<snip base64, md5=836c8b9969a987a7...>
[31m-      text/plain: <Figure size 720x720 with 25 Axes>

[0m[34m## replaced /cells/22/execution_count:[0m
[31m-  44
[32m+  9

[0m[34m## replaced /cells/22/outputs/0/execution_count:[0m
[31m-  44
[32m+  9

[0m[34m## replaced /cells/23/execution_count:[0m
[31m-  51
[32m+  10

[0m[34m## replaced /cells/23/outputs/0/execution_count:[0m
[31m-  51
[32m+  10

[0m[34m## replaced /cells/24/execution_count:[0m
[31m-  52
[32m+  11

[0m[34m## modified /cells/24/outputs/0/text:[0m
[36m@@ -1,22 +1,25 @@[m
[31m-Model: "sequential_5"[m
[32m+[m[32mWARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.[m
[32m+[m[32mInstructions for updating:[m
[32m+[m[32mCall initializer instance with the dtype argument instead of passing it to the constructor[m
[32m+[m[32mModel: "sequential"[m
 _________________________________________________________________[m
 Layer (type)                 Output Shape              Param #   [m
 =================================================================[m
[31m-conv2d_13 (Conv2D)           (None, 30, 30, 32)        896       [m
[32m+[m[32mconv2d (Conv2D)              (None, 30, 30, 32)        896[m[41m       [m
 _________________________________________________________________[m
[31m-max_pooling2d_9 (MaxPooling2 (None, 15, 15, 32)        0         [m
[32m+[m[32mmax_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0[m[41m         [m
 _________________________________________________________________[m
[31m-conv2d_14 (Conv2D)           (None, 13, 13, 64)        18496     [m
[32m+[m[32mconv2d_1 (Conv2D)            (None, 13, 13, 64)        18496[m[41m     [m
 _________________________________________________________________[m
[31m-max_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         [m
[32m+[m[32mmax_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0[m[41m         [m
 _________________________________________________________________[m
[31m-conv2d_15 (Conv2D)           (None, 4, 4, 64)          36928     [m
[32m+[m[32mconv2d_2 (Conv2D)            (None, 4, 4, 64)          36928[m[41m     [m
 _________________________________________________________________[m
[31m-flatten_2 (Flatten)          (None, 1024)              0         [m
[32m+[m[32mflatten (Flatten)            (None, 1024)              0[m[41m         [m
 _________________________________________________________________[m
[31m-dense_2 (Dense)              (None, 64)                65600     [m
[32m+[m[32mdense (Dense)                (None, 64)                65600[m[41m     [m
 _________________________________________________________________[m
[31m-dense_3 (Dense)              (None, 10)                650       [m
[32m+[m[32mdense_1 (Dense)              (None, 10)                650[m[41m       [m
 =================================================================[m
 Total params: 122,570[m
 Trainable params: 122,570[m

[0m[34m## replaced /cells/26/execution_count:[0m
[31m-  53
[32m+  12

[0m[34m## replaced /cells/27/execution_count:[0m
[31m-  54
[32m+  13

[0m[34m## modified /cells/27/outputs/0/text:[0m
[36m@@ -1,21 +1,21 @@[m
 Train on 50000 samples, validate on 10000 samples[m
 Epoch 1/10[m
[31m-50000/50000 [==============================] - 43s 859us/sample - loss: 1.5203 - accuracy: 0.4448 - val_loss: 1.2410 - val_accuracy: 0.5498[m
[32m+[m[32m50000/50000 [==============================] - 12s 243us/sample - loss: 1.5192 - acc: 0.4443 - val_loss: 1.2547 - val_acc: 0.5471[m
 Epoch 2/10[m
[31m-50000/50000 [==============================] - 41s 824us/sample - loss: 1.1562 - accuracy: 0.5903 - val_loss: 1.0852 - val_accuracy: 0.6094[m
[32m+[m[32m50000/50000 [==============================] - 11s 210us/sample - loss: 1.1638 - acc: 0.5882 - val_loss: 1.1084 - val_acc: 0.6103[m
 Epoch 3/10[m
[31m-50000/50000 [==============================] - 37s 748us/sample - loss: 1.0153 - accuracy: 0.6443 - val_loss: 0.9633 - val_accuracy: 0.6612[m
[32m+[m[32m50000/50000 [==============================] - 11s 210us/sample - loss: 1.0142 - acc: 0.6436 - val_loss: 0.9982 - val_acc: 0.6526[m
 Epoch 4/10[m
[31m-50000/50000 [==============================] - 38s 769us/sample - loss: 0.9234 - accuracy: 0.6761 - val_loss: 0.9613 - val_accuracy: 0.6633[m
[32m+[m[32m50000/50000 [==============================] - 10s 209us/sample - loss: 0.9224 - acc: 0.6774 - val_loss: 0.9448 - val_acc: 0.6751[m
 Epoch 5/10[m
[31m-50000/50000 [==============================] - 39s 782us/sample - loss: 0.8479 - accuracy: 0.7025 - val_loss: 0.9722 - val_accuracy: 0.6613[m
[32m+[m[32m50000/50000 [==============================] - 10s 209us/sample - loss: 0.8519 - acc: 0.7016 - val_loss: 0.9241 - val_acc: 0.6808[m
 Epoch 6/10[m
[31m-50000/50000 [==============================] - 42s 833us/sample - loss: 0.7862 - accuracy: 0.7258 - val_loss: 0.9456 - val_accuracy: 0.6703[m
[32m+[m[32m50000/50000 [==============================] - 10s 209us/sample - loss: 0.7929 - acc: 0.7232 - val_loss: 0.8959 - val_acc: 0.6877[m
 Epoch 7/10[m
[31m-50000/50000 [==============================] - 44s 883us/sample - loss: 0.7297 - accuracy: 0.7436 - val_loss: 0.8979 - val_accuracy: 0.6948[m
[32m+[m[32m50000/50000 [==============================] - 10s 209us/sample - loss: 0.7424 - acc: 0.7402 - val_loss: 0.8628 - val_acc: 0.7046[m
 Epoch 8/10[m
[31m-50000/50000 [==============================] - 44s 889us/sample - loss: 0.6852 - accuracy: 0.7592 - val_loss: 0.9226 - val_accuracy: 0.6918[m
[32m+[m[32m50000/50000 [==============================] - 10s 208us/sample - loss: 0.7023 - acc: 0.7563 - val_loss: 0.8802 - val_acc: 0.7055[m
 Epoch 9/10[m
[31m-50000/50000 [==============================] - 41s 827us/sample - loss: 0.6458 - accuracy: 0.7743 - val_loss: 0.8872 - val_accuracy: 0.6990[m
[32m+[m[32m50000/50000 [==============================] - 11s 211us/sample - loss: 0.6610 - acc: 0.7694 - val_loss: 0.9562 - val_acc: 0.6940[m
 Epoch 10/10[m
[31m-50000/50000 [==============================] - 42s 831us/sample - loss: 0.6003 - accuracy: 0.7899 - val_loss: 0.8644 - val_accuracy: 0.7113[m
[32m+[m[32m50000/50000 [==============================] - 10s 208us/sample - loss: 0.6266 - acc: 0.7802 - val_loss: 0.8664 - val_acc: 0.7125[m

[0m[34m## modified /cells/27/outputs/1/data/text/plain:[0m
[31m-  <tensorflow.python.keras.callbacks.History at 0x7fdab8af5a58>
[32m+  <tensorflow.python.keras.callbacks.History at 0x7fbdbe665358>

[0m[34m## replaced /cells/27/outputs/1/execution_count:[0m
[31m-  54
[32m+  13

[0m[34m## replaced /cells/28/execution_count:[0m
[31m-  55
[32m+  14

[0m[34m## modified /cells/28/outputs/0/text:[0m
[36m@@ -1 +1 @@[m
[31m-10000/10000 - 3s - loss: 0.8644 - accuracy: 0.7113[m
[32m+[m[32m10000/10000 - 1s - loss: 0.8664 - acc: 0.7125[m

[0m[34m## replaced /cells/34/execution_count:[0m
[31m-  56
[32m+  15

[0m[34m## replaced /cells/35/execution_count:[0m
[31m-  58
[32m+  16

[0m[34m## replaced /cells/36/execution_count:[0m
[31m-  59
[32m+  17

[0m[34m## replaced /cells/36/outputs/0/execution_count:[0m
[31m-  59
[32m+  17

[0m[34m## replaced /cells/37/execution_count:[0m
[31m-  60
[32m+  18

[0m[34m## inserted before /cells/37/outputs/0:[0m
[32m+  output:
[32m+    output_type: stream
[32m+    name: stdout
[32m+    text:
[32m+      Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5
[32m+      102858752/102853048 [==============================] - 1s 0us/step
[32m+      Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json
[32m+      40960/35363 [==================================] - 0s 1us/step
[32m+      [('n04037443', 'racer', 0.90904033), ('n04285008', 'sports_car', 0.08587628), ('n04461696', 'tow_truck', 0.0025079222)]

[0m[34m## deleted /cells/37/outputs/0:[0m
[31m-  output:
[31m-    output_type: stream
[31m-    name: stdout
[31m-    text:
[31m-      [('n04037443', 'racer', 0.90904015), ('n04285008', 'sports_car', 0.08587643), ('n04461696', 'tow_truck', 0.0025079146)]

[0m[34m## replaced /cells/37/outputs/1/execution_count:[0m
[31m-  60
[32m+  18

[0m[34m## replaced /cells/38/execution_count:[0m
[31m-  61
[32m+  19

[0m[34m## replaced /cells/38/outputs/0/execution_count:[0m
[31m-  61
[32m+  19

[0m[34m## replaced /cells/39/execution_count:[0m
[31m-  62
[32m+  20

[0m[34m## modified /cells/39/outputs/0/text:[0m
[36m@@ -1 +1 @@[m
[31m-[('n07753592', 'banana', 0.06412234), ('n03532672', 'hook', 0.060046483), ('n03498962', 'hatchet', 0.058439624)][m
[32m+[m[32m[('n07753592', 'banana', 0.06412225), ('n03532672', 'hook', 0.060046516), ('n03498962', 'hatchet', 0.058439627)][m

[0m[34m## modified /cells/39/outputs/1/data/text/plain:[0m
[31m-  0.06412234
[32m+  0.06412225

[0m[34m## replaced /cells/39/outputs/1/execution_count:[0m
[31m-  62
[32m+  20

[0m[34m## modified /metadata/kernelspec/display_name:[0m
[31m-  U4-S3-DNN (Python 3.7)
[32m+  conda_amazonei_tensorflow_p36

[0m[34m## modified /metadata/kernelspec/name:[0m
[31m-  u4-s3-dnn
[32m+  conda_amazonei_tensorflow_p36

[0m[34m## modified /metadata/language_info/version:[0m
[31m-  3.7.3
[32m+  3.6.5

[0m[34m## replaced /nbformat_minor:[0m
[31m-  2
[32m+  4

[0m