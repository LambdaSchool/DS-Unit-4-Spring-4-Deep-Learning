{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HAN_LS_DS_Uni_4_Sprint_3_Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.14.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehanchung/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/SC/HAN_LS_DS_Uni_4_Sprint_3_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF7-DRn-NVJu",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9-hkyvtN90D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e056121-73be-49f4-976b-dfa351c8085d"
      },
      "source": [
        "!pip install numpy==1.16.1\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "c424cefb-7681-43e8-f4b6-09546215e0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "6fe05e09-f909-4397-a3bd-7e4d0d068a8a"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "\n",
        "batch_size = 46\n",
        "max_features = len(word_index.values())\n",
        "maxlen = 200\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "\n",
        "\n",
        "print('Build model...')\n",
        "# TODO - your code!\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "# using sigmoid because the provided model.compile code uses crossentropy loss\n",
        "# and y has shape of (N,)\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982 train sequences\n",
            "2246 test sequences\n",
            "Pad sequences (samples x time)\n",
            "X_train shape: (8982, 200)\n",
            "X_test shape: (2246, 200)\n",
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4wRjuOINVJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "01a5b0e3-5455-452f-ed70-ded6b27b4bdf"
      },
      "source": [
        "# You should only run this cell once your model has been properly configured\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "score, acc = model.evaluate(X_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "8982/8982 [==============================] - 87s 10ms/sample - loss: nan - acc: 0.0469 - val_loss: nan - val_acc: 0.0374\n",
            "2246/2246 [==============================] - 5s 2ms/sample - loss: nan - acc: 0.0387\n",
            "Test score: nan\n",
            "Test accuracy: 0.03873553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDMT22oUNVJ8",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "\n",
        "Neural networks expect fixed size inputs, so by padding the sequences/sentences we can ensure that the network gets sentences of the same length every time.\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "\n",
        "LSTM has better long term dependencies compare to simple RNN. It achives that by adding a remember/forget gate inside a single cell. That gate help prevent vanishing gradient problems for long time horizon unrolling.\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "\n",
        "Time dependent dataset can be modeled using LSTM/RNN. For example, 1) using weather data to predict next day's temperature, 2) using financial/economic data to predict next day's stock price, 3) using large corpus of sentences/words to predict the next word/character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "3cca7aa0-1011-433b-f20c-8d3fe5136898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google_images_download in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (from google_images_download) (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "769cb2db-8a83-4f35-b8a7-82b29f2e9dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"animal pond\", \"limit\": 4, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = animal pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
            "Completed Image ====> 1.Pondanimals.GIF\n",
            "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
            "Completed Image ====> 2.hqdefault.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
            "Completed Image ====> 3.PKLS4116_inline.png\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
            "Completed Image ====> 4.PKLS4116.png\n",
            "\n",
            "Errors: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goal* - also check for fish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {}
      },
      "source": [
        "# You've got something to do in this cell. ;)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "    \"\"\" Scans image for Frogs\n",
        "    \n",
        "    Should return a integer with the number of frogs detected in an\n",
        "    image.\n",
        "    \n",
        "    Inputs:\n",
        "    ---------\n",
        "    img:  Precrossed image ready for predicftion\n",
        "    \n",
        "    Returns: \n",
        "    ---------\n",
        "    frogs (int):  Count of predicted frogs in the image\n",
        "    \"\"\"\n",
        "    # Your Code Here\n",
        "    # TODO - your code!\n",
        "    resnet = ResNet50(include_top=True, weights='imagenet')\n",
        "    pred = resnet.predict(img)\n",
        "    # looking at the top 5 detected classes only\n",
        "    result = decode_predictions(pred, top=5)[0]\n",
        "    frog_count = list(sum(result, ()))\n",
        "    frog_count = [str(i) for i in frog_count]\n",
        "    frog_count = (' '.join(frog_count)).count('frog')\n",
        "    return frog_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ3wBjvzNVKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_predictions(urls):\n",
        "    image_data = []\n",
        "    frogs = []\n",
        "    for url in urls:\n",
        "        x = process_img_path(url)\n",
        "        x = image.img_to_array(x)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        image_data.append(x)\n",
        "        frogs.append(img_contains_frog(x))\n",
        "    \n",
        "    return image_data,frogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7uiaOV7NVKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "438fce42-4e71-4734-de4d-fbcc1c19c9c3"
      },
      "source": [
        "f, axarr = plt.subplots(2,2)\n",
        "\n",
        "imgs, frogs = display_predictions(absolute_image_paths[0]['animal pond'])\n",
        "\n",
        "for x,y in [(0,0),(0,1), (1,0), (1,1)]:  \n",
        "    axarr[x,y].imshow(np.squeeze(imgs[x], axis=0))\n",
        "    axarr[x,y].set_title(f\"Frog: {frogs[x]}\")\n",
        "    axarr[x,y].axis('off')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAEICAYAAADBWUaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__  Autoencoders can be used to reduce the dimensionality of its inputs, e.g., **compression**, by taking the middle layer as the output. The decoder will be able to reproduce the input from the middle output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "\n",
        "Making the right recommendation for business decisions based on the models and data. Given my decade plus experience in investing across both public equity and startups, I will be able frame the questions and select the right models and data to construct a viewpoint for decision making.\n",
        "\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "\n",
        "Going full stack. Data Science is about learning something from Data. So where does data come from, how does data going into the production pipeline, how will the distribution of the data change over time, and how to design a data feedback loop so the process can be iterative. And I would love to ship actual product, be it dashboard for visualization or an web API endpoint for frontend to consume.\n",
        "\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "\n",
        "I am not a prophet and I have no clue what will be the next big buzzword that replace data mining/big data/data science. The job will be the same. More data, more learning from data, and more data based products.\n",
        "\n",
        "- What are the threats posed by AI to our society?\n",
        "\n",
        "AI is merely a new tool people invented to make our lives easier. We have been through different cycles of innovation for the past thousands of years and AI will be no different. We will thus see the same threats posted by iron in bronze age or mechanical machines in agricultural age.\n",
        "\n",
        "- How do you think we can counteract those threats? \n",
        "\n",
        "That is way above my paygrade. It requires the political class to make the right rules and regulations to 'counteract' those threats if necessary. \n",
        "\n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "Possible, yes. Probable, no. At least not in my lifetime. In the long run, we are all dead.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdoA5pH2NVKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "7d60a047-e787-4ee6-b516-904ec3d496b2"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRlHbWfwSff6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}