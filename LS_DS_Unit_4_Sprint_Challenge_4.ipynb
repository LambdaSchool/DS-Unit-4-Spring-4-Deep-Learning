{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - RNNs\n",
    "\n",
    "Use an RNN to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=723812,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982,), (8982,), (2246,), (2246,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(word) for word in word_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, SimpleRNN\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 50\n",
    "batch_size = 64\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8982, 500), (2246, 500))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 46)\n",
    "y_test = np_utils.to_categorical(y_test, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 26s 3ms/step - loss: 2.2640 - acc: 0.4431 - val_loss: 2.0236 - val_acc: 0.4911\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 1.8861 - acc: 0.5190 - val_loss: 1.8025 - val_acc: 0.5303\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 1.6138 - acc: 0.5828 - val_loss: 1.9079 - val_acc: 0.5223\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 1.3220 - acc: 0.6641 - val_loss: 1.8618 - val_acc: 0.5606\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.9901 - acc: 0.7531 - val_loss: 1.9170 - val_acc: 0.5681\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.7266 - acc: 0.8198 - val_loss: 2.1229 - val_acc: 0.5539\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.5437 - acc: 0.8673 - val_loss: 2.1082 - val_acc: 0.5748\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.4258 - acc: 0.8995 - val_loss: 2.1999 - val_acc: 0.5686\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.3250 - acc: 0.9257 - val_loss: 2.2242 - val_acc: 0.5801\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 10s 1ms/step - loss: 0.2804 - acc: 0.9349 - val_loss: 2.2876 - val_acc: 0.5654\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64))\n",
    "model.add(SimpleRNN(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(64))\n",
    "\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPn6c0x21gu1"
   },
   "source": [
    "Conclusion - RNN runs, and gives pretty decent improvement over a naive model. To *really* improve the model, more playing with parameters would help. Also - RNN may well not be the best approach here, but it is at least a valid one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_images_download\n",
      "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
      "Collecting selenium (from google_images_download)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
      "\u001b[K    100% |████████████████████████████████| 911kB 7.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from selenium->google_images_download) (1.23)\n",
      "Building wheels for collected packages: google-images-download\n",
      "  Running setup.py bdist_wheel for google-images-download ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
      "Successfully built google-images-download\n",
      "Installing collected packages: selenium, google-images-download\n",
      "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = animal pond\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
      "Completed Image ====> 1.Pondanimals.GIF\n",
      "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
      "Completed Image ====> 2.hqdefault.jpg\n",
      "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
      "Completed Image ====> 3.PKLS4116_inline.png\n",
      "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
      "URLError on an image...trying next one... Error: HTTP Error 503: Service Temporarily Unavailable\n",
      "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
      "Completed Image ====> 4.PKLS4116.png\n",
      "Image URL: https://i.pinimg.com/originals/57/5c/5b/575c5b5c441e27ff04eb50571ee30127.jpg\n",
      "Completed Image ====> 5.575c5b5c441e27ff04eb50571ee30127.jpg\n",
      "\n",
      "Errors: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\": \"animal pond\", \"limit\": 5, \"print_urls\": True}\n",
    "absolute_image_paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goal* - also check for fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img_path(img_path):\n",
    "    return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=3)[0]\n",
    "    print(results)\n",
    "    for entry in results:\n",
    "        if (entry[1] == 'bullfrog') or (entry[1] == 'tree frog') or (entry[1] == 'tailed frog') or (entry[1] == 'frog'):\n",
    "            return entry[2]\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls = [\"./downloads/animal pond/5.575c5b5c441e27ff04eb50571ee30127.jpg\",\n",
    "            \"./downloads/animal pond/4.PKLS4116.png\",\n",
    "           \"./downloads/animal pond/3.PKLS4116_inline.png\",\n",
    "           \"./downloads/animal pond/2.hqdefault.jpg\",\n",
    "           \"./downloads/animal pond/1.Pondanimals.GIF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n02116738', 'African_hunting_dog', 0.6101571), ('n02105162', 'malinois', 0.19866791), ('n02114712', 'red_wolf', 0.051153056)]\n",
      "[('n03485794', 'handkerchief', 0.8822726), ('n02834397', 'bib', 0.022680892), ('n03291819', 'envelope', 0.020095171)]\n",
      "[('n04243546', 'slot', 0.8712449), ('n04476259', 'tray', 0.04993588), ('n03908618', 'pencil_box', 0.023072386)]\n",
      "[('n01443537', 'goldfish', 0.8495859), ('n01631663', 'eft', 0.06760218), ('n02536864', 'coho', 0.035163548)]\n",
      "[('n03598930', 'jigsaw_puzzle', 0.8680313), ('n06359193', 'web_site', 0.06410024), ('n02834397', 'bib', 0.021264324)]\n"
     ]
    }
   ],
   "source": [
    "for i in img_urls:\n",
    "    img_contains_frog(process_img_path(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ResNet50 has a hard time evaluating cartoon images.  As seen above, it misclassied every single image that was a cartoon.  This makes sense as the training data is majorly composed of real images, and the network has a hard time adjusting to previously unseen forms of a frog, or a fish (i.e. cartoon forms).  The model instead generalizes the pictures into something it does recognize.. like 'slot', or 'pencil box'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Generative Adverserial Networks (GANS)\n",
    "\n",
    "Describe the difference between a discriminator and generator in a GAN in your own words.\n",
    "\n",
    "__*Your Answer:*__ In a GAN, a generator and discriminator are working towards complete opposite goals.  The discriminator in a GAN, in the case of an image, is trying to determine if an image is real or fake.  The discriminator is able to detect the likelihood of this using some training data that was fed into its network.  So if the Discriminator is trained using a lot of Piccaso paintings, it should be able to discriminate between a fake and real Picasso.  It's goal is to reach 100% accuracy.\n",
    "\n",
    "The generator on the other hand has the goal to trick the discriminator into thinking that it's outputs are 100% real.  The generator starts off with completely random outputs.  The discriminator naturally is able to tell that the generator's initial outputs are fake.  The trick of the generator is that it then uses the feedback from the discriminator to change the weights of its outputs in order to try and make something that is more likely to pass the test. After enough rejects, the discriminator will want to get to the point that it is generating something that can pass the discriminator test, but is not quite an exact replica of an already existing Picasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?\n",
    " * I have the most fun in the predictive modeling part of Data Science.  This along with the story telling aspect of data science I feel is my strongest suit in the field.  I really want to expand my knowledge of best practice when it comes to creating models.\n",
    "- What area of Data Science would you most like to learn more about, and why?\n",
    " * I would like to improve upon my data engineering and pipeline creation skills.  I have the least exposure to these skills, and feel like they are important not only to add to my tools, but to really differentiate myself from others that do not appreciate the entire process of crunching data.\n",
    "- Where do you think Data Science will be in 5 years?\n",
    " * I think data science might become a little more organized or regulated than it is today. There are so many tools to use, most of which are not fully taken advantage of.  I can see how that in itself can halt a lot of organizations from getting started in building their own pipelines and organize their data properly.  With a more regularized framework of what data science should look like, I feel like it will unlock the benefits to many more.\n",
    "- What are the threats posed by AI to our society?\n",
    " * I honestly do not know what the actual threats AI poses to society from what I have learned so far.  Even though it is true that the decisions of a lot of Neural Networks people are building are hazy, I feel like we still understand the limitations of what neural networks can do.  The biggest threat I think is ourselves.  AI, as far as I understand, can only go wrong if the creators are not thoughful about the biases and information they feed into a system.\n",
    "- How do you think we can counteract those threats? \n",
    " * Having a regularized approach in the creation and research of Neural Networks will be incredibly important.  If there is a uniform way that people are building networks and testing them, just like any other research, others will be able to replicate and confirm findings (or prove wrong). With a uniform framework, udnerstanding can spread faster, and there is less chance of the technology to run away from us.\n",
    "- Do you think achieving General Artifical Intelligence is ever possible?\n",
    " * I do not know enough about current research, or about how general intelligence works in the first place to give a great answer.  But.. I think it is possible. It is not artificial in the way we describe it, but general intelligence has already occured with biology.. naturally.  It took a few billion years, but why would it be harder when there is directed energy and intelligence towards the effort? It may take a few thousand or million of years, but I see no reason that as we continue to learn about the brain, about the universe around us, and improve upon the technology that we currently have at the rate it has been improving.. that at some point we will have the ability to create general intelligence.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}