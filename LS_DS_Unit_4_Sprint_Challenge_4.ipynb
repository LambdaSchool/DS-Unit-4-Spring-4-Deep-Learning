{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tortas/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/LS_DS_Unit_4_Sprint_Challenge_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU_9HNLc7Wwd",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "outputId": "ed32e858-5a8b-4a1e-d180-822e6b927e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "64d04d8b-39f8-4d23-fa77-74017f257b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "63671dec-eca0-4211-e9de-5753aded06ad"
      },
      "source": [
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p4M6QrCMsKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67002419-3a84-4ee4-d459-bfa65a84795f"
      },
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 16:52:32.986763 139960824625024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 16:52:33.024604 139960824625024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 16:52:33.033595 139960824625024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 16:52:33.175859 139960824625024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0726 16:52:33.185555 139960824625024 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0726 16:52:33.443041 139960824625024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 16:52:33.466485 139960824625024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0726 16:52:33.472983 139960824625024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "25000/25000 [==============================] - 119s 5ms/step - loss: 0.4669 - acc: 0.7766 - val_loss: 0.3797 - val_acc: 0.8323\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 114s 5ms/step - loss: 0.3298 - acc: 0.8593 - val_loss: 0.3691 - val_acc: 0.8380\n",
            "Epoch 3/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.2626 - acc: 0.8942 - val_loss: 0.3923 - val_acc: 0.8329\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.2024 - acc: 0.9202 - val_loss: 0.4313 - val_acc: 0.8305\n",
            "Epoch 5/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.1585 - acc: 0.9402 - val_loss: 0.5077 - val_acc: 0.8287\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.1235 - acc: 0.9546 - val_loss: 0.5793 - val_acc: 0.8251\n",
            "Epoch 7/15\n",
            "25000/25000 [==============================] - 112s 4ms/step - loss: 0.0994 - acc: 0.9644 - val_loss: 0.6326 - val_acc: 0.8201\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 112s 4ms/step - loss: 0.0777 - acc: 0.9725 - val_loss: 0.7533 - val_acc: 0.8104\n",
            "Epoch 9/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.0558 - acc: 0.9811 - val_loss: 0.7936 - val_acc: 0.8168\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.0489 - acc: 0.9842 - val_loss: 0.8406 - val_acc: 0.8187\n",
            "Epoch 11/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.0424 - acc: 0.9856 - val_loss: 0.8243 - val_acc: 0.8150\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 113s 5ms/step - loss: 0.0304 - acc: 0.9900 - val_loss: 1.0263 - val_acc: 0.8106\n",
            "Epoch 13/15\n",
            "25000/25000 [==============================] - 112s 4ms/step - loss: 0.0296 - acc: 0.9905 - val_loss: 0.9766 - val_acc: 0.8164\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 112s 4ms/step - loss: 0.0199 - acc: 0.9938 - val_loss: 1.0030 - val_acc: 0.8143\n",
            "Epoch 15/15\n",
            "25000/25000 [==============================] - 112s 4ms/step - loss: 0.0200 - acc: 0.9936 - val_loss: 1.0163 - val_acc: 0.8163\n",
            "25000/25000 [==============================] - 21s 835us/step\n",
            "Test score: 1.016306214350462\n",
            "Test accuracy: 0.81632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lPn6c0x21gu1"
      },
      "source": [
        "Conclusion - RNN runs, and gives pretty decent improvement over a naive model. To *really* improve the model, more playing with parameters would help. Also - RNN may well not be the best approach here, but it is at least a valid one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "496e3d98-29be-475d-cf5a-b579a4125571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_images_download\n",
            "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
            "Collecting selenium (from google_images_download)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
            "Successfully built google-images-download\n",
            "Installing collected packages: selenium, google-images-download\n",
            "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "e0713a25-49c9-4286-b940-503e36c317ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"animal pond\", \"limit\": 15, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = animal pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
            "Completed Image ====> 1.Pondanimals.GIF\n",
            "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
            "Completed Image ====> 2.hqdefault.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
            "Completed Image ====> 3.PKLS4116_inline.png\n",
            "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Completed Image ====> 4.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
            "Completed Image ====> 5.PKLS4116.png\n",
            "Image URL: https://cdn.pixabay.com/photo/2018/04/11/23/05/frog-3312038__340.jpg\n",
            "Completed Image ====> 6.frog-3312038__340.jpg\n",
            "Image URL: https://i.pinimg.com/originals/57/5c/5b/575c5b5c441e27ff04eb50571ee30127.jpg\n",
            "Completed Image ====> 7.575c5b5c441e27ff04eb50571ee30127.jpg\n",
            "Image URL: https://pixnio.com/free-images/fauna-animals/reptiles-and-amphibians/alligators-and-crocodiles-pictures/alligator-animal-on-pond.jpg\n",
            "Completed Image ====> 8.alligator-animal-on-pond.jpg\n",
            "Image URL: https://www.pixoto.com/images-photography/animals/birds/birds-in-a-pond-5986310798966784.jpg\n",
            "Completed Image ====> 9.birds-in-a-pond-5986310798966784.jpg\n",
            "Image URL: https://cdn.pixabay.com/photo/2017/04/19/20/37/frog-2243543_960_720.jpg\n",
            "Completed Image ====> 10.frog-2243543_960_720.jpg\n",
            "Image URL: https://img-aws.ehowcdn.com/750x428p/photos.demandstudios.com/getty/article/178/192/87827228_XS.jpg\n",
            "Completed Image ====> 11.87827228_XS.jpg\n",
            "Image URL: https://a5.mzstatic.com/us/r30/Purple4/v4/48/05/96/480596cb-892e-df83-830e-76d623bd29fa/screen480x480.jpeg\n",
            "Completed Image ====> 12.screen480x480.jpeg\n",
            "Image URL: http://static.havahart.com/media/articles/images/817/55-herons-out-koi-pond.jpg\n",
            "Completed Image ====> 13.55-herons-out-koi-pond.jpg\n",
            "Image URL: https://www.nwf.org/-/media/NEW-WEBSITE/Programs/Garden-for-Wildlife/amphibian_bronze-frog_Julia-Bartosh_400x267.ashx\n",
            "Invalid or missing image format. Skipping...\n",
            "Image URL: https://cdn.pixabay.com/photo/2017/08/17/06/32/goose-2650209_960_720.jpg\n",
            "Completed Image ====> 14.goose-2650209_960_720.jpg\n",
            "Image URL: https://pondinformer.com/wp-content/uploads/2018/04/pond-fish-that-eat-algae.jpg\n",
            "Completed Image ====> 15.pond-fish-that-eat-algae.jpg\n",
            "\n",
            "Errors: 1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0ypnem2e0e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "absolute_image_paths = absolute_image_paths[0]['animal pond'] # Dictionary -> List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goal* - also check for fish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_meU_MvfZlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224,224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x,axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)\n",
        "  results = decode_predictions(features, top=3)[0]\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if 'frog' in entry[1]:\n",
        "      return entry[2]\n",
        "  return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwG5tjKXhvFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "36268326-2c59-4254-ab30-80cee93a0db3"
      },
      "source": [
        "for img in absolute_image_paths:\n",
        "  img_contains_frog(process_img_path(img))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n03598930', 'jigsaw_puzzle', 0.8680313), ('n06359193', 'web_site', 0.06410018), ('n02834397', 'bib', 0.021264324)]\n",
            "[('n01443537', 'goldfish', 0.8495859), ('n01631663', 'eft', 0.067602046), ('n02536864', 'coho', 0.035163548)]\n",
            "[('n04243546', 'slot', 0.87124527), ('n04476259', 'tray', 0.049935803), ('n03908618', 'pencil_box', 0.023072328)]\n",
            "[('n02442845', 'mink', 0.30976582), ('n02363005', 'beaver', 0.23398991), ('n02361337', 'marmot', 0.2079679)]\n",
            "[('n03485794', 'handkerchief', 0.88227266), ('n02834397', 'bib', 0.022680871), ('n03291819', 'envelope', 0.020095097)]\n",
            "[('n01737021', 'water_snake', 0.3073064), ('n01641577', 'bullfrog', 0.26061213), ('n04275548', 'spider_web', 0.11343445)]\n",
            "[('n02116738', 'African_hunting_dog', 0.6101558), ('n02105162', 'malinois', 0.19866863), ('n02114712', 'red_wolf', 0.051153094)]\n",
            "[('n01698640', 'American_alligator', 0.96394104), ('n01697457', 'African_crocodile', 0.026759902), ('n01737021', 'water_snake', 0.0059646694)]\n",
            "[('n02009912', 'American_egret', 0.7822422), ('n02012849', 'crane', 0.14339165), ('n02009229', 'little_blue_heron', 0.021143371)]\n",
            "[('n01641577', 'bullfrog', 0.9223301), ('n01644900', 'tailed_frog', 0.07364703), ('n01644373', 'tree_frog', 0.0011781204)]\n",
            "[('n01443537', 'goldfish', 0.9569482), ('n01833805', 'hummingbird', 0.009290835), ('n12620546', 'hip', 0.0034554899)]\n",
            "[('n03710721', 'maillot', 0.17273416), ('n04371430', 'swimming_trunks', 0.12428127), ('n04476259', 'tray', 0.09713027)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Generative Adverserial Networks (GANS)\n",
        "\n",
        "Describe the difference between a discriminator and generator in a GAN in your own words.\n",
        "\n",
        "__*Your Answer:*__ In a Generative Adversarial Network there are two separate neural networks pitted against each other (hence the \"Adversarial\" in the name). One is considered the generator because it is used to generate outputs. Those outputs are then fed into a discriminator network whose role is to determine whether the output is a genuine sample of whatever is being classified. Based on whether the discriminator is fooled by the output, the generator tweaks its weights to perform better in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist? My strongest area is regression models. This is mostly due to my strength in math and statistics from my experience as an undergrad.\n",
        "- What area of Data Science would you most like to learn more about, and why? I would like to dive deeper into GAN's. I think they are fascinating and fun to work with. I have been inspired to create my own music generating AI.\n",
        "- Where do you think Data Science will be in 5 years? I think Data Science will be even more deeply entrenched into every sector of life. More and more data will be available as technology improves and our ability to capture it improves and there will need to be a lot more scientists around to use and analyze it.\n",
        "- What are the treats posed by AI to our society? With such powerful technology and its potential to grow even stronger the danger is always there that it will be used to control. It could be used in surveillance purposes aimed at creating police states and suppressing dissent along with many other devious purposes.\n",
        "- How do you think we can counteract those threats? By being proactive in forming ethical policies and enforcing those that already exist. We also need to hold the people who use technology for wrong.\n",
        "- Do you think achieving General Artifical Intelligence is ever possible? I think so. I believe that eventually the breakthroughs will be made in order for AI to take the next big step into the realm of general AI.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rcyHRP-7Wxm",
        "colab_type": "code",
        "colab": {},
        "outputId": "f49382eb-d4e8-46f3-997d-fd158af6fd38"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}