{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My LS_DS_444_AGI_and_The_Future_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wel51x/DS-Unit-4-Sprint-4-Deep-Learning/blob/master/My_LS_DS_444_AGI_and_The_Future_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IizNKWLomoA",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science - Artificial General Intelligence and The Future\n",
        "\n",
        "![Future City](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/City-of-the-future.jpg/640px-City-of-the-future.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moj-4gr89pum",
        "colab_type": "text"
      },
      "source": [
        "# Lecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EZdBzC6pvV9",
        "colab_type": "text"
      },
      "source": [
        "## Defining Intelligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Y6I1aO9uCz",
        "colab_type": "text"
      },
      "source": [
        "A straightforward definition of Artificial Intelligence would simply be \"intelligence, created from technology rather than biology.\" But that simply raises the question - what is *intelligence*?\n",
        "\n",
        "In the early history of computers, this seemed like an easier question. Intelligence meant solving tricky problems - things that took time and mental effort for a human to figure out.\n",
        "\n",
        "Defined that way, computers have made a litany of intelligent achievements over the years:\n",
        "- Arithmetic\n",
        "- Logic\n",
        "- Chess\n",
        "- Go\n",
        "- StarCraft\n",
        "- Mathematical proofs\n",
        "- Understanding natural language\n",
        "- Generating natural language\n",
        "- Understanding images\n",
        "- Generating images\n",
        "- Making medical diagnoses\n",
        "- Fitting and *optimizing* ML models\n",
        "\n",
        "And many more - every time you fit a simple regression, you're facilitating an act of artificial intelligence. You're writing code that will (hopefully) understand and generalize based on data, giving a \"human-like\" ability to intuit and predict something."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXdC1uCC91ID",
        "colab_type": "text"
      },
      "source": [
        "## \"General\" Intelligence - a moving target\n",
        "\n",
        "But, somehow, that isn't what most people *really* mean when they talk about AI.\n",
        "\n",
        "![And they both react poorly to showers.](https://imgs.xkcd.com/comics/ai.png)\n",
        "\n",
        "Somewhere that word \"general\" snuck in, and now we're concerned about \"Artificial General Intelligence.\" So, what is that?\n",
        "\n",
        "![Data](https://upload.wikimedia.org/wikipedia/en/0/09/DataTNG.jpg)\n",
        "\n",
        "The inspiration is likely characters such as the above, but that's not a definition. Intuitively the claim is \"computers that can be thrown in a variety of environments and learn without guidance\", but another good definition (based on how people use the term) may simply be \"whatever we haven't figured out how to get computers to do yet.\"\n",
        "\n",
        "Repeatedly, claims are made about tasks that will require a \"true AI\" to achieve. Then, when those tasks are completed, the bar is moved, and \"true AI\" is somehow always a bit further off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJV_2Ozk5LLV",
        "colab_type": "text"
      },
      "source": [
        "## AI - Hype versus Value\n",
        "\n",
        "Hot off the presses! [Google launches an end-to-end AI platform](https://techcrunch.com/2019/04/10/google-expands-its-ai-services/)!\n",
        "\n",
        "...\n",
        "\n",
        "What does that mean? Well, it might mean a lot, but it's a little unclear what. Some selected [Hacker News](https://news.ycombinator.com/item?id=19626275) comments:\n",
        "\n",
        "> This platform focuses not on the this-AI-is-magic-and-can-solve-everything like many AI SaaS startups announced on Hacker News, but focuses on how to actually integrate this AI into production workflows, which is something I wish was discussed more often in AI. -- minimaxir\n",
        "\n",
        "> Looks like Google is taking over Cloud (from AWS) for AI by building an ecosystem and building tools for non Data scientists - consumer level product. Surely IBM can do similar thing with their recent Redhat acquisition, but will they ? -- amrrs\n",
        "\n",
        "> I work in building and deploying production ML/AI models but I'm having a lot of trouble cutting through the marketing jargon in this article and on Google's website as well. Can someone explain what this does in engineering terms? How does this differ from something like AWS Sagemaker? -- chibg10\n",
        "\n",
        "> This will make a bunch of startup's life really hard. I think it makes it harder to justify investing in your own ML pipeline or even building your own models for many use cases. -- petard\n",
        "\n",
        "One thing it definitely means - AI is a hot keyword, and people making hiring and other corporate decisions will be on the look out for it, even if they're not sure what it is.\n",
        "\n",
        "So - yes, you *do* know AI. AI is a real thing, and you are capable of using \"artificial\" technology to bring about real *intelligence* and insight.\n",
        "\n",
        "Do you know how to make an intelligent anthropomorphic android? No - and nobody else does yet, either. And that's OK. There's still lots of cool advances and things to learn and build."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpSkJFuIkJeU",
        "colab_type": "text"
      },
      "source": [
        "## Automation, for good and ill\n",
        "\n",
        "It is worth spending a moment considering the double-edged sword that is automation. This story did not begin with artificial intelligence, or even statistics or mathematics - it began when the first tool inventor figured out how to make something clever like a lever or a wheel, and use it to reduce the amount of labor needed to achieve some task.\n",
        "\n",
        "In the modern day we talk about automation, but in practice most technology is best considered as a *productivity multiplier* - all businesses still need at least *some* humans around, if nothing else to make policy decisions and collect profit. But the productivity of each individual person can be greatly enhanced through the use of technology.\n",
        "\n",
        "Consider farming - formerly a signification source of employment (and also small family owned farms), technology has tranformed it into a large scale industry where a handful of people produce as much as many more did before. This progression has happened in many areas - fortunately, it is usually accompanied by job growth and opportunity as new markets and services are created by technology as well.\n",
        "\n",
        "So, is it different now? Maybe - \"history will say\" is the only safe stance. But we are automating work at an accelerating rate, and it's unclear where all this growth is going and where the opportunities will be. There's a pretty good bet that it'll involve computers and data - and that's probably a large part of why you're here!\n",
        "\n",
        "The purpose of this section is not to convince you of anything - it is just to make you think. As a Data Scientist, you will have an outsized impact on society, and it is your responsibility to consider that impact and what you want to do with it.\n",
        "\n",
        "**Important caveat** - think and engage with society, *but* strive to not be strident or unduly certain when you do so. Broadcasting political beliefs, especially while on the job market, usually closes more doors than it opens. So, consider perspectives, and encourage dialogue - don't just (re)broadcast outrage at the latest injustice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xltSPWmMhQod",
        "colab_type": "code",
        "outputId": "f3e6b321-2e69-4d70-cb0e-0a558b1f953a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "!pip install tpot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tpot in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.2.1)\n",
            "Requirement already satisfied: deap>=1.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.28.1)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.16)\n",
            "Requirement already satisfied: pandas>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.24.2)\n",
            "Requirement already satisfied: stopit>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.20.3)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.21.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->tpot) (2.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2019.3.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->tpot) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhI7BzgmhWMy",
        "colab_type": "code",
        "outputId": "1d87b2c5-9dbd-4af5-a0fb-de8eb2d24c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "from tpot import TPOTRegressor\n",
        "\n",
        "df = pd.read_csv('car_regression.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>make</th>\n",
              "      <th>price</th>\n",
              "      <th>body</th>\n",
              "      <th>mileage</th>\n",
              "      <th>engV</th>\n",
              "      <th>engType</th>\n",
              "      <th>registration</th>\n",
              "      <th>year</th>\n",
              "      <th>drive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>15500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>20500.0</td>\n",
              "      <td>3</td>\n",
              "      <td>173</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>135</td>\n",
              "      <td>5.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2008</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>17800.0</td>\n",
              "      <td>5</td>\n",
              "      <td>162</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55</td>\n",
              "      <td>16600.0</td>\n",
              "      <td>0</td>\n",
              "      <td>83</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   make    price  body  mileage  engV  engType  registration  year  drive\n",
              "0    23  15500.0     0       68   2.5        1             1  2010      1\n",
              "1    50  20500.0     3      173   1.8        1             1  2011      2\n",
              "2    50  35000.0     2      135   5.5        3             1  2008      2\n",
              "3    50  17800.0     5      162   1.8        0             1  2012      0\n",
              "4    55  16600.0     0       83   2.0        3             1  2013      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XED4cuyimEsP",
        "colab_type": "code",
        "outputId": "4fed6257-9bfb-4cb3-c408-0df2d80f95fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>make</th>\n",
              "      <th>price</th>\n",
              "      <th>body</th>\n",
              "      <th>mileage</th>\n",
              "      <th>engV</th>\n",
              "      <th>engType</th>\n",
              "      <th>registration</th>\n",
              "      <th>year</th>\n",
              "      <th>drive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "      <td>8495.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>46.535491</td>\n",
              "      <td>16185.453305</td>\n",
              "      <td>2.302295</td>\n",
              "      <td>141.744202</td>\n",
              "      <td>2.568337</td>\n",
              "      <td>1.650618</td>\n",
              "      <td>0.941613</td>\n",
              "      <td>2006.500883</td>\n",
              "      <td>0.575868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>24.526251</td>\n",
              "      <td>24449.641512</td>\n",
              "      <td>1.610307</td>\n",
              "      <td>97.464062</td>\n",
              "      <td>5.387238</td>\n",
              "      <td>1.341282</td>\n",
              "      <td>0.234488</td>\n",
              "      <td>6.925907</td>\n",
              "      <td>0.741235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>259.350000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1959.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>5490.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>9500.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>68.000000</td>\n",
              "      <td>17145.600000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2011.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>82.000000</td>\n",
              "      <td>547800.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>99.990000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              make          price  ...         year        drive\n",
              "count  8495.000000    8495.000000  ...  8495.000000  8495.000000\n",
              "mean     46.535491   16185.453305  ...  2006.500883     0.575868\n",
              "std      24.526251   24449.641512  ...     6.925907     0.741235\n",
              "min       0.000000     259.350000  ...  1959.000000     0.000000\n",
              "25%      23.000000    5490.000000  ...  2004.000000     0.000000\n",
              "50%      50.000000    9500.000000  ...  2008.000000     0.000000\n",
              "75%      68.000000   17145.600000  ...  2011.000000     1.000000\n",
              "max      82.000000  547800.000000  ...  2016.000000     2.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRdeEEbomGQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('price', axis=1).values\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, df['price'].values, train_size=0.75, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5dAYY5VmuEc",
        "colab_type": "code",
        "outputId": "e4bbd6aa-9761-45dd-8385-66aba12fab3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
        "tpot.fit(X_train, y_train)\n",
        "print(tpot.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "501ec2510bfa4f73a8fc4096a22a1e2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: -133141429.03390601\n",
            "Generation 2 - Current best internal CV score: -129432295.79929402\n",
            "Generation 3 - Current best internal CV score: -129432295.79929402\n",
            "Generation 4 - Current best internal CV score: -129432295.79929402\n",
            "Generation 5 - Current best internal CV score: -127465051.18964705\n",
            "\n",
            "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.99, learning_rate=0.1, loss=lad, max_depth=9, max_features=0.25, min_samples_leaf=10, min_samples_split=15, n_estimators=100, subsample=0.9000000000000001)\n",
            "-120411233.98885702\n",
            "CPU times: user 7min 16s, sys: 9.28 s, total: 7min 25s\n",
            "Wall time: 7min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma_BH3rpqLFA",
        "colab_type": "code",
        "outputId": "63602cc4-48a2-461a-d922-4ca2ac354f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tpot.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6941.76312027,  6490.98506205,  5716.99816711, ...,\n",
              "        9482.15768688,  8170.80266469, 22037.23983594])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTSYqr_dqdNb",
        "colab_type": "code",
        "outputId": "e04e2b8d-f6f2-4c1d-a452-63b36fb7a578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7000.,  6100.,  6500., ..., 13200.,  7800., 22700.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVijM-bCd6Xh",
        "colab_type": "text"
      },
      "source": [
        "It works - but it looks like we're not quite out of a job yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYXU2HBrswcX",
        "colab_type": "text"
      },
      "source": [
        "## So, is AutoML an \"AGI\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws30-q7PtEWE",
        "colab_type": "text"
      },
      "source": [
        "**No** - it's a search (grid or possibly using genetic/tree pruning/etc. heuristics) in parameter space, with some clever type inference heuristics and a slick interface.\n",
        "\n",
        "But, it *is* artificial, it *does* give intelligent results, and (like most technology) it *multiplies* productivity. It's not going to \"take our jobs\" - but it does mean that, in some situations, one data scientist will be able to do what formerly took several to achieve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glOqJQkA0bxG",
        "colab_type": "text"
      },
      "source": [
        "## Is Artificial General Intelligence dangerous?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZrQq9D3ik6h",
        "colab_type": "text"
      },
      "source": [
        "![I'm working to bring about a superintelligent AI that will eternally torment everyone who failed to make fun of the Roko's Basilisk people.](https://imgs.xkcd.com/comics/ai_box_experiment.png)\n",
        "\n",
        "There's been much philosophizing, thought experimenting, and even some genuine advocacy and policy considerations about the impact of a \"true\" AGI on human society. Most of these analyses essentially consider the AGI as an unfathomable deity, thinking and moving in ways well beyond human comprehension.\n",
        "\n",
        "Consider the [paperclip maximizer](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer):\n",
        "\n",
        "> Suppose we have an AI whose only goal is to make as many paper clips as possible. The AI will realize quickly that it would be much better if there were no humans because humans might decide to switch it off. Because if humans do so, there would be fewer paper clips. Also, human bodies contain a lot of atoms that could be made into paper clips. The future that the AI would be trying to gear towards would be one in which there were a lot of paper clips but no humans. — Nick Bostrom\n",
        "\n",
        "This is an example of *instrumental convergence* - the idea that, if an AGI were to pursue an unbounded goal (a natural instruction like \"Maximize the health of all humans\") it may push it in extremely unexpected ways (put all humans in vats of goo, to both preserve them and prevent them from disabling it, since its existence is also of value to help humans).\n",
        "\n",
        "Is this a *realistic* concern? Well, maybe eventually - but pretty obviously not an immediate one. There are many more prominent challenges involving tech and society - privacy, economic growth, equality, education - and even *if* AGI existed it's not clear how they would have the means to enact such fantastic plans. Killer robot armies make for good TV, but at some step there's likely a human with an off switch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayWGQhHu1yRu",
        "colab_type": "text"
      },
      "source": [
        "## Where is AI going, and where does it leave us?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrBqwYoziUSm",
        "colab_type": "text"
      },
      "source": [
        "![Lambda calculus? More like SHAMda calculus, amirite?](https://imgs.xkcd.com/comics/ai_research.png)\n",
        "\n",
        "On the one hand, we live in a remarkable time. The explosion of technology from WWII to present has brought about countless innovations, greatly increased median life expectancy and GDP, and shows no sign of slowing down.\n",
        "\n",
        "On the other hand, the more things change the more they stay the same. Humans are still Homo sapiens, with the same brains we've had for many millenia. [Dunbar's number](https://en.wikipedia.org/wiki/Dunbar's_number) stymies our attempts to be globally considerate and aware, and at the end of the day it seems like the vast majority of our behavior is as it ever has been - just with shinier toys.\n",
        "\n",
        "So, what will happen? Will technology usher in a utopia, where automation finally relieves us all of burdensome tasks and we are free to explore science, art, and leisure? Or are we doomed to a dystopia, where increased production is also increasingly centralized and the vast majority of humanity becomes a permanent underclass in a postmodern cyberpunk world?\n",
        "\n",
        "Probably neither - both are extreme points along a continuum of possibility. But wherever we do end up, it is all but certain that AI (that is, technology generating insights and signal) will be a key part of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbzOQKU7Yv2",
        "colab_type": "text"
      },
      "source": [
        "## And what about A*G*I?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB8YZxHc7gGm",
        "colab_type": "text"
      },
      "source": [
        "> \"I think, therefore I am.\" -- René Descartes\n",
        "\n",
        "> \"I am a strange loop.\" -- Douglas Hofstadter\n",
        "\n",
        "Artificial General Intelligence is, as discussed, a moving target. Perhaps what we're looking for isn't intelligence, but consciousness - and specifically, consciousness *we* recognize and empathize with. Much like all parents, us humans want to foster something new in our image, and see it succeed in a way we appreciate.\n",
        "\n",
        "It's not clear if technology will ever *really* get there. The structure and approach to artificial intelligence is inherently, well, artificial - some things like neural networks are \"inspired\" by biology, but still very different (far fewer connections, but far faster with more data). Perhaps computers really already *are* intelligent, just not in a way we recognize.\n",
        "\n",
        "And if we ever do succeed at making our virtual progeny, we may find it bittersweet - not because they will inevitably destroy us (though they probably will outlast us), but simply because it will then lead us to wonder what is so special about us in the first place. If we can create an AGI from metal and sand, then are we not just mechanisms of a different sort?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfZdD_cp1t5",
        "colab_type": "text"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "Use either [automl-gs](https://github.com/minimaxir/automl-gs) or [TPOT](https://github.com/EpistasisLab/tpot) to solve at least two of your prior assignments, projects, or other past work (any time you fit a classification or regression model). Report the results, and compare/contrast with the results you found when you worked on it using your \"human\" ML approach.\n",
        "\n",
        "Note - these tools promise a lot, but the reality is that you may have to debug a bit and figure out getting your data in a format that it recognizes. Welcome to the cutting edge - at least there's still plenty of work to do!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qznbNnhLpHZa",
        "colab_type": "text"
      },
      "source": [
        "###LS_DS_433_Keras_Assignment\n",
        "\n",
        "Using Boston Housing - fashion_mnist ran forever!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltj1je1fp5rO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - ✨\n",
        "import pandas as pd\n",
        "from tpot import TPOTRegressor, TPOTClassifier\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.scorer import make_scorer\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsTzeMLrDNXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a custom metric function\n",
        "def my_custom_accuracy(y_true, y_pred):\n",
        "    return float(sum(y_pred == y_true)) / len(y_true)\n",
        "\n",
        "# Make a custom a scorer from the custom metric function\n",
        "# Note: greater_is_better=False in make_scorer below would mean that the scoring function should be minimized.\n",
        "my_custom_scorer = make_scorer(my_custom_accuracy, greater_is_better=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ5gi0gNnMrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skipping - runs forever\n",
        "#from keras.datasets import fashion_mnist\n",
        "\n",
        "#(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "#X_train = X_train.reshape(60000, 784).astype('float32') /255\n",
        "#X_test = X_test.reshape(10000, 784).astype('float32') /255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjE2Xv1IHK6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20avINZX-HyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# normalize\n",
        "X_train = X_train/X_train.max(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP5g3MBpoDrF",
        "colab_type": "code",
        "outputId": "948fb0c4-7827-4628-84ba-b3630ae2523d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (102, 13), (404,), (102,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6WBsHDmnV3V",
        "colab_type": "code",
        "outputId": "b736f354-c5d2-4824-fd49-2696ba129e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2,\n",
        "#                     n_jobs=-1, scoring=my_custom_scorer)\n",
        "                     n_jobs=-1)\n",
        "tpot.fit(X_train, y_train)\n",
        "print(\"TPOT Score:\", tpot.score(X_test, y_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ed382d352fe4975834df3d20db1e293",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: -14.02713117922806\n",
            "Generation 2 - Current best internal CV score: -13.759563730393054\n",
            "Generation 3 - Current best internal CV score: -12.67086481994507\n",
            "Generation 4 - Current best internal CV score: -12.409412441747262\n",
            "Generation 5 - Current best internal CV score: -12.409412441747262\n",
            "\n",
            "Best pipeline: RandomForestRegressor(XGBRegressor(input_matrix, learning_rate=0.1, max_depth=3, min_child_weight=8, n_estimators=100, nthread=1, subsample=0.45), bootstrap=True, max_features=0.9500000000000001, min_samples_leaf=5, min_samples_split=16, n_estimators=100)\n",
            "-87.76869167232162\n",
            "CPU times: user 10.4 s, sys: 614 ms, total: 11 s\n",
            "Wall time: 1min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEk0KFhKEJEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "f2a81aed-2b8c-4b09-d674-2439d283c7cc"
      },
      "source": [
        "sorted(sklearn.metrics.SCORERS.keys())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'brier_score_loss',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'mutual_info_score',\n",
              " 'my_custom_accuracy',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lYLbK_7AyCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "f6ba61a8-aa77-4c3f-fce9-4a7f4eed5022"
      },
      "source": [
        "tpot.predict(X_test)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([25.30775757, 25.80842108, 26.17217644, 25.78636394, 25.89888601,\n",
              "       25.63203903, 26.02417473, 26.02417473, 27.4399327 , 25.63203903,\n",
              "       25.63203903, 25.63203903, 25.30775757, 26.17217644, 25.32593938,\n",
              "       25.5902118 , 25.83332108, 26.17217644, 25.63203903, 23.82909796,\n",
              "       25.32593938, 25.63203903, 27.45291821, 25.73249385, 26.02417473,\n",
              "       25.63203903, 25.80842108, 26.02417473, 25.30775757, 26.13034921,\n",
              "       25.80842108, 25.63203903, 30.40119996, 25.70400288, 25.63203903,\n",
              "       25.30775757, 22.94249512, 25.32593938, 25.78636394, 26.02417473,\n",
              "       26.02417473, 25.80842108, 25.30775757, 25.63203903, 28.45638579,\n",
              "       26.17217644, 26.13034921, 25.63203903, 25.30775757, 25.70400288,\n",
              "       26.02417473, 25.80842108, 25.30775757, 25.63203903, 25.79149385,\n",
              "       26.17217644, 25.30775757, 25.5902118 , 30.40119996, 26.06600196,\n",
              "       25.32593938, 25.30775757, 25.34799653, 25.63203903, 25.77432108,\n",
              "       26.13034921, 25.30775757, 26.02417473, 25.67003145, 25.30775757,\n",
              "       23.82909796, 25.79149385, 25.63203903, 25.68194573, 27.41109098,\n",
              "       25.76659385, 25.76659385, 25.80842108, 26.02417473, 25.30775757,\n",
              "       25.63203903, 25.26593034, 25.66217565, 25.78636394, 25.63203903,\n",
              "       25.76659385, 25.32593938, 30.28437352, 26.17217644, 25.63203903,\n",
              "       25.63203903, 25.85705879, 25.76659385, 25.5902118 , 25.66217565,\n",
              "       22.94249512, 25.26593034, 25.78636394, 25.83332108, 25.78636394,\n",
              "       25.80842108, 25.32593938])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r09HEIJswz4c",
        "colab_type": "text"
      },
      "source": [
        "###Heart Disease dataset from UCI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Ej3Dwcwyss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/wel51x/Data/master/heart.csv')\n",
        "X = df.drop('target', axis=1).values\n",
        "y = df['target'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=0.8, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Ogi92Q1tvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5d4e836-12d3-42e3-b4fe-37cf6e2b7b97"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape, "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((242, 13), (61, 13), (242,), (61,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdxyg1At1o61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "6742ca3d-c698-4bc1-ef79-f73ba8fc0196"
      },
      "source": [
        "%%time\n",
        "\n",
        "tpot = TPOTClassifier(generations=5, population_size=20, random_state=42, verbosity=2, scoring='roc_auc')\n",
        "tpot.fit(X_train, y_train)\n",
        "print(\"TPOT Score:\", tpot.score(X_test, y_test))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0717f23e97de485485b5cd296d69db2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.8924322590989258\n",
            "Generation 2 - Current best internal CV score: 0.8967291967291967\n",
            "Generation 3 - Current best internal CV score: 0.8980920314253649\n",
            "Generation 4 - Current best internal CV score: 0.8980920314253649\n",
            "Generation 5 - Current best internal CV score: 0.9051787718454385\n",
            "\n",
            "Best pipeline: BernoulliNB(OneHotEncoder(RobustScaler(GradientBoostingClassifier(input_matrix, learning_rate=0.001, max_depth=1, max_features=0.2, min_samples_leaf=5, min_samples_split=7, n_estimators=100, subsample=1.0)), minimum_fraction=0.05, sparse=False, threshold=10), alpha=100.0, fit_prior=True)\n",
            "TPOT Score: 0.9118279569892473\n",
            "CPU times: user 45.5 s, sys: 4.08 s, total: 49.6 s\n",
            "Wall time: 44.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsPYTqo2AzTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55bae667-983d-42d6-a1fb-0243f8e5fb56"
      },
      "source": [
        "tpot.predict(X_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1",
        "colab_type": "text"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6",
        "colab_type": "text"
      },
      "source": [
        "Stretch goals\n",
        "- Apply AutoML to more data, including data you've not analyzed or data you're considering for project work\n",
        "- Try to work with the GPU/TPU options, and see if you can accelerate your AutoML\n",
        "- Check out other competing AutoML systems (see resources or search and share - many are cloud hosted which is why we went with this)\n",
        "- Write a blog post summarizing your experience learning Data Science at Lambda School!\n",
        "\n",
        "Resources\n",
        "- [What to expect from AutoML software](https://epistasislab.github.io/tpot/using/#what-to-expect-from-automl-software)\n",
        "- [TPOT examples](https://epistasislab.github.io/tpot/examples/)\n",
        "- [Google Cloud AutoML](https://cloud.google.com/automl/) - the Google offering in the AutoML space (also has vision, video, NLP, and translation)\n",
        "- [Microsoft AutoML](https://www.microsoft.com/en-us/research/project/automl/)\n",
        "- [AutoML.org](https://www.automl.org)\n",
        "- [Ludwig](https://uber.github.io/ludwig/) - a toolbox for deep learning that doesn't require coding, from Uber\n",
        "- [USENIX Security '18-Q: Why Do Keynote Speakers Keep Suggesting That Improving Security Is Possible?](https://youtu.be/ajGX7odA87k) - a humorous but informative presentation by James Mickens, focused on security but with a consideration of data and machine learning"
      ]
    }
  ]
}